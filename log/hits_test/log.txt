2019-06-20 16:07:53,150 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:07:53,150 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:07:53,150 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:07:53,150 - root - INFO - Dataset: hits
2019-06-20 16:07:53,150 - root - INFO - Normal class: 1
2019-06-20 16:07:53,150 - root - INFO - Network: mnist_LeNet
2019-06-20 16:07:53,151 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:07:53,151 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:07:53,187 - root - INFO - Computation device: cuda
2019-06-20 16:07:53,187 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:12:36,303 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:12:36,303 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:12:36,303 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:12:36,303 - root - INFO - Dataset: hits
2019-06-20 16:12:36,303 - root - INFO - Normal class: 1
2019-06-20 16:12:36,303 - root - INFO - Network: mnist_LeNet
2019-06-20 16:12:36,303 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:12:36,303 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:12:36,341 - root - INFO - Computation device: cuda
2019-06-20 16:12:36,341 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:14:20,518 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:14:20,518 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:14:20,518 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:14:20,518 - root - INFO - Dataset: hits
2019-06-20 16:14:20,518 - root - INFO - Normal class: 1
2019-06-20 16:14:20,518 - root - INFO - Network: mnist_LeNet
2019-06-20 16:14:20,519 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:14:20,519 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:14:20,558 - root - INFO - Computation device: cuda
2019-06-20 16:14:20,558 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:14:30,248 - root - INFO - Pretraining: True
2019-06-20 16:14:30,248 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:14:30,249 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:14:30,249 - root - INFO - Pretraining epochs: 150
2019-06-20 16:14:30,249 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:14:30,249 - root - INFO - Pretraining batch size: 200
2019-06-20 16:14:30,249 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:14:32,352 - root - INFO - Starting pretraining...
2019-06-20 16:15:21,605 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:15:21,605 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:15:21,605 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:15:21,605 - root - INFO - Dataset: hits
2019-06-20 16:15:21,605 - root - INFO - Normal class: 1
2019-06-20 16:15:21,605 - root - INFO - Network: mnist_LeNet
2019-06-20 16:15:21,605 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:15:21,605 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:15:21,641 - root - INFO - Computation device: cuda
2019-06-20 16:15:21,641 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:15:31,304 - root - INFO - Pretraining: True
2019-06-20 16:15:31,304 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:15:31,304 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:15:31,304 - root - INFO - Pretraining epochs: 150
2019-06-20 16:15:31,304 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:15:31,304 - root - INFO - Pretraining batch size: 200
2019-06-20 16:15:31,304 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:15:33,366 - root - INFO - Starting pretraining...
2019-06-20 16:36:37,598 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:36:37,598 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:36:37,599 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:36:37,599 - root - INFO - Dataset: hits
2019-06-20 16:36:37,600 - root - INFO - Normal class: 1
2019-06-20 16:36:37,600 - root - INFO - Network: mnist_LeNet
2019-06-20 16:36:37,600 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:36:37,600 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:36:37,629 - root - INFO - Computation device: cuda
2019-06-20 16:36:37,629 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:36:47,453 - root - INFO - Pretraining: True
2019-06-20 16:36:47,453 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:36:47,453 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:36:47,453 - root - INFO - Pretraining epochs: 150
2019-06-20 16:36:47,453 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:36:47,453 - root - INFO - Pretraining batch size: 200
2019-06-20 16:36:47,453 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:36:49,525 - root - INFO - Starting pretraining...
2019-06-20 16:37:44,770 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:37:44,770 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:37:44,770 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:37:44,770 - root - INFO - Dataset: hits
2019-06-20 16:37:44,770 - root - INFO - Normal class: 1
2019-06-20 16:37:44,770 - root - INFO - Network: mnist_LeNet
2019-06-20 16:37:44,770 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:37:44,770 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:37:44,808 - root - INFO - Computation device: cuda
2019-06-20 16:37:44,808 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:37:54,582 - root - INFO - Pretraining: True
2019-06-20 16:37:54,582 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:37:54,583 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:37:54,583 - root - INFO - Pretraining epochs: 150
2019-06-20 16:37:54,583 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:37:54,583 - root - INFO - Pretraining batch size: 200
2019-06-20 16:37:54,583 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:37:56,882 - root - INFO - Starting pretraining...
2019-06-20 17:05:11,280 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:05:11,280 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:05:11,280 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:05:11,280 - root - INFO - Dataset: hits
2019-06-20 17:05:11,280 - root - INFO - Normal class: 1
2019-06-20 17:05:11,280 - root - INFO - Network: mnist_LeNet
2019-06-20 17:05:11,280 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:05:11,280 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:05:11,317 - root - INFO - Computation device: cuda
2019-06-20 17:05:11,317 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:05:21,204 - root - INFO - Pretraining: True
2019-06-20 17:05:21,204 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:05:21,204 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:05:21,204 - root - INFO - Pretraining epochs: 150
2019-06-20 17:05:21,204 - root - INFO - Pretraining learning rate scheduler milestones: 50
2019-06-20 17:05:21,204 - root - INFO - Pretraining batch size: 200
2019-06-20 17:05:21,204 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:07:42,028 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:07:42,028 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:07:42,028 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:07:42,028 - root - INFO - Dataset: hits
2019-06-20 17:07:42,028 - root - INFO - Normal class: 1
2019-06-20 17:07:42,028 - root - INFO - Network: mnist_LeNet
2019-06-20 17:07:42,028 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:07:42,028 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:07:42,062 - root - INFO - Computation device: cuda
2019-06-20 17:07:42,062 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:07:51,850 - root - INFO - Pretraining: True
2019-06-20 17:07:51,850 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:07:51,850 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:07:51,850 - root - INFO - Pretraining epochs: 150
2019-06-20 17:07:51,850 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:07:51,850 - root - INFO - Pretraining batch size: 200
2019-06-20 17:07:51,850 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:07:53,932 - root - INFO - Starting pretraining...
2019-06-20 17:08:31,874 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:08:31,874 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:08:31,875 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:08:31,875 - root - INFO - Dataset: hits
2019-06-20 17:08:31,875 - root - INFO - Normal class: 1
2019-06-20 17:08:31,875 - root - INFO - Network: mnist_LeNet
2019-06-20 17:08:31,875 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:08:31,875 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:08:31,911 - root - INFO - Computation device: cuda
2019-06-20 17:08:31,911 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:08:41,747 - root - INFO - Pretraining: True
2019-06-20 17:08:41,747 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:08:41,747 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:08:41,747 - root - INFO - Pretraining epochs: 150
2019-06-20 17:08:41,747 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:08:41,747 - root - INFO - Pretraining batch size: 200
2019-06-20 17:08:41,747 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:08:43,824 - root - INFO - Starting pretraining...
2019-06-20 17:13:23,431 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:13:23,431 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:13:23,431 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:13:23,431 - root - INFO - Dataset: hits
2019-06-20 17:13:23,431 - root - INFO - Normal class: 1
2019-06-20 17:13:23,431 - root - INFO - Network: hits_LeNet
2019-06-20 17:13:23,431 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:13:23,431 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:13:23,467 - root - INFO - Computation device: cuda
2019-06-20 17:13:23,467 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:13:33,261 - root - INFO - Pretraining: True
2019-06-20 17:13:33,261 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:13:33,261 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:13:33,261 - root - INFO - Pretraining epochs: 150
2019-06-20 17:13:33,261 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:13:33,261 - root - INFO - Pretraining batch size: 200
2019-06-20 17:13:33,261 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:14:29,614 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:14:29,614 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:14:29,615 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:14:29,615 - root - INFO - Dataset: hits
2019-06-20 17:14:29,615 - root - INFO - Normal class: 1
2019-06-20 17:14:29,615 - root - INFO - Network: hits_LeNet
2019-06-20 17:14:29,615 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:14:29,615 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:14:29,649 - root - INFO - Computation device: cuda
2019-06-20 17:14:29,649 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:14:39,431 - root - INFO - Pretraining: True
2019-06-20 17:14:39,431 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:14:39,431 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:14:39,431 - root - INFO - Pretraining epochs: 150
2019-06-20 17:14:39,431 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:14:39,431 - root - INFO - Pretraining batch size: 200
2019-06-20 17:14:39,431 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:14:41,510 - root - INFO - Starting pretraining...
2019-06-20 17:16:21,853 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:16:21,854 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:16:21,854 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:16:21,854 - root - INFO - Dataset: hits
2019-06-20 17:16:21,854 - root - INFO - Normal class: 1
2019-06-20 17:16:21,854 - root - INFO - Network: hits_LeNet
2019-06-20 17:16:21,854 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:16:21,854 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:16:21,890 - root - INFO - Computation device: cuda
2019-06-20 17:16:21,890 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:16:31,630 - root - INFO - Pretraining: True
2019-06-20 17:16:31,630 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:16:31,630 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:16:31,631 - root - INFO - Pretraining epochs: 150
2019-06-20 17:16:31,631 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:16:31,631 - root - INFO - Pretraining batch size: 200
2019-06-20 17:16:31,631 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:16:33,707 - root - INFO - Starting pretraining...
2019-06-20 17:18:05,415 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:18:05,415 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:18:05,415 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:18:05,415 - root - INFO - Dataset: hits
2019-06-20 17:18:05,415 - root - INFO - Normal class: 1
2019-06-20 17:18:05,416 - root - INFO - Network: hits_LeNet
2019-06-20 17:18:05,416 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:18:05,416 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:18:05,452 - root - INFO - Computation device: cuda
2019-06-20 17:18:05,453 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:18:15,253 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:18:15,253 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:18:15,253 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:18:15,253 - root - INFO - Dataset: hits
2019-06-20 17:18:15,253 - root - INFO - Normal class: 1
2019-06-20 17:18:15,254 - root - INFO - Network: hits_LeNet
2019-06-20 17:18:15,254 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:18:15,254 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:18:15,293 - root - INFO - Computation device: cuda
2019-06-20 17:18:15,293 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:18:25,205 - root - INFO - Pretraining: True
2019-06-20 17:18:25,206 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:18:25,206 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:18:25,206 - root - INFO - Pretraining epochs: 150
2019-06-20 17:18:25,206 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:18:25,206 - root - INFO - Pretraining batch size: 200
2019-06-20 17:18:25,206 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:18:27,311 - root - INFO - Starting pretraining...
2019-06-20 17:22:20,915 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:22:20,915 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:22:20,915 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:22:20,915 - root - INFO - Dataset: hits
2019-06-20 17:22:20,915 - root - INFO - Normal class: 1
2019-06-20 17:22:20,915 - root - INFO - Network: hits_LeNet
2019-06-20 17:22:20,915 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:22:20,915 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:22:20,951 - root - INFO - Computation device: cuda
2019-06-20 17:22:20,952 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:22:30,970 - root - INFO - Pretraining: True
2019-06-20 17:22:30,970 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:22:30,970 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:22:30,970 - root - INFO - Pretraining epochs: 150
2019-06-20 17:22:30,970 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:22:30,970 - root - INFO - Pretraining batch size: 200
2019-06-20 17:22:30,970 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:22:33,067 - root - INFO - Starting pretraining...
2019-06-20 17:22:35,992 - root - INFO -   Epoch 1/150	 Time: 2.925	 Loss: 11.33173425
2019-06-20 17:22:38,654 - root - INFO -   Epoch 2/150	 Time: 2.661	 Loss: 7.48575881
2019-06-20 17:22:41,315 - root - INFO -   Epoch 3/150	 Time: 2.661	 Loss: 7.17361083
2019-06-20 17:22:43,971 - root - INFO -   Epoch 4/150	 Time: 2.656	 Loss: 7.03975483
2019-06-20 17:22:46,697 - root - INFO -   Epoch 5/150	 Time: 2.726	 Loss: 6.95310752
2019-06-20 17:22:49,424 - root - INFO -   Epoch 6/150	 Time: 2.726	 Loss: 6.89141204
2019-06-20 17:22:52,227 - root - INFO -   Epoch 7/150	 Time: 2.803	 Loss: 6.84585164
2019-06-20 17:22:55,050 - root - INFO -   Epoch 8/150	 Time: 2.823	 Loss: 6.80797648
2019-06-20 17:22:57,843 - root - INFO -   Epoch 9/150	 Time: 2.793	 Loss: 6.76440492
2019-06-20 17:23:01,192 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:23:01,192 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:23:01,192 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:23:01,192 - root - INFO - Dataset: hits
2019-06-20 17:23:01,192 - root - INFO - Normal class: 1
2019-06-20 17:23:01,192 - root - INFO - Network: hits_LeNet
2019-06-20 17:23:01,192 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:23:01,192 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:23:01,219 - root - INFO - Computation device: cuda
2019-06-20 17:23:01,220 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:23:11,047 - root - INFO - Pretraining: True
2019-06-20 17:23:11,047 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:23:11,047 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:23:11,047 - root - INFO - Pretraining epochs: 150
2019-06-20 17:23:11,047 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:23:11,047 - root - INFO - Pretraining batch size: 200
2019-06-20 17:23:11,047 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:23:13,162 - root - INFO - Starting pretraining...
2019-06-20 17:23:16,050 - root - INFO -   Epoch 1/150	 Time: 2.887	 Loss: 10.84813132
2019-06-20 17:23:18,727 - root - INFO -   Epoch 2/150	 Time: 2.677	 Loss: 7.61841553
2019-06-20 17:23:21,376 - root - INFO -   Epoch 3/150	 Time: 2.649	 Loss: 7.26817422
2019-06-20 17:23:24,014 - root - INFO -   Epoch 4/150	 Time: 2.637	 Loss: 7.10173927
2019-06-20 17:23:26,669 - root - INFO -   Epoch 5/150	 Time: 2.655	 Loss: 6.99342669
2019-06-20 17:23:29,383 - root - INFO -   Epoch 6/150	 Time: 2.714	 Loss: 6.90969832
2019-06-20 17:23:32,081 - root - INFO -   Epoch 7/150	 Time: 2.697	 Loss: 6.83642267
2019-06-20 17:23:34,725 - root - INFO -   Epoch 8/150	 Time: 2.644	 Loss: 6.77654856
2019-06-20 17:23:37,384 - root - INFO -   Epoch 9/150	 Time: 2.659	 Loss: 6.72785154
2019-06-20 17:23:40,056 - root - INFO -   Epoch 10/150	 Time: 2.672	 Loss: 6.68749217
2019-06-20 17:23:42,752 - root - INFO -   Epoch 11/150	 Time: 2.696	 Loss: 6.65747369
2019-06-20 17:23:45,500 - root - INFO -   Epoch 12/150	 Time: 2.748	 Loss: 6.63078036
2019-06-20 17:23:48,261 - root - INFO -   Epoch 13/150	 Time: 2.761	 Loss: 6.60749839
2019-06-20 17:23:50,952 - root - INFO -   Epoch 14/150	 Time: 2.691	 Loss: 6.58332027
2019-06-20 17:23:53,632 - root - INFO -   Epoch 15/150	 Time: 2.679	 Loss: 6.56512005
2019-06-20 17:23:56,391 - root - INFO -   Epoch 16/150	 Time: 2.759	 Loss: 6.53927390
2019-06-20 17:23:59,045 - root - INFO -   Epoch 17/150	 Time: 2.654	 Loss: 6.52859460
2019-06-20 17:24:01,712 - root - INFO -   Epoch 18/150	 Time: 2.667	 Loss: 6.50863774
2019-06-20 17:24:04,373 - root - INFO -   Epoch 19/150	 Time: 2.662	 Loss: 6.49756993
2019-06-20 17:24:07,026 - root - INFO -   Epoch 20/150	 Time: 2.653	 Loss: 6.48298678
2019-06-20 17:24:09,691 - root - INFO -   Epoch 21/150	 Time: 2.664	 Loss: 6.47297244
2019-06-20 17:24:12,365 - root - INFO -   Epoch 22/150	 Time: 2.674	 Loss: 6.45477151
2019-06-20 17:24:15,033 - root - INFO -   Epoch 23/150	 Time: 2.668	 Loss: 6.44558006
2019-06-20 17:24:17,760 - root - INFO -   Epoch 24/150	 Time: 2.726	 Loss: 6.43630643
2019-06-20 17:24:20,477 - root - INFO -   Epoch 25/150	 Time: 2.717	 Loss: 6.42849579
2019-06-20 17:24:23,162 - root - INFO -   Epoch 26/150	 Time: 2.685	 Loss: 6.41617077
2019-06-20 17:24:25,823 - root - INFO -   Epoch 27/150	 Time: 2.661	 Loss: 6.40695681
2019-06-20 17:24:28,512 - root - INFO -   Epoch 28/150	 Time: 2.689	 Loss: 6.40045967
2019-06-20 17:24:31,210 - root - INFO -   Epoch 29/150	 Time: 2.698	 Loss: 6.38870850
2019-06-20 17:24:33,882 - root - INFO -   Epoch 30/150	 Time: 2.672	 Loss: 6.38480808
2019-06-20 17:24:36,568 - root - INFO -   Epoch 31/150	 Time: 2.685	 Loss: 6.37211437
2019-06-20 17:24:39,245 - root - INFO -   Epoch 32/150	 Time: 2.677	 Loss: 6.36749736
2019-06-20 17:24:41,917 - root - INFO -   Epoch 33/150	 Time: 2.672	 Loss: 6.35869768
2019-06-20 17:24:44,602 - root - INFO -   Epoch 34/150	 Time: 2.685	 Loss: 6.35014580
2019-06-20 17:24:47,272 - root - INFO -   Epoch 35/150	 Time: 2.670	 Loss: 6.34388324
2019-06-20 17:24:49,941 - root - INFO -   Epoch 36/150	 Time: 2.669	 Loss: 6.34087182
2019-06-20 17:24:52,602 - root - INFO -   Epoch 37/150	 Time: 2.661	 Loss: 6.32995935
2019-06-20 17:24:55,278 - root - INFO -   Epoch 38/150	 Time: 2.676	 Loss: 6.32579105
2019-06-20 17:24:57,920 - root - INFO -   Epoch 39/150	 Time: 2.642	 Loss: 6.31995302
2019-06-20 17:25:00,553 - root - INFO -   Epoch 40/150	 Time: 2.633	 Loss: 6.31248970
2019-06-20 17:25:03,180 - root - INFO -   Epoch 41/150	 Time: 2.627	 Loss: 6.30549742
2019-06-20 17:25:05,827 - root - INFO -   Epoch 42/150	 Time: 2.647	 Loss: 6.30304794
2019-06-20 17:25:08,498 - root - INFO -   Epoch 43/150	 Time: 2.671	 Loss: 6.29661477
2019-06-20 17:25:11,155 - root - INFO -   Epoch 44/150	 Time: 2.657	 Loss: 6.29032967
2019-06-20 17:25:13,816 - root - INFO -   Epoch 45/150	 Time: 2.661	 Loss: 6.28211379
2019-06-20 17:25:16,488 - root - INFO -   Epoch 46/150	 Time: 2.672	 Loss: 6.28089020
2019-06-20 17:25:19,150 - root - INFO -   Epoch 47/150	 Time: 2.662	 Loss: 6.27510845
2019-06-20 17:25:21,829 - root - INFO -   Epoch 48/150	 Time: 2.678	 Loss: 6.27069571
2019-06-20 17:25:24,504 - root - INFO -   Epoch 49/150	 Time: 2.675	 Loss: 6.26801757
2019-06-20 17:25:27,209 - root - INFO -   Epoch 50/150	 Time: 2.705	 Loss: 6.25416291
2019-06-20 17:25:27,209 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:25:29,883 - root - INFO -   Epoch 51/150	 Time: 2.674	 Loss: 6.25371410
2019-06-20 17:25:32,545 - root - INFO -   Epoch 52/150	 Time: 2.662	 Loss: 6.25313416
2019-06-20 17:25:35,229 - root - INFO -   Epoch 53/150	 Time: 2.684	 Loss: 6.25409945
2019-06-20 17:25:37,907 - root - INFO -   Epoch 54/150	 Time: 2.678	 Loss: 6.25090052
2019-06-20 17:25:40,578 - root - INFO -   Epoch 55/150	 Time: 2.671	 Loss: 6.25340900
2019-06-20 17:25:43,246 - root - INFO -   Epoch 56/150	 Time: 2.668	 Loss: 6.25297152
2019-06-20 17:25:45,921 - root - INFO -   Epoch 57/150	 Time: 2.675	 Loss: 6.25571752
2019-06-20 17:25:48,596 - root - INFO -   Epoch 58/150	 Time: 2.674	 Loss: 6.24748438
2019-06-20 17:25:51,277 - root - INFO -   Epoch 59/150	 Time: 2.681	 Loss: 6.24935644
2019-06-20 17:25:53,938 - root - INFO -   Epoch 60/150	 Time: 2.661	 Loss: 6.24719246
2019-06-20 17:25:56,611 - root - INFO -   Epoch 61/150	 Time: 2.672	 Loss: 6.25014540
2019-06-20 17:25:59,272 - root - INFO -   Epoch 62/150	 Time: 2.661	 Loss: 6.24968274
2019-06-20 17:26:01,933 - root - INFO -   Epoch 63/150	 Time: 2.661	 Loss: 6.24658368
2019-06-20 17:26:04,588 - root - INFO -   Epoch 64/150	 Time: 2.655	 Loss: 6.24563253
2019-06-20 17:26:07,221 - root - INFO -   Epoch 65/150	 Time: 2.633	 Loss: 6.24454575
2019-06-20 17:26:09,876 - root - INFO -   Epoch 66/150	 Time: 2.655	 Loss: 6.24670084
2019-06-20 17:26:12,517 - root - INFO -   Epoch 67/150	 Time: 2.640	 Loss: 6.24335873
2019-06-20 17:26:15,162 - root - INFO -   Epoch 68/150	 Time: 2.645	 Loss: 6.24679689
2019-06-20 17:26:17,810 - root - INFO -   Epoch 69/150	 Time: 2.648	 Loss: 6.24628350
2019-06-20 17:26:20,450 - root - INFO -   Epoch 70/150	 Time: 2.639	 Loss: 6.24519099
2019-06-20 17:26:23,086 - root - INFO -   Epoch 71/150	 Time: 2.636	 Loss: 6.24123851
2019-06-20 17:26:25,746 - root - INFO -   Epoch 72/150	 Time: 2.660	 Loss: 6.24276576
2019-06-20 17:26:28,394 - root - INFO -   Epoch 73/150	 Time: 2.648	 Loss: 6.23968406
2019-06-20 17:26:31,045 - root - INFO -   Epoch 74/150	 Time: 2.650	 Loss: 6.24149112
2019-06-20 17:26:33,707 - root - INFO -   Epoch 75/150	 Time: 2.662	 Loss: 6.23818318
2019-06-20 17:26:36,368 - root - INFO -   Epoch 76/150	 Time: 2.661	 Loss: 6.23869417
2019-06-20 17:26:39,040 - root - INFO -   Epoch 77/150	 Time: 2.672	 Loss: 6.24123886
2019-06-20 17:26:41,720 - root - INFO -   Epoch 78/150	 Time: 2.680	 Loss: 6.23707017
2019-06-20 17:26:44,373 - root - INFO -   Epoch 79/150	 Time: 2.652	 Loss: 6.23989738
2019-06-20 17:26:47,025 - root - INFO -   Epoch 80/150	 Time: 2.652	 Loss: 6.23740589
2019-06-20 17:26:49,680 - root - INFO -   Epoch 81/150	 Time: 2.654	 Loss: 6.23736563
2019-06-20 17:26:52,346 - root - INFO -   Epoch 82/150	 Time: 2.666	 Loss: 6.23445263
2019-06-20 17:26:55,001 - root - INFO -   Epoch 83/150	 Time: 2.655	 Loss: 6.23801863
2019-06-20 17:26:57,671 - root - INFO -   Epoch 84/150	 Time: 2.670	 Loss: 6.23396498
2019-06-20 17:27:00,336 - root - INFO -   Epoch 85/150	 Time: 2.665	 Loss: 6.23277338
2019-06-20 17:27:02,994 - root - INFO -   Epoch 86/150	 Time: 2.658	 Loss: 6.23349955
2019-06-20 17:27:05,645 - root - INFO -   Epoch 87/150	 Time: 2.650	 Loss: 6.23360542
2019-06-20 17:27:08,308 - root - INFO -   Epoch 88/150	 Time: 2.663	 Loss: 6.23273732
2019-06-20 17:27:10,985 - root - INFO -   Epoch 89/150	 Time: 2.676	 Loss: 6.23048589
2019-06-20 17:27:13,651 - root - INFO -   Epoch 90/150	 Time: 2.666	 Loss: 6.23413318
2019-06-20 17:27:16,320 - root - INFO -   Epoch 91/150	 Time: 2.669	 Loss: 6.23633983
2019-06-20 17:27:18,999 - root - INFO -   Epoch 92/150	 Time: 2.678	 Loss: 6.23004717
2019-06-20 17:27:21,666 - root - INFO -   Epoch 93/150	 Time: 2.667	 Loss: 6.22696004
2019-06-20 17:27:24,348 - root - INFO -   Epoch 94/150	 Time: 2.682	 Loss: 6.23088403
2019-06-20 17:27:27,018 - root - INFO -   Epoch 95/150	 Time: 2.670	 Loss: 6.23109467
2019-06-20 17:27:29,683 - root - INFO -   Epoch 96/150	 Time: 2.664	 Loss: 6.22754872
2019-06-20 17:27:32,370 - root - INFO -   Epoch 97/150	 Time: 2.687	 Loss: 6.22814392
2019-06-20 17:27:35,022 - root - INFO -   Epoch 98/150	 Time: 2.652	 Loss: 6.22946106
2019-06-20 17:27:37,707 - root - INFO -   Epoch 99/150	 Time: 2.684	 Loss: 6.22829848
2019-06-20 17:27:40,395 - root - INFO -   Epoch 100/150	 Time: 2.689	 Loss: 6.22453388
2019-06-20 17:27:43,086 - root - INFO -   Epoch 101/150	 Time: 2.691	 Loss: 6.22621523
2019-06-20 17:27:45,775 - root - INFO -   Epoch 102/150	 Time: 2.688	 Loss: 6.22613408
2019-06-20 17:27:48,459 - root - INFO -   Epoch 103/150	 Time: 2.684	 Loss: 6.22247566
2019-06-20 17:27:51,122 - root - INFO -   Epoch 104/150	 Time: 2.664	 Loss: 6.22381806
2019-06-20 17:27:53,789 - root - INFO -   Epoch 105/150	 Time: 2.667	 Loss: 6.22403664
2019-06-20 17:27:56,469 - root - INFO -   Epoch 106/150	 Time: 2.680	 Loss: 6.22328102
2019-06-20 17:27:59,129 - root - INFO -   Epoch 107/150	 Time: 2.660	 Loss: 6.22334327
2019-06-20 17:28:01,775 - root - INFO -   Epoch 108/150	 Time: 2.646	 Loss: 6.22365144
2019-06-20 17:28:04,442 - root - INFO -   Epoch 109/150	 Time: 2.667	 Loss: 6.21962273
2019-06-20 17:28:07,111 - root - INFO -   Epoch 110/150	 Time: 2.669	 Loss: 6.22172706
2019-06-20 17:28:09,776 - root - INFO -   Epoch 111/150	 Time: 2.665	 Loss: 6.22072601
2019-06-20 17:28:12,447 - root - INFO -   Epoch 112/150	 Time: 2.671	 Loss: 6.21691472
2019-06-20 17:28:15,114 - root - INFO -   Epoch 113/150	 Time: 2.667	 Loss: 6.21989086
2019-06-20 17:28:17,766 - root - INFO -   Epoch 114/150	 Time: 2.652	 Loss: 6.22081116
2019-06-20 17:28:20,424 - root - INFO -   Epoch 115/150	 Time: 2.658	 Loss: 6.21943299
2019-06-20 17:28:23,084 - root - INFO -   Epoch 116/150	 Time: 2.660	 Loss: 6.21633579
2019-06-20 17:28:25,744 - root - INFO -   Epoch 117/150	 Time: 2.660	 Loss: 6.21901361
2019-06-20 17:28:28,417 - root - INFO -   Epoch 118/150	 Time: 2.672	 Loss: 6.21577363
2019-06-20 17:28:31,088 - root - INFO -   Epoch 119/150	 Time: 2.671	 Loss: 6.21767719
2019-06-20 17:28:33,747 - root - INFO -   Epoch 120/150	 Time: 2.659	 Loss: 6.21827010
2019-06-20 17:28:36,411 - root - INFO -   Epoch 121/150	 Time: 2.663	 Loss: 6.21262865
2019-06-20 17:28:39,080 - root - INFO -   Epoch 122/150	 Time: 2.669	 Loss: 6.21721333
2019-06-20 17:28:41,737 - root - INFO -   Epoch 123/150	 Time: 2.658	 Loss: 6.21527074
2019-06-20 17:28:44,386 - root - INFO -   Epoch 124/150	 Time: 2.649	 Loss: 6.21526268
2019-06-20 17:28:47,047 - root - INFO -   Epoch 125/150	 Time: 2.661	 Loss: 6.21477416
2019-06-20 17:28:49,719 - root - INFO -   Epoch 126/150	 Time: 2.671	 Loss: 6.21321654
2019-06-20 17:28:52,382 - root - INFO -   Epoch 127/150	 Time: 2.664	 Loss: 6.21155486
2019-06-20 17:28:55,042 - root - INFO -   Epoch 128/150	 Time: 2.659	 Loss: 6.21139448
2019-06-20 17:28:57,709 - root - INFO -   Epoch 129/150	 Time: 2.666	 Loss: 6.21424223
2019-06-20 17:29:00,375 - root - INFO -   Epoch 130/150	 Time: 2.666	 Loss: 6.21343072
2019-06-20 17:29:03,024 - root - INFO -   Epoch 131/150	 Time: 2.648	 Loss: 6.21441805
2019-06-20 17:29:05,679 - root - INFO -   Epoch 132/150	 Time: 2.655	 Loss: 6.20868341
2019-06-20 17:29:08,346 - root - INFO -   Epoch 133/150	 Time: 2.667	 Loss: 6.21045348
2019-06-20 17:29:10,992 - root - INFO -   Epoch 134/150	 Time: 2.646	 Loss: 6.20700185
2019-06-20 17:29:13,648 - root - INFO -   Epoch 135/150	 Time: 2.656	 Loss: 6.20732049
2019-06-20 17:29:16,317 - root - INFO -   Epoch 136/150	 Time: 2.669	 Loss: 6.20880803
2019-06-20 17:29:19,005 - root - INFO -   Epoch 137/150	 Time: 2.688	 Loss: 6.20740051
2019-06-20 17:29:21,658 - root - INFO -   Epoch 138/150	 Time: 2.653	 Loss: 6.20859655
2019-06-20 17:29:24,322 - root - INFO -   Epoch 139/150	 Time: 2.663	 Loss: 6.20533798
2019-06-20 17:29:26,977 - root - INFO -   Epoch 140/150	 Time: 2.655	 Loss: 6.20727367
2019-06-20 17:29:29,666 - root - INFO -   Epoch 141/150	 Time: 2.690	 Loss: 6.20759741
2019-06-20 17:29:32,323 - root - INFO -   Epoch 142/150	 Time: 2.657	 Loss: 6.20642353
2019-06-20 17:29:34,964 - root - INFO -   Epoch 143/150	 Time: 2.640	 Loss: 6.20452491
2019-06-20 17:29:37,609 - root - INFO -   Epoch 144/150	 Time: 2.646	 Loss: 6.20737433
2019-06-20 17:29:40,269 - root - INFO -   Epoch 145/150	 Time: 2.659	 Loss: 6.20689093
2019-06-20 17:29:42,938 - root - INFO -   Epoch 146/150	 Time: 2.669	 Loss: 6.20628634
2019-06-20 17:29:45,591 - root - INFO -   Epoch 147/150	 Time: 2.652	 Loss: 6.20370042
2019-06-20 17:29:48,301 - root - INFO -   Epoch 148/150	 Time: 2.710	 Loss: 6.20365078
2019-06-20 17:29:50,997 - root - INFO -   Epoch 149/150	 Time: 2.696	 Loss: 6.20189147
2019-06-20 17:29:53,696 - root - INFO -   Epoch 150/150	 Time: 2.698	 Loss: 6.20007428
2019-06-20 17:29:53,696 - root - INFO - Pretraining time: 400.533
2019-06-20 17:29:53,696 - root - INFO - Finished pretraining.
2019-06-20 17:29:53,696 - root - INFO - Testing autoencoder...
2019-06-20 17:29:55,020 - root - INFO - Test set Loss: 6.91779534
2019-06-20 17:29:55,093 - root - INFO - Test set AUC: 61.47%
2019-06-20 17:29:55,093 - root - INFO - Autoencoder testing time: 1.397
2019-06-20 17:29:55,093 - root - INFO - Finished testing autoencoder.
2019-06-20 17:29:55,097 - root - INFO - Training optimizer: adam
2019-06-20 17:29:55,097 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:29:55,097 - root - INFO - Training epochs: 150
2019-06-20 17:29:55,097 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:29:55,097 - root - INFO - Training batch size: 200
2019-06-20 17:29:55,097 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:29:55,098 - root - INFO - Initializing center c...
2019-06-20 17:29:56,173 - root - INFO - Center c initialized.
2019-06-20 17:29:56,173 - root - INFO - Starting training...
2019-06-20 17:29:57,955 - root - INFO -   Epoch 1/150	 Time: 1.782	 Loss: 0.30549915
2019-06-20 17:29:59,727 - root - INFO -   Epoch 2/150	 Time: 1.772	 Loss: 0.07961659
2019-06-20 17:30:01,502 - root - INFO -   Epoch 3/150	 Time: 1.775	 Loss: 0.04611896
2019-06-20 17:30:03,292 - root - INFO -   Epoch 4/150	 Time: 1.790	 Loss: 0.03178556
2019-06-20 17:30:05,068 - root - INFO -   Epoch 5/150	 Time: 1.776	 Loss: 0.02498519
2019-06-20 17:30:06,806 - root - INFO -   Epoch 6/150	 Time: 1.737	 Loss: 0.02041418
2019-06-20 17:30:08,563 - root - INFO -   Epoch 7/150	 Time: 1.757	 Loss: 0.01743753
2019-06-20 17:30:10,334 - root - INFO -   Epoch 8/150	 Time: 1.770	 Loss: 0.01526006
2019-06-20 17:30:12,096 - root - INFO -   Epoch 9/150	 Time: 1.762	 Loss: 0.01389805
2019-06-20 17:30:13,800 - root - INFO -   Epoch 10/150	 Time: 1.704	 Loss: 0.01252342
2019-06-20 17:30:15,505 - root - INFO -   Epoch 11/150	 Time: 1.705	 Loss: 0.01076636
2019-06-20 17:30:17,238 - root - INFO -   Epoch 12/150	 Time: 1.733	 Loss: 0.01009415
2019-06-20 17:30:19,009 - root - INFO -   Epoch 13/150	 Time: 1.771	 Loss: 0.00978986
2019-06-20 17:30:20,730 - root - INFO -   Epoch 14/150	 Time: 1.721	 Loss: 0.00885446
2019-06-20 17:30:22,499 - root - INFO -   Epoch 15/150	 Time: 1.768	 Loss: 0.00801055
2019-06-20 17:30:24,269 - root - INFO -   Epoch 16/150	 Time: 1.770	 Loss: 0.00753892
2019-06-20 17:30:26,046 - root - INFO -   Epoch 17/150	 Time: 1.777	 Loss: 0.00755593
2019-06-20 17:30:27,823 - root - INFO -   Epoch 18/150	 Time: 1.777	 Loss: 0.00677415
2019-06-20 17:30:29,595 - root - INFO -   Epoch 19/150	 Time: 1.772	 Loss: 0.00640596
2019-06-20 17:30:31,361 - root - INFO -   Epoch 20/150	 Time: 1.766	 Loss: 0.00586725
2019-06-20 17:30:33,142 - root - INFO -   Epoch 21/150	 Time: 1.781	 Loss: 0.00580289
2019-06-20 17:30:34,922 - root - INFO -   Epoch 22/150	 Time: 1.781	 Loss: 0.00558946
2019-06-20 17:30:36,664 - root - INFO -   Epoch 23/150	 Time: 1.742	 Loss: 0.00509255
2019-06-20 17:30:38,374 - root - INFO -   Epoch 24/150	 Time: 1.710	 Loss: 0.00500704
2019-06-20 17:30:40,083 - root - INFO -   Epoch 25/150	 Time: 1.709	 Loss: 0.00462297
2019-06-20 17:30:41,800 - root - INFO -   Epoch 26/150	 Time: 1.717	 Loss: 0.00462104
2019-06-20 17:30:43,510 - root - INFO -   Epoch 27/150	 Time: 1.709	 Loss: 0.00439633
2019-06-20 17:30:45,221 - root - INFO -   Epoch 28/150	 Time: 1.711	 Loss: 0.00405758
2019-06-20 17:30:46,931 - root - INFO -   Epoch 29/150	 Time: 1.710	 Loss: 0.00397697
2019-06-20 17:30:48,681 - root - INFO -   Epoch 30/150	 Time: 1.750	 Loss: 0.00379877
2019-06-20 17:30:50,452 - root - INFO -   Epoch 31/150	 Time: 1.770	 Loss: 0.00355004
2019-06-20 17:30:52,236 - root - INFO -   Epoch 32/150	 Time: 1.784	 Loss: 0.00352081
2019-06-20 17:30:54,024 - root - INFO -   Epoch 33/150	 Time: 1.788	 Loss: 0.00340578
2019-06-20 17:30:55,815 - root - INFO -   Epoch 34/150	 Time: 1.790	 Loss: 0.00306464
2019-06-20 17:30:57,623 - root - INFO -   Epoch 35/150	 Time: 1.808	 Loss: 0.00321168
2019-06-20 17:30:59,399 - root - INFO -   Epoch 36/150	 Time: 1.776	 Loss: 0.00305746
2019-06-20 17:31:01,175 - root - INFO -   Epoch 37/150	 Time: 1.776	 Loss: 0.00290725
2019-06-20 17:31:02,962 - root - INFO -   Epoch 38/150	 Time: 1.787	 Loss: 0.00277884
2019-06-20 17:31:04,768 - root - INFO -   Epoch 39/150	 Time: 1.806	 Loss: 0.00267590
2019-06-20 17:31:06,556 - root - INFO -   Epoch 40/150	 Time: 1.788	 Loss: 0.00265328
2019-06-20 17:31:08,342 - root - INFO -   Epoch 41/150	 Time: 1.786	 Loss: 0.00260603
2019-06-20 17:31:10,134 - root - INFO -   Epoch 42/150	 Time: 1.792	 Loss: 0.00252138
2019-06-20 17:31:11,908 - root - INFO -   Epoch 43/150	 Time: 1.774	 Loss: 0.00256313
2019-06-20 17:31:13,672 - root - INFO -   Epoch 44/150	 Time: 1.763	 Loss: 0.00235844
2019-06-20 17:31:15,396 - root - INFO -   Epoch 45/150	 Time: 1.724	 Loss: 0.00224947
2019-06-20 17:31:17,104 - root - INFO -   Epoch 46/150	 Time: 1.708	 Loss: 0.00213720
2019-06-20 17:31:18,815 - root - INFO -   Epoch 47/150	 Time: 1.711	 Loss: 0.00214175
2019-06-20 17:31:20,561 - root - INFO -   Epoch 48/150	 Time: 1.746	 Loss: 0.00210359
2019-06-20 17:31:22,339 - root - INFO -   Epoch 49/150	 Time: 1.778	 Loss: 0.00195310
2019-06-20 17:31:24,101 - root - INFO -   Epoch 50/150	 Time: 1.761	 Loss: 0.00165063
2019-06-20 17:31:24,101 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:31:25,864 - root - INFO -   Epoch 51/150	 Time: 1.763	 Loss: 0.00163284
2019-06-20 17:31:27,666 - root - INFO -   Epoch 52/150	 Time: 1.802	 Loss: 0.00162081
2019-06-20 17:31:29,454 - root - INFO -   Epoch 53/150	 Time: 1.787	 Loss: 0.00159821
2019-06-20 17:31:31,228 - root - INFO -   Epoch 54/150	 Time: 1.773	 Loss: 0.00162424
2019-06-20 17:31:33,011 - root - INFO -   Epoch 55/150	 Time: 1.783	 Loss: 0.00158176
2019-06-20 17:31:34,790 - root - INFO -   Epoch 56/150	 Time: 1.779	 Loss: 0.00161527
2019-06-20 17:31:36,570 - root - INFO -   Epoch 57/150	 Time: 1.780	 Loss: 0.00160477
2019-06-20 17:31:38,341 - root - INFO -   Epoch 58/150	 Time: 1.771	 Loss: 0.00155127
2019-06-20 17:31:40,118 - root - INFO -   Epoch 59/150	 Time: 1.777	 Loss: 0.00156906
2019-06-20 17:31:41,899 - root - INFO -   Epoch 60/150	 Time: 1.781	 Loss: 0.00161760
2019-06-20 17:31:43,616 - root - INFO -   Epoch 61/150	 Time: 1.717	 Loss: 0.00158331
2019-06-20 17:31:45,323 - root - INFO -   Epoch 62/150	 Time: 1.707	 Loss: 0.00161356
2019-06-20 17:31:47,040 - root - INFO -   Epoch 63/150	 Time: 1.717	 Loss: 0.00155017
2019-06-20 17:31:48,778 - root - INFO -   Epoch 64/150	 Time: 1.738	 Loss: 0.00159163
2019-06-20 17:31:50,564 - root - INFO -   Epoch 65/150	 Time: 1.786	 Loss: 0.00156328
2019-06-20 17:31:52,339 - root - INFO -   Epoch 66/150	 Time: 1.775	 Loss: 0.00151111
2019-06-20 17:31:54,115 - root - INFO -   Epoch 67/150	 Time: 1.776	 Loss: 0.00155014
2019-06-20 17:31:55,896 - root - INFO -   Epoch 68/150	 Time: 1.781	 Loss: 0.00150546
2019-06-20 17:31:57,670 - root - INFO -   Epoch 69/150	 Time: 1.773	 Loss: 0.00146955
2019-06-20 17:31:59,446 - root - INFO -   Epoch 70/150	 Time: 1.776	 Loss: 0.00147782
2019-06-20 17:32:01,236 - root - INFO -   Epoch 71/150	 Time: 1.790	 Loss: 0.00153610
2019-06-20 17:32:03,031 - root - INFO -   Epoch 72/150	 Time: 1.796	 Loss: 0.00153439
2019-06-20 17:32:04,817 - root - INFO -   Epoch 73/150	 Time: 1.786	 Loss: 0.00152867
2019-06-20 17:32:06,592 - root - INFO -   Epoch 74/150	 Time: 1.774	 Loss: 0.00148392
2019-06-20 17:32:08,363 - root - INFO -   Epoch 75/150	 Time: 1.771	 Loss: 0.00149349
2019-06-20 17:32:10,139 - root - INFO -   Epoch 76/150	 Time: 1.776	 Loss: 0.00150436
2019-06-20 17:32:11,909 - root - INFO -   Epoch 77/150	 Time: 1.770	 Loss: 0.00151377
2019-06-20 17:32:13,651 - root - INFO -   Epoch 78/150	 Time: 1.742	 Loss: 0.00145487
2019-06-20 17:32:15,366 - root - INFO -   Epoch 79/150	 Time: 1.715	 Loss: 0.00147057
2019-06-20 17:32:17,078 - root - INFO -   Epoch 80/150	 Time: 1.712	 Loss: 0.00144507
2019-06-20 17:32:18,788 - root - INFO -   Epoch 81/150	 Time: 1.709	 Loss: 0.00144851
2019-06-20 17:32:20,505 - root - INFO -   Epoch 82/150	 Time: 1.717	 Loss: 0.00144560
2019-06-20 17:32:22,238 - root - INFO -   Epoch 83/150	 Time: 1.733	 Loss: 0.00139252
2019-06-20 17:32:24,022 - root - INFO -   Epoch 84/150	 Time: 1.783	 Loss: 0.00137220
2019-06-20 17:32:25,811 - root - INFO -   Epoch 85/150	 Time: 1.790	 Loss: 0.00140130
2019-06-20 17:32:27,612 - root - INFO -   Epoch 86/150	 Time: 1.801	 Loss: 0.00141301
2019-06-20 17:32:29,397 - root - INFO -   Epoch 87/150	 Time: 1.784	 Loss: 0.00139266
2019-06-20 17:32:31,168 - root - INFO -   Epoch 88/150	 Time: 1.771	 Loss: 0.00142614
2019-06-20 17:32:32,926 - root - INFO -   Epoch 89/150	 Time: 1.758	 Loss: 0.00138370
2019-06-20 17:32:34,695 - root - INFO -   Epoch 90/150	 Time: 1.769	 Loss: 0.00141271
2019-06-20 17:32:36,434 - root - INFO -   Epoch 91/150	 Time: 1.739	 Loss: 0.00138904
2019-06-20 17:32:38,219 - root - INFO -   Epoch 92/150	 Time: 1.785	 Loss: 0.00137946
2019-06-20 17:32:40,004 - root - INFO -   Epoch 93/150	 Time: 1.784	 Loss: 0.00137353
2019-06-20 17:32:41,833 - root - INFO -   Epoch 94/150	 Time: 1.829	 Loss: 0.00141786
2019-06-20 17:32:43,645 - root - INFO -   Epoch 95/150	 Time: 1.812	 Loss: 0.00132232
2019-06-20 17:32:45,459 - root - INFO -   Epoch 96/150	 Time: 1.814	 Loss: 0.00135083
2019-06-20 17:32:47,270 - root - INFO -   Epoch 97/150	 Time: 1.810	 Loss: 0.00135456
2019-06-20 17:32:49,078 - root - INFO -   Epoch 98/150	 Time: 1.808	 Loss: 0.00134975
2019-06-20 17:32:50,869 - root - INFO -   Epoch 99/150	 Time: 1.791	 Loss: 0.00132467
2019-06-20 17:32:52,686 - root - INFO -   Epoch 100/150	 Time: 1.817	 Loss: 0.00132863
2019-06-20 17:32:54,471 - root - INFO -   Epoch 101/150	 Time: 1.784	 Loss: 0.00134698
2019-06-20 17:32:56,286 - root - INFO -   Epoch 102/150	 Time: 1.815	 Loss: 0.00130890
2019-06-20 17:32:58,099 - root - INFO -   Epoch 103/150	 Time: 1.813	 Loss: 0.00134472
2019-06-20 17:32:59,875 - root - INFO -   Epoch 104/150	 Time: 1.776	 Loss: 0.00131823
2019-06-20 17:33:01,664 - root - INFO -   Epoch 105/150	 Time: 1.789	 Loss: 0.00132456
2019-06-20 17:33:03,448 - root - INFO -   Epoch 106/150	 Time: 1.785	 Loss: 0.00130109
2019-06-20 17:33:05,235 - root - INFO -   Epoch 107/150	 Time: 1.787	 Loss: 0.00127746
2019-06-20 17:33:07,031 - root - INFO -   Epoch 108/150	 Time: 1.796	 Loss: 0.00124052
2019-06-20 17:33:08,845 - root - INFO -   Epoch 109/150	 Time: 1.814	 Loss: 0.00129026
2019-06-20 17:33:10,654 - root - INFO -   Epoch 110/150	 Time: 1.808	 Loss: 0.00128377
2019-06-20 17:33:12,478 - root - INFO -   Epoch 111/150	 Time: 1.825	 Loss: 0.00129167
2019-06-20 17:33:14,266 - root - INFO -   Epoch 112/150	 Time: 1.787	 Loss: 0.00125346
2019-06-20 17:33:16,055 - root - INFO -   Epoch 113/150	 Time: 1.789	 Loss: 0.00128441
2019-06-20 17:33:17,841 - root - INFO -   Epoch 114/150	 Time: 1.786	 Loss: 0.00126068
2019-06-20 17:33:19,654 - root - INFO -   Epoch 115/150	 Time: 1.813	 Loss: 0.00120740
2019-06-20 17:33:21,445 - root - INFO -   Epoch 116/150	 Time: 1.791	 Loss: 0.00119652
2019-06-20 17:33:23,247 - root - INFO -   Epoch 117/150	 Time: 1.802	 Loss: 0.00122446
2019-06-20 17:33:25,058 - root - INFO -   Epoch 118/150	 Time: 1.810	 Loss: 0.00122763
2019-06-20 17:33:26,877 - root - INFO -   Epoch 119/150	 Time: 1.819	 Loss: 0.00121931
2019-06-20 17:33:28,672 - root - INFO -   Epoch 120/150	 Time: 1.795	 Loss: 0.00120727
2019-06-20 17:33:30,418 - root - INFO -   Epoch 121/150	 Time: 1.746	 Loss: 0.00119510
2019-06-20 17:33:32,190 - root - INFO -   Epoch 122/150	 Time: 1.772	 Loss: 0.00123032
2019-06-20 17:33:33,984 - root - INFO -   Epoch 123/150	 Time: 1.793	 Loss: 0.00119412
2019-06-20 17:33:35,770 - root - INFO -   Epoch 124/150	 Time: 1.787	 Loss: 0.00117027
2019-06-20 17:33:37,564 - root - INFO -   Epoch 125/150	 Time: 1.793	 Loss: 0.00117659
2019-06-20 17:33:39,335 - root - INFO -   Epoch 126/150	 Time: 1.771	 Loss: 0.00120157
2019-06-20 17:33:41,062 - root - INFO -   Epoch 127/150	 Time: 1.727	 Loss: 0.00118976
2019-06-20 17:33:42,795 - root - INFO -   Epoch 128/150	 Time: 1.733	 Loss: 0.00116820
2019-06-20 17:33:44,523 - root - INFO -   Epoch 129/150	 Time: 1.728	 Loss: 0.00119829
2019-06-20 17:33:46,266 - root - INFO -   Epoch 130/150	 Time: 1.742	 Loss: 0.00116351
2019-06-20 17:33:48,060 - root - INFO -   Epoch 131/150	 Time: 1.794	 Loss: 0.00115290
2019-06-20 17:33:49,877 - root - INFO -   Epoch 132/150	 Time: 1.817	 Loss: 0.00114932
2019-06-20 17:33:51,660 - root - INFO -   Epoch 133/150	 Time: 1.783	 Loss: 0.00115407
2019-06-20 17:33:53,456 - root - INFO -   Epoch 134/150	 Time: 1.796	 Loss: 0.00112099
2019-06-20 17:33:55,246 - root - INFO -   Epoch 135/150	 Time: 1.789	 Loss: 0.00116200
2019-06-20 17:33:57,041 - root - INFO -   Epoch 136/150	 Time: 1.795	 Loss: 0.00111368
2019-06-20 17:33:58,828 - root - INFO -   Epoch 137/150	 Time: 1.786	 Loss: 0.00111804
2019-06-20 17:34:00,619 - root - INFO -   Epoch 138/150	 Time: 1.791	 Loss: 0.00114440
2019-06-20 17:34:02,420 - root - INFO -   Epoch 139/150	 Time: 1.801	 Loss: 0.00112799
2019-06-20 17:34:04,225 - root - INFO -   Epoch 140/150	 Time: 1.805	 Loss: 0.00110884
2019-06-20 17:34:06,051 - root - INFO -   Epoch 141/150	 Time: 1.826	 Loss: 0.00115527
2019-06-20 17:34:07,812 - root - INFO -   Epoch 142/150	 Time: 1.760	 Loss: 0.00111939
2019-06-20 17:34:09,642 - root - INFO -   Epoch 143/150	 Time: 1.830	 Loss: 0.00108965
2019-06-20 17:34:11,495 - root - INFO -   Epoch 144/150	 Time: 1.854	 Loss: 0.00108713
2019-06-20 17:34:13,297 - root - INFO -   Epoch 145/150	 Time: 1.801	 Loss: 0.00107175
2019-06-20 17:34:15,106 - root - INFO -   Epoch 146/150	 Time: 1.809	 Loss: 0.00108071
2019-06-20 17:34:16,876 - root - INFO -   Epoch 147/150	 Time: 1.770	 Loss: 0.00105417
2019-06-20 17:34:18,639 - root - INFO -   Epoch 148/150	 Time: 1.763	 Loss: 0.00113181
2019-06-20 17:34:20,446 - root - INFO -   Epoch 149/150	 Time: 1.806	 Loss: 0.00105171
2019-06-20 17:34:22,221 - root - INFO -   Epoch 150/150	 Time: 1.775	 Loss: 0.00105047
2019-06-20 17:34:22,221 - root - INFO - Training time: 266.047
2019-06-20 17:34:22,221 - root - INFO - Finished training.
2019-06-20 17:34:22,221 - root - INFO - Starting testing...
2019-06-20 17:34:23,197 - root - INFO - Testing time: 0.976
2019-06-20 17:34:23,266 - root - INFO - Test set AUC: 75.31%
2019-06-20 17:34:23,266 - root - INFO - Finished testing.
2019-06-20 17:37:26,151 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:37:26,151 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:37:26,151 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:37:26,151 - root - INFO - Dataset: hits
2019-06-20 17:37:26,151 - root - INFO - Normal class: 1
2019-06-20 17:37:26,151 - root - INFO - Network: hits_LeNet
2019-06-20 17:37:26,151 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:37:26,151 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:37:26,189 - root - INFO - Computation device: cuda
2019-06-20 17:37:26,189 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:37:36,067 - root - INFO - Pretraining: True
2019-06-20 17:37:36,068 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:37:36,068 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:37:36,068 - root - INFO - Pretraining epochs: 2
2019-06-20 17:37:36,068 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:37:36,068 - root - INFO - Pretraining batch size: 200
2019-06-20 17:37:36,068 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:37:38,154 - root - INFO - Starting pretraining...
2019-06-20 17:37:41,398 - root - INFO -   Epoch 1/2	 Time: 3.244	 Loss: 14.55410245
2019-06-20 17:37:44,375 - root - INFO -   Epoch 2/2	 Time: 2.976	 Loss: 8.22712424
2019-06-20 17:37:44,375 - root - INFO - Pretraining time: 6.220
2019-06-20 17:37:44,375 - root - INFO - Finished pretraining.
2019-06-20 17:37:44,375 - root - INFO - Testing autoencoder...
2019-06-20 17:37:46,181 - root - INFO - Test set Loss: 10.73809366
2019-06-20 17:37:46,251 - root - INFO - Test set AUC: 81.80%
2019-06-20 17:37:46,251 - root - INFO - Autoencoder testing time: 1.876
2019-06-20 17:37:46,251 - root - INFO - Finished testing autoencoder.
2019-06-20 17:37:46,255 - root - INFO - Training optimizer: adam
2019-06-20 17:37:46,256 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:37:46,256 - root - INFO - Training epochs: 2
2019-06-20 17:37:46,256 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:37:46,256 - root - INFO - Training batch size: 200
2019-06-20 17:37:46,256 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:37:46,256 - root - INFO - Initializing center c...
2019-06-20 17:37:47,711 - root - INFO - Center c initialized.
2019-06-20 17:37:47,712 - root - INFO - Starting training...
2019-06-20 17:37:49,788 - root - INFO -   Epoch 1/2	 Time: 2.076	 Loss: 0.91618391
2019-06-20 17:37:51,838 - root - INFO -   Epoch 2/2	 Time: 2.049	 Loss: 0.18287016
2019-06-20 17:37:51,838 - root - INFO - Training time: 4.126
2019-06-20 17:37:51,838 - root - INFO - Finished training.
2019-06-20 17:37:51,838 - root - INFO - Starting testing...
2019-06-20 17:37:53,297 - root - INFO - Testing time: 1.459
2019-06-20 17:37:53,367 - root - INFO - Test set AUC: 91.89%
2019-06-20 17:37:53,367 - root - INFO - Finished testing.
2019-06-20 17:39:58,781 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:39:58,781 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:39:58,781 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:39:58,781 - root - INFO - Dataset: hits
2019-06-20 17:39:58,781 - root - INFO - Normal class: 1
2019-06-20 17:39:58,781 - root - INFO - Network: hits_LeNet
2019-06-20 17:39:58,782 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:39:58,782 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:39:58,818 - root - INFO - Computation device: cuda
2019-06-20 17:39:58,818 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:40:08,680 - root - INFO - Pretraining: True
2019-06-20 17:40:08,680 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:40:08,680 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:40:08,680 - root - INFO - Pretraining epochs: 2
2019-06-20 17:40:08,680 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:40:08,680 - root - INFO - Pretraining batch size: 200
2019-06-20 17:40:08,680 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:40:10,816 - root - INFO - Starting pretraining...
2019-06-20 17:40:14,048 - root - INFO -   Epoch 1/2	 Time: 3.232	 Loss: 11.98258979
2019-06-20 17:40:17,071 - root - INFO -   Epoch 2/2	 Time: 3.023	 Loss: 7.88343131
2019-06-20 17:40:17,071 - root - INFO - Pretraining time: 6.255
2019-06-20 17:40:17,071 - root - INFO - Finished pretraining.
2019-06-20 17:40:17,072 - root - INFO - Testing autoencoder...
2019-06-20 17:40:18,929 - root - INFO - Test set Loss: 9.90700213
2019-06-20 17:40:19,000 - root - INFO - Test set AUC: 76.81%
2019-06-20 17:40:19,000 - root - INFO - Autoencoder testing time: 1.928
2019-06-20 17:40:19,000 - root - INFO - Finished testing autoencoder.
2019-06-20 17:40:19,004 - root - INFO - Training optimizer: adam
2019-06-20 17:40:19,004 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:40:19,004 - root - INFO - Training epochs: 2
2019-06-20 17:40:19,004 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:40:19,004 - root - INFO - Training batch size: 200
2019-06-20 17:40:19,004 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:40:19,004 - root - INFO - Initializing center c...
2019-06-20 17:40:20,476 - root - INFO - Center c initialized.
2019-06-20 17:40:20,476 - root - INFO - Starting training...
2019-06-20 17:40:22,536 - root - INFO -   Epoch 1/2	 Time: 2.060	 Loss: 0.81412385
2019-06-20 17:40:24,614 - root - INFO -   Epoch 2/2	 Time: 2.077	 Loss: 0.14985813
2019-06-20 17:40:24,614 - root - INFO - Training time: 4.138
2019-06-20 17:40:24,614 - root - INFO - Finished training.
2019-06-20 17:40:24,614 - root - INFO - Starting testing...
2019-06-20 17:40:26,107 - root - INFO - Testing time: 1.492
2019-06-20 17:40:26,178 - root - INFO - Test set AUC: 93.69%
2019-06-20 17:40:26,178 - root - INFO - Finished testing.
2019-06-20 17:42:25,667 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:42:25,667 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:42:25,667 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:42:25,667 - root - INFO - Dataset: hits
2019-06-20 17:42:25,667 - root - INFO - Normal class: 1
2019-06-20 17:42:25,667 - root - INFO - Network: hits_LeNet
2019-06-20 17:42:25,667 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:42:25,667 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:42:25,705 - root - INFO - Computation device: cuda
2019-06-20 17:42:25,705 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:42:35,587 - root - INFO - Pretraining: True
2019-06-20 17:42:35,587 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:42:35,587 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:42:35,587 - root - INFO - Pretraining epochs: 2
2019-06-20 17:42:35,587 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:42:35,588 - root - INFO - Pretraining batch size: 200
2019-06-20 17:42:35,588 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:42:37,678 - root - INFO - Starting pretraining...
2019-06-20 17:42:40,922 - root - INFO -   Epoch 1/2	 Time: 3.244	 Loss: 9.96876604
2019-06-20 17:42:43,934 - root - INFO -   Epoch 2/2	 Time: 3.012	 Loss: 7.44697237
2019-06-20 17:42:43,934 - root - INFO - Pretraining time: 6.256
2019-06-20 17:42:43,934 - root - INFO - Finished pretraining.
2019-06-20 17:42:43,935 - root - INFO - Testing autoencoder...
2019-06-20 17:42:45,773 - root - INFO - Test set Loss: 9.17358697
2019-06-20 17:42:45,844 - root - INFO - Test set AUC: 74.12%
2019-06-20 17:42:45,844 - root - INFO - Autoencoder testing time: 1.910
2019-06-20 17:42:45,844 - root - INFO - Finished testing autoencoder.
2019-06-20 17:42:45,848 - root - INFO - Training optimizer: adam
2019-06-20 17:42:45,848 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:42:45,848 - root - INFO - Training epochs: 2
2019-06-20 17:42:45,848 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:42:45,848 - root - INFO - Training batch size: 200
2019-06-20 17:42:45,848 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:42:45,849 - root - INFO - Initializing center c...
2019-06-20 17:42:47,290 - root - INFO - Center c initialized.
2019-06-20 17:42:47,290 - root - INFO - Starting training...
2019-06-20 17:42:49,352 - root - INFO -   Epoch 1/2	 Time: 2.061	 Loss: 0.56879167
2019-06-20 17:42:51,408 - root - INFO -   Epoch 2/2	 Time: 2.056	 Loss: 0.12290905
2019-06-20 17:42:51,408 - root - INFO - Training time: 4.118
2019-06-20 17:42:51,408 - root - INFO - Finished training.
2019-06-20 17:42:51,409 - root - INFO - Starting testing...
2019-06-20 17:42:52,896 - root - INFO - Testing time: 1.487
2019-06-20 17:42:52,966 - root - INFO - Test set AUC: 92.38%
2019-06-20 17:42:52,966 - root - INFO - Finished testing.
2019-06-20 17:43:51,483 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:43:51,484 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:43:51,484 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:43:51,484 - root - INFO - Dataset: hits
2019-06-20 17:43:51,484 - root - INFO - Normal class: 1
2019-06-20 17:43:51,484 - root - INFO - Network: hits_LeNet
2019-06-20 17:43:51,484 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:43:51,484 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:43:51,519 - root - INFO - Computation device: cuda
2019-06-20 17:43:51,519 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:44:01,451 - root - INFO - Pretraining: True
2019-06-20 17:44:01,451 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:44:01,451 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:44:01,451 - root - INFO - Pretraining epochs: 2
2019-06-20 17:44:01,451 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:44:01,451 - root - INFO - Pretraining batch size: 200
2019-06-20 17:44:01,451 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:44:03,551 - root - INFO - Starting pretraining...
2019-06-20 17:44:06,799 - root - INFO -   Epoch 1/2	 Time: 3.248	 Loss: 10.77849464
2019-06-20 17:44:09,825 - root - INFO -   Epoch 2/2	 Time: 3.026	 Loss: 7.63928155
2019-06-20 17:44:09,825 - root - INFO - Pretraining time: 6.275
2019-06-20 17:44:09,825 - root - INFO - Finished pretraining.
2019-06-20 17:44:09,826 - root - INFO - Testing autoencoder...
2019-06-20 17:44:11,634 - root - INFO - Test set Loss: 9.31854469
2019-06-20 17:44:11,705 - root - INFO - Test set AUC: 75.12%
2019-06-20 17:44:11,705 - root - INFO - Autoencoder testing time: 1.879
2019-06-20 17:44:11,705 - root - INFO - Finished testing autoencoder.
2019-06-20 17:44:11,709 - root - INFO - Training optimizer: adam
2019-06-20 17:44:11,709 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:44:11,709 - root - INFO - Training epochs: 2
2019-06-20 17:44:11,709 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:44:11,709 - root - INFO - Training batch size: 200
2019-06-20 17:44:11,709 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:44:11,710 - root - INFO - Initializing center c...
2019-06-20 17:44:13,133 - root - INFO - Center c initialized.
2019-06-20 17:44:13,133 - root - INFO - Starting training...
2019-06-20 17:44:15,279 - root - INFO -   Epoch 1/2	 Time: 2.146	 Loss: 0.62023142
2019-06-20 17:44:17,340 - root - INFO -   Epoch 2/2	 Time: 2.061	 Loss: 0.14132732
2019-06-20 17:44:17,340 - root - INFO - Training time: 4.207
2019-06-20 17:44:17,340 - root - INFO - Finished training.
2019-06-20 17:44:17,341 - root - INFO - Starting testing...
2019-06-20 17:44:18,807 - root - INFO - Testing time: 1.466
2019-06-20 17:44:18,877 - root - INFO - Test set AUC: 91.98%
2019-06-20 17:44:18,877 - root - INFO - Finished testing.
2019-06-20 17:44:54,669 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:44:54,669 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:44:54,669 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:44:54,669 - root - INFO - Dataset: hits
2019-06-20 17:44:54,669 - root - INFO - Normal class: 1
2019-06-20 17:44:54,669 - root - INFO - Network: hits_LeNet
2019-06-20 17:44:54,669 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:44:54,669 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:44:54,704 - root - INFO - Computation device: cuda
2019-06-20 17:44:54,705 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:45:04,557 - root - INFO - Pretraining: True
2019-06-20 17:45:04,557 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:45:04,557 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:45:04,557 - root - INFO - Pretraining epochs: 2
2019-06-20 17:45:04,557 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:45:04,557 - root - INFO - Pretraining batch size: 200
2019-06-20 17:45:04,558 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:45:06,635 - root - INFO - Starting pretraining...
2019-06-20 17:45:09,880 - root - INFO -   Epoch 1/2	 Time: 3.245	 Loss: 9.78301325
2019-06-20 17:45:12,897 - root - INFO -   Epoch 2/2	 Time: 3.017	 Loss: 7.38386713
2019-06-20 17:45:12,897 - root - INFO - Pretraining time: 6.262
2019-06-20 17:45:12,897 - root - INFO - Finished pretraining.
2019-06-20 17:45:12,898 - root - INFO - Testing autoencoder...
2019-06-20 17:45:14,741 - root - INFO - Test set Loss: 9.15403120
2019-06-20 17:45:14,812 - root - INFO - Test set AUC: 73.55%
2019-06-20 17:45:14,812 - root - INFO - Autoencoder testing time: 1.914
2019-06-20 17:45:14,812 - root - INFO - Finished testing autoencoder.
2019-06-20 17:45:14,816 - root - INFO - Training optimizer: adam
2019-06-20 17:45:14,816 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:45:14,816 - root - INFO - Training epochs: 2
2019-06-20 17:45:14,816 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:45:14,816 - root - INFO - Training batch size: 200
2019-06-20 17:45:14,816 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:45:14,817 - root - INFO - Initializing center c...
2019-06-20 17:45:16,273 - root - INFO - Center c initialized.
2019-06-20 17:45:16,273 - root - INFO - Starting training...
2019-06-20 17:45:18,333 - root - INFO -   Epoch 1/2	 Time: 2.060	 Loss: 0.55296865
2019-06-20 17:45:20,398 - root - INFO -   Epoch 2/2	 Time: 2.065	 Loss: 0.12050932
2019-06-20 17:45:20,398 - root - INFO - Training time: 4.126
2019-06-20 17:45:20,398 - root - INFO - Finished training.
2019-06-20 17:45:20,399 - root - INFO - Starting testing...
2019-06-20 17:45:21,888 - root - INFO - Testing time: 1.489
2019-06-20 17:45:21,959 - root - INFO - Test set AUC: 89.55%
2019-06-20 17:45:21,959 - root - INFO - Finished testing.
2019-06-20 17:47:44,336 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:47:44,336 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:47:44,336 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:47:44,336 - root - INFO - Dataset: hits
2019-06-20 17:47:44,336 - root - INFO - Normal class: 1
2019-06-20 17:47:44,336 - root - INFO - Network: hits_LeNet
2019-06-20 17:47:44,336 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:47:44,336 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:47:44,371 - root - INFO - Computation device: cuda
2019-06-20 17:47:44,372 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:47:54,296 - root - INFO - Pretraining: True
2019-06-20 17:47:54,296 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:47:54,296 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:47:54,296 - root - INFO - Pretraining epochs: 150
2019-06-20 17:47:54,296 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:47:54,296 - root - INFO - Pretraining batch size: 200
2019-06-20 17:47:54,296 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:47:56,384 - root - INFO - Starting pretraining...
2019-06-20 17:47:59,602 - root - INFO -   Epoch 1/150	 Time: 3.218	 Loss: 10.96036076
2019-06-20 17:48:02,596 - root - INFO -   Epoch 2/150	 Time: 2.994	 Loss: 7.57195216
2019-06-20 17:48:05,604 - root - INFO -   Epoch 3/150	 Time: 3.007	 Loss: 7.22401037
2019-06-20 17:48:08,590 - root - INFO -   Epoch 4/150	 Time: 2.986	 Loss: 7.05673695
2019-06-20 17:48:11,596 - root - INFO -   Epoch 5/150	 Time: 3.006	 Loss: 6.95665355
2019-06-20 17:48:14,573 - root - INFO -   Epoch 6/150	 Time: 2.976	 Loss: 6.88093352
2019-06-20 17:48:17,583 - root - INFO -   Epoch 7/150	 Time: 3.010	 Loss: 6.82540081
2019-06-20 17:48:20,541 - root - INFO -   Epoch 8/150	 Time: 2.958	 Loss: 6.77073026
2019-06-20 17:48:23,548 - root - INFO -   Epoch 9/150	 Time: 3.006	 Loss: 6.72421800
2019-06-20 17:48:26,515 - root - INFO -   Epoch 10/150	 Time: 2.967	 Loss: 6.68699269
2019-06-20 17:48:29,503 - root - INFO -   Epoch 11/150	 Time: 2.988	 Loss: 6.64374182
2019-06-20 17:48:32,474 - root - INFO -   Epoch 12/150	 Time: 2.971	 Loss: 6.61168104
2019-06-20 17:48:35,466 - root - INFO -   Epoch 13/150	 Time: 2.991	 Loss: 6.58263281
2019-06-20 17:48:38,449 - root - INFO -   Epoch 14/150	 Time: 2.983	 Loss: 6.56075949
2019-06-20 17:48:41,440 - root - INFO -   Epoch 15/150	 Time: 2.991	 Loss: 6.53560044
2019-06-20 17:48:44,518 - root - INFO -   Epoch 16/150	 Time: 3.077	 Loss: 6.52014546
2019-06-20 17:48:47,517 - root - INFO -   Epoch 17/150	 Time: 2.999	 Loss: 6.50182996
2019-06-20 17:48:50,525 - root - INFO -   Epoch 18/150	 Time: 3.008	 Loss: 6.48389193
2019-06-20 17:48:53,529 - root - INFO -   Epoch 19/150	 Time: 3.004	 Loss: 6.47167795
2019-06-20 17:48:56,493 - root - INFO -   Epoch 20/150	 Time: 2.964	 Loss: 6.46368330
2019-06-20 17:48:59,458 - root - INFO -   Epoch 21/150	 Time: 2.965	 Loss: 6.44533823
2019-06-20 17:49:02,435 - root - INFO -   Epoch 22/150	 Time: 2.977	 Loss: 6.43411785
2019-06-20 17:49:05,474 - root - INFO -   Epoch 23/150	 Time: 3.038	 Loss: 6.42180299
2019-06-20 17:49:08,483 - root - INFO -   Epoch 24/150	 Time: 3.009	 Loss: 6.41001554
2019-06-20 17:49:11,464 - root - INFO -   Epoch 25/150	 Time: 2.981	 Loss: 6.40343632
2019-06-20 17:49:14,425 - root - INFO -   Epoch 26/150	 Time: 2.961	 Loss: 6.39495918
2019-06-20 17:49:17,410 - root - INFO -   Epoch 27/150	 Time: 2.985	 Loss: 6.38143938
2019-06-20 17:49:20,429 - root - INFO -   Epoch 28/150	 Time: 3.019	 Loss: 6.37343210
2019-06-20 17:49:23,405 - root - INFO -   Epoch 29/150	 Time: 2.975	 Loss: 6.36879019
2019-06-20 17:49:26,397 - root - INFO -   Epoch 30/150	 Time: 2.992	 Loss: 6.36047093
2019-06-20 17:49:29,388 - root - INFO -   Epoch 31/150	 Time: 2.991	 Loss: 6.35366426
2019-06-20 17:49:32,405 - root - INFO -   Epoch 32/150	 Time: 3.016	 Loss: 6.34668343
2019-06-20 17:49:35,401 - root - INFO -   Epoch 33/150	 Time: 2.996	 Loss: 6.34223263
2019-06-20 17:49:38,377 - root - INFO -   Epoch 34/150	 Time: 2.976	 Loss: 6.33498974
2019-06-20 17:49:41,378 - root - INFO -   Epoch 35/150	 Time: 3.001	 Loss: 6.33044595
2019-06-20 17:49:44,354 - root - INFO -   Epoch 36/150	 Time: 2.975	 Loss: 6.32661851
2019-06-20 17:49:47,376 - root - INFO -   Epoch 37/150	 Time: 3.022	 Loss: 6.32264344
2019-06-20 17:49:50,366 - root - INFO -   Epoch 38/150	 Time: 2.990	 Loss: 6.31665776
2019-06-20 17:49:53,385 - root - INFO -   Epoch 39/150	 Time: 3.018	 Loss: 6.31464158
2019-06-20 17:49:56,390 - root - INFO -   Epoch 40/150	 Time: 3.005	 Loss: 6.30649902
2019-06-20 17:49:59,404 - root - INFO -   Epoch 41/150	 Time: 3.014	 Loss: 6.30345398
2019-06-20 17:50:02,404 - root - INFO -   Epoch 42/150	 Time: 3.000	 Loss: 6.29688850
2019-06-20 17:50:05,480 - root - INFO -   Epoch 43/150	 Time: 3.075	 Loss: 6.29288064
2019-06-20 17:50:08,507 - root - INFO -   Epoch 44/150	 Time: 3.027	 Loss: 6.28843697
2019-06-20 17:50:11,522 - root - INFO -   Epoch 45/150	 Time: 3.015	 Loss: 6.28605066
2019-06-20 17:50:14,638 - root - INFO -   Epoch 46/150	 Time: 3.116	 Loss: 6.28524171
2019-06-20 17:50:17,751 - root - INFO -   Epoch 47/150	 Time: 3.112	 Loss: 6.28036864
2019-06-20 17:50:20,776 - root - INFO -   Epoch 48/150	 Time: 3.026	 Loss: 6.27663287
2019-06-20 17:50:23,859 - root - INFO -   Epoch 49/150	 Time: 3.082	 Loss: 6.27210133
2019-06-20 17:50:26,887 - root - INFO -   Epoch 50/150	 Time: 3.028	 Loss: 6.26715455
2019-06-20 17:50:26,888 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:50:29,924 - root - INFO -   Epoch 51/150	 Time: 3.036	 Loss: 6.26479727
2019-06-20 17:50:32,979 - root - INFO -   Epoch 52/150	 Time: 3.055	 Loss: 6.26518513
2019-06-20 17:50:36,028 - root - INFO -   Epoch 53/150	 Time: 3.049	 Loss: 6.26423376
2019-06-20 17:50:39,063 - root - INFO -   Epoch 54/150	 Time: 3.035	 Loss: 6.26485502
2019-06-20 17:50:42,113 - root - INFO -   Epoch 55/150	 Time: 3.050	 Loss: 6.26507266
2019-06-20 17:50:45,199 - root - INFO -   Epoch 56/150	 Time: 3.086	 Loss: 6.26599734
2019-06-20 17:50:48,247 - root - INFO -   Epoch 57/150	 Time: 3.047	 Loss: 6.26495138
2019-06-20 17:50:51,335 - root - INFO -   Epoch 58/150	 Time: 3.088	 Loss: 6.26301161
2019-06-20 17:50:54,382 - root - INFO -   Epoch 59/150	 Time: 3.047	 Loss: 6.26309533
2019-06-20 17:50:57,397 - root - INFO -   Epoch 60/150	 Time: 3.014	 Loss: 6.26460581
2019-06-20 17:51:00,445 - root - INFO -   Epoch 61/150	 Time: 3.048	 Loss: 6.26098878
2019-06-20 17:51:03,496 - root - INFO -   Epoch 62/150	 Time: 3.051	 Loss: 6.26435303
2019-06-20 17:51:06,562 - root - INFO -   Epoch 63/150	 Time: 3.066	 Loss: 6.26441282
2019-06-20 17:51:09,623 - root - INFO -   Epoch 64/150	 Time: 3.061	 Loss: 6.26118788
2019-06-20 17:51:12,730 - root - INFO -   Epoch 65/150	 Time: 3.106	 Loss: 6.26170778
2019-06-20 17:51:15,774 - root - INFO -   Epoch 66/150	 Time: 3.044	 Loss: 6.26056741
2019-06-20 17:51:18,812 - root - INFO -   Epoch 67/150	 Time: 3.038	 Loss: 6.26186917
2019-06-20 17:51:21,857 - root - INFO -   Epoch 68/150	 Time: 3.045	 Loss: 6.25944569
2019-06-20 17:51:24,888 - root - INFO -   Epoch 69/150	 Time: 3.030	 Loss: 6.26156627
2019-06-20 17:51:27,902 - root - INFO -   Epoch 70/150	 Time: 3.014	 Loss: 6.26004454
2019-06-20 17:51:30,930 - root - INFO -   Epoch 71/150	 Time: 3.028	 Loss: 6.26035032
2019-06-20 17:51:33,948 - root - INFO -   Epoch 72/150	 Time: 3.017	 Loss: 6.25774589
2019-06-20 17:51:37,002 - root - INFO -   Epoch 73/150	 Time: 3.053	 Loss: 6.25631467
2019-06-20 17:51:40,045 - root - INFO -   Epoch 74/150	 Time: 3.043	 Loss: 6.25695519
2019-06-20 17:51:43,126 - root - INFO -   Epoch 75/150	 Time: 3.082	 Loss: 6.25972166
2019-06-20 17:51:46,137 - root - INFO -   Epoch 76/150	 Time: 3.010	 Loss: 6.25630420
2019-06-20 17:51:49,219 - root - INFO -   Epoch 77/150	 Time: 3.082	 Loss: 6.25675753
2019-06-20 17:51:52,276 - root - INFO -   Epoch 78/150	 Time: 3.057	 Loss: 6.25400395
2019-06-20 17:51:55,300 - root - INFO -   Epoch 79/150	 Time: 3.024	 Loss: 6.25427469
2019-06-20 17:51:58,300 - root - INFO -   Epoch 80/150	 Time: 3.000	 Loss: 6.25506653
2019-06-20 17:52:01,304 - root - INFO -   Epoch 81/150	 Time: 3.004	 Loss: 6.25337676
2019-06-20 17:52:04,287 - root - INFO -   Epoch 82/150	 Time: 2.983	 Loss: 6.25449513
2019-06-20 17:52:07,279 - root - INFO -   Epoch 83/150	 Time: 2.991	 Loss: 6.25346565
2019-06-20 17:52:10,316 - root - INFO -   Epoch 84/150	 Time: 3.037	 Loss: 6.25270229
2019-06-20 17:52:13,317 - root - INFO -   Epoch 85/150	 Time: 3.001	 Loss: 6.25109933
2019-06-20 17:52:16,311 - root - INFO -   Epoch 86/150	 Time: 2.993	 Loss: 6.25173321
2019-06-20 17:52:19,313 - root - INFO -   Epoch 87/150	 Time: 3.002	 Loss: 6.25183058
2019-06-20 17:52:22,313 - root - INFO -   Epoch 88/150	 Time: 2.999	 Loss: 6.25232123
2019-06-20 17:52:25,322 - root - INFO -   Epoch 89/150	 Time: 3.009	 Loss: 6.25259536
2019-06-20 17:52:28,322 - root - INFO -   Epoch 90/150	 Time: 3.000	 Loss: 6.25206949
2019-06-20 17:52:31,346 - root - INFO -   Epoch 91/150	 Time: 3.023	 Loss: 6.25073677
2019-06-20 17:52:34,366 - root - INFO -   Epoch 92/150	 Time: 3.020	 Loss: 6.25026184
2019-06-20 17:52:37,350 - root - INFO -   Epoch 93/150	 Time: 2.984	 Loss: 6.24940509
2019-06-20 17:52:40,370 - root - INFO -   Epoch 94/150	 Time: 3.019	 Loss: 6.24769692
2019-06-20 17:52:43,362 - root - INFO -   Epoch 95/150	 Time: 2.992	 Loss: 6.24830864
2019-06-20 17:52:46,365 - root - INFO -   Epoch 96/150	 Time: 3.002	 Loss: 6.24650805
2019-06-20 17:52:49,350 - root - INFO -   Epoch 97/150	 Time: 2.985	 Loss: 6.24940529
2019-06-20 17:52:52,354 - root - INFO -   Epoch 98/150	 Time: 3.004	 Loss: 6.24727135
2019-06-20 17:52:55,345 - root - INFO -   Epoch 99/150	 Time: 2.991	 Loss: 6.24573993
2019-06-20 17:52:58,353 - root - INFO -   Epoch 100/150	 Time: 3.008	 Loss: 6.24642082
2019-06-20 17:53:01,361 - root - INFO -   Epoch 101/150	 Time: 3.008	 Loss: 6.24528965
2019-06-20 17:53:04,359 - root - INFO -   Epoch 102/150	 Time: 2.997	 Loss: 6.24666766
2019-06-20 17:53:07,395 - root - INFO -   Epoch 103/150	 Time: 3.036	 Loss: 6.24836951
2019-06-20 17:53:10,368 - root - INFO -   Epoch 104/150	 Time: 2.973	 Loss: 6.24368960
2019-06-20 17:53:13,343 - root - INFO -   Epoch 105/150	 Time: 2.975	 Loss: 6.24467032
2019-06-20 17:53:16,356 - root - INFO -   Epoch 106/150	 Time: 3.013	 Loss: 6.24218954
2019-06-20 17:53:19,333 - root - INFO -   Epoch 107/150	 Time: 2.976	 Loss: 6.24643382
2019-06-20 17:53:22,385 - root - INFO -   Epoch 108/150	 Time: 3.052	 Loss: 6.24276111
2019-06-20 17:53:25,381 - root - INFO -   Epoch 109/150	 Time: 2.996	 Loss: 6.24106553
2019-06-20 17:53:28,362 - root - INFO -   Epoch 110/150	 Time: 2.981	 Loss: 6.24345646
2019-06-20 17:53:31,384 - root - INFO -   Epoch 111/150	 Time: 3.021	 Loss: 6.24080523
2019-06-20 17:53:34,411 - root - INFO -   Epoch 112/150	 Time: 3.026	 Loss: 6.24380897
2019-06-20 17:53:37,398 - root - INFO -   Epoch 113/150	 Time: 2.987	 Loss: 6.24494787
2019-06-20 17:53:40,421 - root - INFO -   Epoch 114/150	 Time: 3.023	 Loss: 6.23981172
2019-06-20 17:53:43,429 - root - INFO -   Epoch 115/150	 Time: 3.007	 Loss: 6.23881325
2019-06-20 17:53:46,430 - root - INFO -   Epoch 116/150	 Time: 3.001	 Loss: 6.24096669
2019-06-20 17:53:49,427 - root - INFO -   Epoch 117/150	 Time: 2.997	 Loss: 6.23773433
2019-06-20 17:53:52,438 - root - INFO -   Epoch 118/150	 Time: 3.011	 Loss: 6.23925651
2019-06-20 17:53:55,475 - root - INFO -   Epoch 119/150	 Time: 3.037	 Loss: 6.23928804
2019-06-20 17:53:58,480 - root - INFO -   Epoch 120/150	 Time: 3.005	 Loss: 6.23884540
2019-06-20 17:54:01,504 - root - INFO -   Epoch 121/150	 Time: 3.024	 Loss: 6.24141474
2019-06-20 17:54:04,511 - root - INFO -   Epoch 122/150	 Time: 3.007	 Loss: 6.23820496
2019-06-20 17:54:07,503 - root - INFO -   Epoch 123/150	 Time: 2.992	 Loss: 6.23752825
2019-06-20 17:54:10,512 - root - INFO -   Epoch 124/150	 Time: 3.009	 Loss: 6.23655763
2019-06-20 17:54:13,522 - root - INFO -   Epoch 125/150	 Time: 3.009	 Loss: 6.23821381
2019-06-20 17:54:16,533 - root - INFO -   Epoch 126/150	 Time: 3.011	 Loss: 6.23691339
2019-06-20 17:54:19,531 - root - INFO -   Epoch 127/150	 Time: 2.998	 Loss: 6.23643666
2019-06-20 17:54:22,549 - root - INFO -   Epoch 128/150	 Time: 3.018	 Loss: 6.23478127
2019-06-20 17:54:25,565 - root - INFO -   Epoch 129/150	 Time: 3.015	 Loss: 6.23557813
2019-06-20 17:54:28,574 - root - INFO -   Epoch 130/150	 Time: 3.009	 Loss: 6.23592750
2019-06-20 17:54:31,608 - root - INFO -   Epoch 131/150	 Time: 3.033	 Loss: 6.23584092
2019-06-20 17:54:34,630 - root - INFO -   Epoch 132/150	 Time: 3.022	 Loss: 6.23549195
2019-06-20 17:54:37,654 - root - INFO -   Epoch 133/150	 Time: 3.024	 Loss: 6.23441371
2019-06-20 17:54:40,666 - root - INFO -   Epoch 134/150	 Time: 3.011	 Loss: 6.23377683
2019-06-20 17:54:43,678 - root - INFO -   Epoch 135/150	 Time: 3.012	 Loss: 6.23282170
2019-06-20 17:54:46,679 - root - INFO -   Epoch 136/150	 Time: 3.000	 Loss: 6.23497851
2019-06-20 17:54:49,693 - root - INFO -   Epoch 137/150	 Time: 3.014	 Loss: 6.23292577
2019-06-20 17:54:52,704 - root - INFO -   Epoch 138/150	 Time: 3.011	 Loss: 6.23134460
2019-06-20 17:54:55,716 - root - INFO -   Epoch 139/150	 Time: 3.011	 Loss: 6.23372023
2019-06-20 17:54:58,716 - root - INFO -   Epoch 140/150	 Time: 3.000	 Loss: 6.23313330
2019-06-20 17:55:01,717 - root - INFO -   Epoch 141/150	 Time: 3.001	 Loss: 6.23129545
2019-06-20 17:55:04,728 - root - INFO -   Epoch 142/150	 Time: 3.011	 Loss: 6.23137745
2019-06-20 17:55:07,747 - root - INFO -   Epoch 143/150	 Time: 3.018	 Loss: 6.23036829
2019-06-20 17:55:10,729 - root - INFO -   Epoch 144/150	 Time: 2.982	 Loss: 6.23280677
2019-06-20 17:55:13,727 - root - INFO -   Epoch 145/150	 Time: 2.998	 Loss: 6.22910980
2019-06-20 17:55:16,721 - root - INFO -   Epoch 146/150	 Time: 2.994	 Loss: 6.23014503
2019-06-20 17:55:19,736 - root - INFO -   Epoch 147/150	 Time: 3.015	 Loss: 6.23281071
2019-06-20 17:55:22,764 - root - INFO -   Epoch 148/150	 Time: 3.027	 Loss: 6.22919517
2019-06-20 17:55:25,765 - root - INFO -   Epoch 149/150	 Time: 3.001	 Loss: 6.22950084
2019-06-20 17:55:28,771 - root - INFO -   Epoch 150/150	 Time: 3.006	 Loss: 6.22966143
2019-06-20 17:55:28,771 - root - INFO - Pretraining time: 452.387
2019-06-20 17:55:28,771 - root - INFO - Finished pretraining.
2019-06-20 17:55:28,772 - root - INFO - Testing autoencoder...
2019-06-20 17:55:30,583 - root - INFO - Test set Loss: 6.82389880
2019-06-20 17:55:30,658 - root - INFO - Test set AUC: 59.45%
2019-06-20 17:55:30,658 - root - INFO - Autoencoder testing time: 1.886
2019-06-20 17:55:30,658 - root - INFO - Finished testing autoencoder.
2019-06-20 17:55:30,662 - root - INFO - Training optimizer: adam
2019-06-20 17:55:30,662 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:55:30,662 - root - INFO - Training epochs: 150
2019-06-20 17:55:30,662 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:55:30,662 - root - INFO - Training batch size: 200
2019-06-20 17:55:30,662 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:55:30,663 - root - INFO - Initializing center c...
2019-06-20 17:55:32,114 - root - INFO - Center c initialized.
2019-06-20 17:55:32,114 - root - INFO - Starting training...
2019-06-20 17:55:34,260 - root - INFO -   Epoch 1/150	 Time: 2.146	 Loss: 0.56860383
2019-06-20 17:55:36,340 - root - INFO -   Epoch 2/150	 Time: 2.080	 Loss: 0.10188770
2019-06-20 17:55:38,404 - root - INFO -   Epoch 3/150	 Time: 2.064	 Loss: 0.05618494
2019-06-20 17:55:40,456 - root - INFO -   Epoch 4/150	 Time: 2.052	 Loss: 0.03859255
2019-06-20 17:55:42,498 - root - INFO -   Epoch 5/150	 Time: 2.042	 Loss: 0.02800876
2019-06-20 17:55:44,576 - root - INFO -   Epoch 6/150	 Time: 2.077	 Loss: 0.02090943
2019-06-20 17:55:46,674 - root - INFO -   Epoch 7/150	 Time: 2.098	 Loss: 0.01614070
2019-06-20 17:55:48,753 - root - INFO -   Epoch 8/150	 Time: 2.079	 Loss: 0.01253932
2019-06-20 17:55:50,829 - root - INFO -   Epoch 9/150	 Time: 2.076	 Loss: 0.00983775
2019-06-20 17:55:52,906 - root - INFO -   Epoch 10/150	 Time: 2.077	 Loss: 0.00774067
2019-06-20 17:55:54,952 - root - INFO -   Epoch 11/150	 Time: 2.045	 Loss: 0.00613702
2019-06-20 17:55:57,042 - root - INFO -   Epoch 12/150	 Time: 2.090	 Loss: 0.00492503
2019-06-20 17:55:59,071 - root - INFO -   Epoch 13/150	 Time: 2.029	 Loss: 0.00400851
2019-06-20 17:56:01,157 - root - INFO -   Epoch 14/150	 Time: 2.085	 Loss: 0.00327998
2019-06-20 17:56:03,267 - root - INFO -   Epoch 15/150	 Time: 2.110	 Loss: 0.00271381
2019-06-20 17:56:05,437 - root - INFO -   Epoch 16/150	 Time: 2.170	 Loss: 0.00226000
2019-06-20 17:56:07,522 - root - INFO -   Epoch 17/150	 Time: 2.084	 Loss: 0.00193265
2019-06-20 17:56:09,615 - root - INFO -   Epoch 18/150	 Time: 2.093	 Loss: 0.00163068
2019-06-20 17:56:11,706 - root - INFO -   Epoch 19/150	 Time: 2.090	 Loss: 0.00142879
2019-06-20 17:56:13,777 - root - INFO -   Epoch 20/150	 Time: 2.071	 Loss: 0.00123429
2019-06-20 17:56:15,855 - root - INFO -   Epoch 21/150	 Time: 2.078	 Loss: 0.00107016
2019-06-20 17:56:17,929 - root - INFO -   Epoch 22/150	 Time: 2.074	 Loss: 0.00096139
2019-06-20 17:56:19,995 - root - INFO -   Epoch 23/150	 Time: 2.065	 Loss: 0.00084264
2019-06-20 17:56:22,055 - root - INFO -   Epoch 24/150	 Time: 2.060	 Loss: 0.00076620
2019-06-20 17:56:24,132 - root - INFO -   Epoch 25/150	 Time: 2.077	 Loss: 0.00068628
2019-06-20 17:56:26,214 - root - INFO -   Epoch 26/150	 Time: 2.082	 Loss: 0.00060536
2019-06-20 17:56:28,264 - root - INFO -   Epoch 27/150	 Time: 2.050	 Loss: 0.00056684
2019-06-20 17:56:30,361 - root - INFO -   Epoch 28/150	 Time: 2.097	 Loss: 0.00050700
2019-06-20 17:56:32,528 - root - INFO -   Epoch 29/150	 Time: 2.167	 Loss: 0.00046897
2019-06-20 17:56:34,606 - root - INFO -   Epoch 30/150	 Time: 2.077	 Loss: 0.00043419
2019-06-20 17:56:36,714 - root - INFO -   Epoch 31/150	 Time: 2.108	 Loss: 0.00039975
2019-06-20 17:56:38,790 - root - INFO -   Epoch 32/150	 Time: 2.075	 Loss: 0.00036157
2019-06-20 17:56:40,874 - root - INFO -   Epoch 33/150	 Time: 2.083	 Loss: 0.00033226
2019-06-20 17:56:42,943 - root - INFO -   Epoch 34/150	 Time: 2.070	 Loss: 0.00031686
2019-06-20 17:56:44,991 - root - INFO -   Epoch 35/150	 Time: 2.047	 Loss: 0.00028546
2019-06-20 17:56:47,054 - root - INFO -   Epoch 36/150	 Time: 2.062	 Loss: 0.00026457
2019-06-20 17:56:49,120 - root - INFO -   Epoch 37/150	 Time: 2.067	 Loss: 0.00025994
2019-06-20 17:56:51,180 - root - INFO -   Epoch 38/150	 Time: 2.060	 Loss: 0.00025441
2019-06-20 17:56:53,199 - root - INFO -   Epoch 39/150	 Time: 2.018	 Loss: 0.00022174
2019-06-20 17:56:55,278 - root - INFO -   Epoch 40/150	 Time: 2.078	 Loss: 0.00021341
2019-06-20 17:56:57,349 - root - INFO -   Epoch 41/150	 Time: 2.071	 Loss: 0.00019923
2019-06-20 17:56:59,413 - root - INFO -   Epoch 42/150	 Time: 2.065	 Loss: 0.00018992
2019-06-20 17:57:01,467 - root - INFO -   Epoch 43/150	 Time: 2.053	 Loss: 0.00017840
2019-06-20 17:57:03,569 - root - INFO -   Epoch 44/150	 Time: 2.101	 Loss: 0.00016729
2019-06-20 17:57:05,647 - root - INFO -   Epoch 45/150	 Time: 2.078	 Loss: 0.00017528
2019-06-20 17:57:07,691 - root - INFO -   Epoch 46/150	 Time: 2.043	 Loss: 0.00015080
2019-06-20 17:57:09,765 - root - INFO -   Epoch 47/150	 Time: 2.074	 Loss: 0.00014530
2019-06-20 17:57:11,841 - root - INFO -   Epoch 48/150	 Time: 2.076	 Loss: 0.00014877
2019-06-20 17:57:13,907 - root - INFO -   Epoch 49/150	 Time: 2.066	 Loss: 0.00014233
2019-06-20 17:57:15,972 - root - INFO -   Epoch 50/150	 Time: 2.064	 Loss: 0.00010170
2019-06-20 17:57:15,972 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:57:18,047 - root - INFO -   Epoch 51/150	 Time: 2.075	 Loss: 0.00009788
2019-06-20 17:57:20,118 - root - INFO -   Epoch 52/150	 Time: 2.070	 Loss: 0.00009712
2019-06-20 17:57:22,181 - root - INFO -   Epoch 53/150	 Time: 2.063	 Loss: 0.00009595
2019-06-20 17:57:24,238 - root - INFO -   Epoch 54/150	 Time: 2.057	 Loss: 0.00009529
2019-06-20 17:57:26,313 - root - INFO -   Epoch 55/150	 Time: 2.075	 Loss: 0.00009686
2019-06-20 17:57:28,394 - root - INFO -   Epoch 56/150	 Time: 2.081	 Loss: 0.00009501
2019-06-20 17:57:30,492 - root - INFO -   Epoch 57/150	 Time: 2.097	 Loss: 0.00009459
2019-06-20 17:57:32,570 - root - INFO -   Epoch 58/150	 Time: 2.079	 Loss: 0.00009442
2019-06-20 17:57:34,621 - root - INFO -   Epoch 59/150	 Time: 2.051	 Loss: 0.00009234
2019-06-20 17:57:36,700 - root - INFO -   Epoch 60/150	 Time: 2.078	 Loss: 0.00009273
2019-06-20 17:57:38,789 - root - INFO -   Epoch 61/150	 Time: 2.088	 Loss: 0.00009175
2019-06-20 17:57:40,840 - root - INFO -   Epoch 62/150	 Time: 2.051	 Loss: 0.00009175
2019-06-20 17:57:42,934 - root - INFO -   Epoch 63/150	 Time: 2.094	 Loss: 0.00008905
2019-06-20 17:57:45,008 - root - INFO -   Epoch 64/150	 Time: 2.073	 Loss: 0.00008856
2019-06-20 17:57:47,092 - root - INFO -   Epoch 65/150	 Time: 2.084	 Loss: 0.00009068
2019-06-20 17:57:49,175 - root - INFO -   Epoch 66/150	 Time: 2.083	 Loss: 0.00008870
2019-06-20 17:57:51,193 - root - INFO -   Epoch 67/150	 Time: 2.017	 Loss: 0.00008748
2019-06-20 17:57:53,243 - root - INFO -   Epoch 68/150	 Time: 2.050	 Loss: 0.00008805
2019-06-20 17:57:55,305 - root - INFO -   Epoch 69/150	 Time: 2.062	 Loss: 0.00008672
2019-06-20 17:57:57,336 - root - INFO -   Epoch 70/150	 Time: 2.031	 Loss: 0.00008328
2019-06-20 17:57:59,401 - root - INFO -   Epoch 71/150	 Time: 2.064	 Loss: 0.00008469
2019-06-20 17:58:01,490 - root - INFO -   Epoch 72/150	 Time: 2.089	 Loss: 0.00008590
2019-06-20 17:58:03,564 - root - INFO -   Epoch 73/150	 Time: 2.074	 Loss: 0.00008345
2019-06-20 17:58:05,621 - root - INFO -   Epoch 74/150	 Time: 2.057	 Loss: 0.00008402
2019-06-20 17:58:07,697 - root - INFO -   Epoch 75/150	 Time: 2.075	 Loss: 0.00008329
2019-06-20 17:58:09,810 - root - INFO -   Epoch 76/150	 Time: 2.113	 Loss: 0.00008334
2019-06-20 17:58:11,892 - root - INFO -   Epoch 77/150	 Time: 2.082	 Loss: 0.00008184
2019-06-20 17:58:13,967 - root - INFO -   Epoch 78/150	 Time: 2.075	 Loss: 0.00008421
2019-06-20 17:58:16,016 - root - INFO -   Epoch 79/150	 Time: 2.049	 Loss: 0.00007936
2019-06-20 17:58:18,074 - root - INFO -   Epoch 80/150	 Time: 2.057	 Loss: 0.00008014
2019-06-20 17:58:20,136 - root - INFO -   Epoch 81/150	 Time: 2.061	 Loss: 0.00007945
2019-06-20 17:58:22,187 - root - INFO -   Epoch 82/150	 Time: 2.051	 Loss: 0.00007759
2019-06-20 17:58:24,280 - root - INFO -   Epoch 83/150	 Time: 2.093	 Loss: 0.00007869
2019-06-20 17:58:26,371 - root - INFO -   Epoch 84/150	 Time: 2.091	 Loss: 0.00007740
2019-06-20 17:58:28,413 - root - INFO -   Epoch 85/150	 Time: 2.041	 Loss: 0.00007732
2019-06-20 17:58:30,481 - root - INFO -   Epoch 86/150	 Time: 2.068	 Loss: 0.00007690
2019-06-20 17:58:32,535 - root - INFO -   Epoch 87/150	 Time: 2.053	 Loss: 0.00007882
2019-06-20 17:58:34,613 - root - INFO -   Epoch 88/150	 Time: 2.078	 Loss: 0.00007395
2019-06-20 17:58:36,712 - root - INFO -   Epoch 89/150	 Time: 2.100	 Loss: 0.00007533
2019-06-20 17:58:38,799 - root - INFO -   Epoch 90/150	 Time: 2.086	 Loss: 0.00007471
2019-06-20 17:58:40,861 - root - INFO -   Epoch 91/150	 Time: 2.062	 Loss: 0.00007464
2019-06-20 17:58:42,943 - root - INFO -   Epoch 92/150	 Time: 2.082	 Loss: 0.00007358
2019-06-20 17:58:45,014 - root - INFO -   Epoch 93/150	 Time: 2.070	 Loss: 0.00007330
2019-06-20 17:58:47,091 - root - INFO -   Epoch 94/150	 Time: 2.077	 Loss: 0.00007311
2019-06-20 17:58:49,171 - root - INFO -   Epoch 95/150	 Time: 2.079	 Loss: 0.00007271
2019-06-20 17:58:51,227 - root - INFO -   Epoch 96/150	 Time: 2.056	 Loss: 0.00007139
2019-06-20 17:58:53,324 - root - INFO -   Epoch 97/150	 Time: 2.096	 Loss: 0.00007200
2019-06-20 17:58:55,406 - root - INFO -   Epoch 98/150	 Time: 2.082	 Loss: 0.00007118
2019-06-20 17:58:57,463 - root - INFO -   Epoch 99/150	 Time: 2.056	 Loss: 0.00007203
2019-06-20 17:58:59,509 - root - INFO -   Epoch 100/150	 Time: 2.046	 Loss: 0.00007113
2019-06-20 17:59:01,553 - root - INFO -   Epoch 101/150	 Time: 2.044	 Loss: 0.00006889
2019-06-20 17:59:03,619 - root - INFO -   Epoch 102/150	 Time: 2.065	 Loss: 0.00006915
2019-06-20 17:59:05,666 - root - INFO -   Epoch 103/150	 Time: 2.048	 Loss: 0.00006893
2019-06-20 17:59:07,717 - root - INFO -   Epoch 104/150	 Time: 2.050	 Loss: 0.00006832
2019-06-20 17:59:09,765 - root - INFO -   Epoch 105/150	 Time: 2.048	 Loss: 0.00006720
2019-06-20 17:59:11,829 - root - INFO -   Epoch 106/150	 Time: 2.063	 Loss: 0.00006939
2019-06-20 17:59:13,893 - root - INFO -   Epoch 107/150	 Time: 2.064	 Loss: 0.00006685
2019-06-20 17:59:15,959 - root - INFO -   Epoch 108/150	 Time: 2.066	 Loss: 0.00006804
2019-06-20 17:59:18,048 - root - INFO -   Epoch 109/150	 Time: 2.088	 Loss: 0.00006666
2019-06-20 17:59:20,123 - root - INFO -   Epoch 110/150	 Time: 2.075	 Loss: 0.00006688
2019-06-20 17:59:22,186 - root - INFO -   Epoch 111/150	 Time: 2.063	 Loss: 0.00006664
2019-06-20 17:59:24,267 - root - INFO -   Epoch 112/150	 Time: 2.080	 Loss: 0.00006634
2019-06-20 17:59:26,338 - root - INFO -   Epoch 113/150	 Time: 2.071	 Loss: 0.00006387
2019-06-20 17:59:28,381 - root - INFO -   Epoch 114/150	 Time: 2.043	 Loss: 0.00006530
2019-06-20 17:59:30,459 - root - INFO -   Epoch 115/150	 Time: 2.077	 Loss: 0.00006450
2019-06-20 17:59:32,536 - root - INFO -   Epoch 116/150	 Time: 2.077	 Loss: 0.00006572
2019-06-20 17:59:34,609 - root - INFO -   Epoch 117/150	 Time: 2.073	 Loss: 0.00006507
2019-06-20 17:59:36,630 - root - INFO -   Epoch 118/150	 Time: 2.021	 Loss: 0.00006227
2019-06-20 17:59:38,686 - root - INFO -   Epoch 119/150	 Time: 2.055	 Loss: 0.00006229
2019-06-20 17:59:40,733 - root - INFO -   Epoch 120/150	 Time: 2.047	 Loss: 0.00006380
2019-06-20 17:59:42,821 - root - INFO -   Epoch 121/150	 Time: 2.088	 Loss: 0.00006168
2019-06-20 17:59:44,878 - root - INFO -   Epoch 122/150	 Time: 2.056	 Loss: 0.00006188
2019-06-20 17:59:46,964 - root - INFO -   Epoch 123/150	 Time: 2.086	 Loss: 0.00006098
2019-06-20 17:59:49,065 - root - INFO -   Epoch 124/150	 Time: 2.101	 Loss: 0.00006072
2019-06-20 17:59:51,130 - root - INFO -   Epoch 125/150	 Time: 2.065	 Loss: 0.00006263
2019-06-20 17:59:53,214 - root - INFO -   Epoch 126/150	 Time: 2.083	 Loss: 0.00006164
2019-06-20 17:59:55,309 - root - INFO -   Epoch 127/150	 Time: 2.096	 Loss: 0.00006035
2019-06-20 17:59:57,349 - root - INFO -   Epoch 128/150	 Time: 2.040	 Loss: 0.00005949
2019-06-20 17:59:59,436 - root - INFO -   Epoch 129/150	 Time: 2.087	 Loss: 0.00006035
2019-06-20 18:00:01,519 - root - INFO -   Epoch 130/150	 Time: 2.082	 Loss: 0.00005930
2019-06-20 18:00:03,565 - root - INFO -   Epoch 131/150	 Time: 2.046	 Loss: 0.00005956
2019-06-20 18:00:05,651 - root - INFO -   Epoch 132/150	 Time: 2.086	 Loss: 0.00006024
2019-06-20 18:00:07,712 - root - INFO -   Epoch 133/150	 Time: 2.060	 Loss: 0.00005794
2019-06-20 18:00:09,773 - root - INFO -   Epoch 134/150	 Time: 2.061	 Loss: 0.00005838
2019-06-20 18:00:11,867 - root - INFO -   Epoch 135/150	 Time: 2.094	 Loss: 0.00005602
2019-06-20 18:00:13,933 - root - INFO -   Epoch 136/150	 Time: 2.065	 Loss: 0.00005896
2019-06-20 18:00:15,996 - root - INFO -   Epoch 137/150	 Time: 2.063	 Loss: 0.00005717
2019-06-20 18:00:18,061 - root - INFO -   Epoch 138/150	 Time: 2.065	 Loss: 0.00005861
2019-06-20 18:00:20,138 - root - INFO -   Epoch 139/150	 Time: 2.077	 Loss: 0.00005741
2019-06-20 18:00:22,208 - root - INFO -   Epoch 140/150	 Time: 2.069	 Loss: 0.00005685
2019-06-20 18:00:24,268 - root - INFO -   Epoch 141/150	 Time: 2.060	 Loss: 0.00005573
2019-06-20 18:00:26,331 - root - INFO -   Epoch 142/150	 Time: 2.062	 Loss: 0.00005904
2019-06-20 18:00:28,396 - root - INFO -   Epoch 143/150	 Time: 2.065	 Loss: 0.00005665
2019-06-20 18:00:30,439 - root - INFO -   Epoch 144/150	 Time: 2.043	 Loss: 0.00005636
2019-06-20 18:00:32,471 - root - INFO -   Epoch 145/150	 Time: 2.032	 Loss: 0.00005632
2019-06-20 18:00:34,552 - root - INFO -   Epoch 146/150	 Time: 2.081	 Loss: 0.00005397
2019-06-20 18:00:36,601 - root - INFO -   Epoch 147/150	 Time: 2.049	 Loss: 0.00005492
2019-06-20 18:00:38,667 - root - INFO -   Epoch 148/150	 Time: 2.066	 Loss: 0.00005456
2019-06-20 18:00:40,716 - root - INFO -   Epoch 149/150	 Time: 2.048	 Loss: 0.00005363
2019-06-20 18:00:42,779 - root - INFO -   Epoch 150/150	 Time: 2.063	 Loss: 0.00005307
2019-06-20 18:00:42,780 - root - INFO - Training time: 310.666
2019-06-20 18:00:42,780 - root - INFO - Finished training.
2019-06-20 18:00:42,780 - root - INFO - Starting testing...
2019-06-20 18:00:44,167 - root - INFO - Testing time: 1.387
2019-06-20 18:00:44,243 - root - INFO - Test set AUC: 69.61%
2019-06-20 18:00:44,243 - root - INFO - Finished testing.
2019-06-21 11:47:17,947 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 11:47:17,947 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 11:47:17,947 - root - INFO - Export path is ../log/hits_test.
2019-06-21 11:47:17,947 - root - INFO - Dataset: hits
2019-06-21 11:47:17,947 - root - INFO - Normal class: 1
2019-06-21 11:47:17,947 - root - INFO - Network: hits_LeNet
2019-06-21 11:47:17,947 - root - INFO - Deep SVDD objective: one-class
2019-06-21 11:47:17,947 - root - INFO - Nu-paramerter: 0.10
2019-06-21 11:47:17,979 - root - INFO - Computation device: cuda
2019-06-21 11:47:17,979 - root - INFO - Number of dataloader workers: 16
2019-06-21 11:47:27,868 - root - INFO - Pretraining: True
2019-06-21 11:47:27,868 - root - INFO - Pretraining optimizer: adam
2019-06-21 11:47:27,868 - root - INFO - Pretraining learning rate: 0.0001
2019-06-21 11:47:27,868 - root - INFO - Pretraining epochs: 2
2019-06-21 11:47:27,868 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-21 11:47:27,868 - root - INFO - Pretraining batch size: 200
2019-06-21 11:47:27,868 - root - INFO - Pretraining weight decay: 0.0005
2019-06-21 11:47:29,971 - root - INFO - Starting pretraining...
2019-06-21 11:47:33,343 - root - INFO -   Epoch 1/2	 Time: 3.372	 Loss: 12.15694988
2019-06-21 11:47:36,449 - root - INFO -   Epoch 2/2	 Time: 3.106	 Loss: 7.83186128
2019-06-21 11:47:36,450 - root - INFO - Pretraining time: 6.478
2019-06-21 11:47:36,450 - root - INFO - Finished pretraining.
2019-06-21 11:47:36,450 - root - INFO - Testing autoencoder...
2019-06-21 11:47:38,435 - root - INFO - Test set Loss: 9.29181943
2019-06-21 11:47:38,505 - root - INFO - Test set AUC: 74.46%
2019-06-21 11:47:38,506 - root - INFO - Autoencoder testing time: 2.056
2019-06-21 11:47:38,506 - root - INFO - Finished testing autoencoder.
2019-06-21 11:47:38,509 - root - INFO - Training optimizer: adam
2019-06-21 11:47:38,510 - root - INFO - Training learning rate: 0.0001
2019-06-21 11:47:38,510 - root - INFO - Training epochs: 2
2019-06-21 11:47:38,510 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-21 11:47:38,510 - root - INFO - Training batch size: 200
2019-06-21 11:47:38,510 - root - INFO - Training weight decay: 5e-07
2019-06-21 11:47:38,510 - root - INFO - Initializing center c...
2019-06-21 11:47:40,065 - root - INFO - Center c initialized.
2019-06-21 11:47:40,065 - root - INFO - Starting training...
2019-06-21 11:47:42,253 - root - INFO -   Epoch 1/2	 Time: 2.188	 Loss: 0.72287164
2019-06-21 11:47:44,430 - root - INFO -   Epoch 2/2	 Time: 2.177	 Loss: 0.15676613
2019-06-21 11:47:44,430 - root - INFO - Training time: 4.365
2019-06-21 11:47:44,430 - root - INFO - Finished training.
2019-06-21 11:47:44,431 - root - INFO - Starting testing...
2019-06-21 11:47:45,961 - root - INFO - Testing time: 1.530
2019-06-21 11:47:46,030 - root - INFO - Test set AUC: 94.45%
2019-06-21 11:47:46,031 - root - INFO - Finished testing.
2019-06-21 13:33:15,467 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 13:33:15,467 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 13:33:15,467 - root - INFO - Export path is ../log/hits_test.
2019-06-21 13:33:15,467 - root - INFO - Dataset: hits
2019-06-21 13:33:15,468 - root - INFO - Normal class: 1
2019-06-21 13:33:15,468 - root - INFO - Network: hits_LeNet
2019-06-21 13:33:15,468 - root - INFO - Deep SVDD objective: one-class
2019-06-21 13:33:15,468 - root - INFO - Nu-paramerter: 0.10
2019-06-21 13:33:15,501 - root - INFO - Computation device: cuda
2019-06-21 13:33:15,501 - root - INFO - Number of dataloader workers: 16
2019-06-21 13:33:29,711 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 13:33:29,711 - root - INFO - Starting testing...
2019-06-21 13:33:31,908 - root - INFO - Testing time: 2.196
2019-06-21 13:33:31,980 - root - INFO - Test set AUC: 94.45%
2019-06-21 13:33:31,980 - root - INFO - Finished testing.
2019-06-21 13:37:45,455 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 13:37:45,455 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 13:37:45,455 - root - INFO - Export path is ../log/hits_test.
2019-06-21 13:37:45,455 - root - INFO - Dataset: hits
2019-06-21 13:37:45,455 - root - INFO - Normal class: 1
2019-06-21 13:37:45,455 - root - INFO - Network: hits_LeNet
2019-06-21 13:37:45,455 - root - INFO - Deep SVDD objective: one-class
2019-06-21 13:37:45,455 - root - INFO - Nu-paramerter: 0.10
2019-06-21 13:37:45,489 - root - INFO - Computation device: cuda
2019-06-21 13:37:45,489 - root - INFO - Number of dataloader workers: 16
2019-06-21 13:37:57,418 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 13:37:57,418 - root - INFO - Starting testing...
2019-06-21 13:37:59,502 - root - INFO - Testing time: 2.083
2019-06-21 13:37:59,584 - root - INFO - Test set AUC: 94.45%
2019-06-21 13:37:59,584 - root - INFO - Finished testing.
2019-06-21 14:00:39,739 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 14:00:39,740 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 14:00:39,740 - root - INFO - Export path is ../log/hits_test.
2019-06-21 14:00:39,740 - root - INFO - Dataset: hits
2019-06-21 14:00:39,740 - root - INFO - Normal class: 1
2019-06-21 14:00:39,740 - root - INFO - Network: hits_LeNet
2019-06-21 14:00:39,740 - root - INFO - Deep SVDD objective: one-class
2019-06-21 14:00:39,740 - root - INFO - Nu-paramerter: 0.10
2019-06-21 14:00:39,753 - root - INFO - Computation device: cuda
2019-06-21 14:00:39,753 - root - INFO - Number of dataloader workers: 16
2019-06-21 14:00:51,742 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 14:00:51,743 - root - INFO - Starting testing...
2019-06-21 14:00:53,683 - root - INFO - Testing time: 1.940
2019-06-21 14:00:53,768 - root - INFO - Test set AUC: 94.45%
2019-06-21 14:00:53,768 - root - INFO - Finished testing.
2019-06-21 14:04:04,940 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 14:04:04,940 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 14:04:04,940 - root - INFO - Export path is ../log/hits_test.
2019-06-21 14:04:04,940 - root - INFO - Dataset: hits
2019-06-21 14:04:04,940 - root - INFO - Normal class: 1
2019-06-21 14:04:04,940 - root - INFO - Network: hits_LeNet
2019-06-21 14:04:04,940 - root - INFO - Deep SVDD objective: one-class
2019-06-21 14:04:04,940 - root - INFO - Nu-paramerter: 0.10
2019-06-21 14:04:04,947 - root - INFO - Computation device: cuda
2019-06-21 14:04:04,947 - root - INFO - Number of dataloader workers: 16
2019-06-21 15:56:31,169 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 15:56:31,169 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 15:56:31,169 - root - INFO - Export path is ../log/hits_test.
2019-06-21 15:56:31,169 - root - INFO - Dataset: hits
2019-06-21 15:56:31,169 - root - INFO - Normal class: 1
2019-06-21 15:56:31,170 - root - INFO - Network: hits_LeNet
2019-06-21 15:56:31,170 - root - INFO - Deep SVDD objective: one-class
2019-06-21 15:56:31,170 - root - INFO - Nu-paramerter: 0.10
2019-06-21 15:56:31,188 - root - INFO - Computation device: cuda
2019-06-21 15:56:31,188 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:21:36,481 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 16:21:36,482 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 16:21:36,482 - root - INFO - Export path is ../log/hits_test.
2019-06-21 16:21:36,482 - root - INFO - Dataset: hits
2019-06-21 16:21:36,482 - root - INFO - Normal class: 1
2019-06-21 16:21:36,482 - root - INFO - Network: hits_LeNet
2019-06-21 16:21:36,482 - root - INFO - Deep SVDD objective: one-class
2019-06-21 16:21:36,482 - root - INFO - Nu-paramerter: 0.10
2019-06-21 16:21:36,500 - root - INFO - Computation device: cuda
2019-06-21 16:21:36,500 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:21:48,182 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 16:21:48,183 - root - INFO - Starting testing...
2019-06-21 16:21:49,885 - root - INFO - Testing time: 1.702
2019-06-21 16:21:49,967 - root - INFO - Test set AUC: 94.45%
2019-06-21 16:21:49,967 - root - INFO - Finished testing.
2019-06-21 16:28:05,550 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 16:28:05,550 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 16:28:05,550 - root - INFO - Export path is ../log/hits_test.
2019-06-21 16:28:05,550 - root - INFO - Dataset: hits
2019-06-21 16:28:05,550 - root - INFO - Normal class: 1
2019-06-21 16:28:05,550 - root - INFO - Network: hits_LeNet
2019-06-21 16:28:05,550 - root - INFO - Deep SVDD objective: one-class
2019-06-21 16:28:05,550 - root - INFO - Nu-paramerter: 0.10
2019-06-21 16:28:05,566 - root - INFO - Computation device: cuda
2019-06-21 16:28:05,566 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:28:17,364 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 16:28:17,365 - root - INFO - Starting testing...
2019-06-21 16:28:19,057 - root - INFO - Testing time: 1.692
2019-06-21 16:28:19,141 - root - INFO - Test set AUC: 94.45%
2019-06-21 16:28:19,141 - root - INFO - Finished testing.
2019-06-21 16:31:16,277 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 16:31:16,277 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 16:31:16,277 - root - INFO - Export path is ../log/hits_test.
2019-06-21 16:31:16,277 - root - INFO - Dataset: hits
2019-06-21 16:31:16,277 - root - INFO - Normal class: 1
2019-06-21 16:31:16,277 - root - INFO - Network: hits_LeNet
2019-06-21 16:31:16,277 - root - INFO - Deep SVDD objective: one-class
2019-06-21 16:31:16,277 - root - INFO - Nu-paramerter: 0.10
2019-06-21 16:31:16,295 - root - INFO - Computation device: cuda
2019-06-21 16:31:16,295 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:31:26,077 - root - INFO - Pretraining: True
2019-06-21 16:31:26,077 - root - INFO - Pretraining optimizer: adam
2019-06-21 16:31:26,077 - root - INFO - Pretraining learning rate: 0.0001
2019-06-21 16:31:26,077 - root - INFO - Pretraining epochs: 150
2019-06-21 16:31:26,077 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-21 16:31:26,077 - root - INFO - Pretraining batch size: 200
2019-06-21 16:31:26,077 - root - INFO - Pretraining weight decay: 0.0005
2019-06-21 16:31:28,175 - root - INFO - Starting pretraining...
2019-06-21 16:31:31,159 - root - INFO -   Epoch 1/150	 Time: 2.984	 Loss: 9.89802513
2019-06-21 16:31:33,942 - root - INFO -   Epoch 2/150	 Time: 2.783	 Loss: 7.51637586
2019-06-21 16:31:36,760 - root - INFO -   Epoch 3/150	 Time: 2.818	 Loss: 7.22940032
2019-06-21 16:31:39,516 - root - INFO -   Epoch 4/150	 Time: 2.755	 Loss: 7.08878589
2019-06-21 16:31:42,272 - root - INFO -   Epoch 5/150	 Time: 2.756	 Loss: 6.98810387
2019-06-21 16:31:45,047 - root - INFO -   Epoch 6/150	 Time: 2.774	 Loss: 6.91401566
2019-06-21 16:31:47,909 - root - INFO -   Epoch 7/150	 Time: 2.862	 Loss: 6.84990201
2019-06-21 16:31:50,733 - root - INFO -   Epoch 8/150	 Time: 2.823	 Loss: 6.80936009
2019-06-21 16:31:53,694 - root - INFO -   Epoch 9/150	 Time: 2.961	 Loss: 6.77065474
2019-06-21 16:31:56,597 - root - INFO -   Epoch 10/150	 Time: 2.903	 Loss: 6.73728955
2019-06-21 16:31:59,333 - root - INFO -   Epoch 11/150	 Time: 2.735	 Loss: 6.69973666
2019-06-21 16:32:02,101 - root - INFO -   Epoch 12/150	 Time: 2.768	 Loss: 6.66590362
2019-06-21 16:32:04,894 - root - INFO -   Epoch 13/150	 Time: 2.793	 Loss: 6.63599835
2019-06-21 16:32:07,680 - root - INFO -   Epoch 14/150	 Time: 2.786	 Loss: 6.61012818
2019-06-21 16:32:10,491 - root - INFO -   Epoch 15/150	 Time: 2.811	 Loss: 6.59422966
2019-06-21 16:32:13,362 - root - INFO -   Epoch 16/150	 Time: 2.871	 Loss: 6.57109083
2019-06-21 16:32:16,149 - root - INFO -   Epoch 17/150	 Time: 2.787	 Loss: 6.55817041
2019-06-21 16:32:18,949 - root - INFO -   Epoch 18/150	 Time: 2.800	 Loss: 6.53737038
2019-06-21 16:32:21,872 - root - INFO -   Epoch 19/150	 Time: 2.923	 Loss: 6.52168590
2019-06-21 16:32:24,746 - root - INFO -   Epoch 20/150	 Time: 2.874	 Loss: 6.50874112
2019-06-21 16:32:27,633 - root - INFO -   Epoch 21/150	 Time: 2.887	 Loss: 6.49396031
2019-06-21 16:32:30,519 - root - INFO -   Epoch 22/150	 Time: 2.885	 Loss: 6.48224988
2019-06-21 16:32:33,426 - root - INFO -   Epoch 23/150	 Time: 2.907	 Loss: 6.47164246
2019-06-21 16:32:36,476 - root - INFO -   Epoch 24/150	 Time: 3.050	 Loss: 6.45788629
2019-06-21 16:32:39,471 - root - INFO -   Epoch 25/150	 Time: 2.994	 Loss: 6.44435115
2019-06-21 16:32:42,426 - root - INFO -   Epoch 26/150	 Time: 2.955	 Loss: 6.44035971
2019-06-21 16:32:45,325 - root - INFO -   Epoch 27/150	 Time: 2.898	 Loss: 6.42984767
2019-06-21 16:32:48,249 - root - INFO -   Epoch 28/150	 Time: 2.924	 Loss: 6.41650783
2019-06-21 16:32:51,098 - root - INFO -   Epoch 29/150	 Time: 2.848	 Loss: 6.41512165
2019-06-21 16:32:53,922 - root - INFO -   Epoch 30/150	 Time: 2.823	 Loss: 6.40486472
2019-06-21 16:32:56,827 - root - INFO -   Epoch 31/150	 Time: 2.905	 Loss: 6.39610987
2019-06-21 16:32:59,724 - root - INFO -   Epoch 32/150	 Time: 2.896	 Loss: 6.39345090
2019-06-21 16:33:02,664 - root - INFO -   Epoch 33/150	 Time: 2.940	 Loss: 6.38104857
2019-06-21 16:33:05,719 - root - INFO -   Epoch 34/150	 Time: 3.055	 Loss: 6.37822581
2019-06-21 16:33:08,687 - root - INFO -   Epoch 35/150	 Time: 2.968	 Loss: 6.37134842
2019-06-21 16:33:11,657 - root - INFO -   Epoch 36/150	 Time: 2.970	 Loss: 6.37001683
2019-06-21 16:33:14,498 - root - INFO -   Epoch 37/150	 Time: 2.840	 Loss: 6.36789033
2019-06-21 16:33:17,340 - root - INFO -   Epoch 38/150	 Time: 2.842	 Loss: 6.36143206
2019-06-21 16:33:20,180 - root - INFO -   Epoch 39/150	 Time: 2.840	 Loss: 6.36079056
2019-06-21 16:33:23,019 - root - INFO -   Epoch 40/150	 Time: 2.839	 Loss: 6.35514666
2019-06-21 16:33:25,885 - root - INFO -   Epoch 41/150	 Time: 2.866	 Loss: 6.34754843
2019-06-21 16:33:28,756 - root - INFO -   Epoch 42/150	 Time: 2.870	 Loss: 6.34677505
2019-06-21 16:33:31,584 - root - INFO -   Epoch 43/150	 Time: 2.828	 Loss: 6.33628875
2019-06-21 16:33:34,425 - root - INFO -   Epoch 44/150	 Time: 2.840	 Loss: 6.33514364
2019-06-21 16:33:37,247 - root - INFO -   Epoch 45/150	 Time: 2.822	 Loss: 6.33063580
2019-06-21 16:33:40,086 - root - INFO -   Epoch 46/150	 Time: 2.839	 Loss: 6.32438651
2019-06-21 16:33:42,904 - root - INFO -   Epoch 47/150	 Time: 2.818	 Loss: 6.31801461
2019-06-21 16:33:45,726 - root - INFO -   Epoch 48/150	 Time: 2.822	 Loss: 6.31714041
2019-06-21 16:33:48,593 - root - INFO -   Epoch 49/150	 Time: 2.866	 Loss: 6.31302400
2019-06-21 16:33:51,442 - root - INFO -   Epoch 50/150	 Time: 2.849	 Loss: 6.30018291
2019-06-21 16:33:51,442 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-21 16:33:54,352 - root - INFO -   Epoch 51/150	 Time: 2.910	 Loss: 6.30161604
2019-06-21 16:33:57,353 - root - INFO -   Epoch 52/150	 Time: 3.000	 Loss: 6.30211313
2019-06-21 16:34:00,171 - root - INFO -   Epoch 53/150	 Time: 2.818	 Loss: 6.30057333
2019-06-21 16:34:02,962 - root - INFO -   Epoch 54/150	 Time: 2.791	 Loss: 6.30336743
2019-06-21 16:34:05,809 - root - INFO -   Epoch 55/150	 Time: 2.847	 Loss: 6.30081177
2019-06-21 16:34:08,610 - root - INFO -   Epoch 56/150	 Time: 2.801	 Loss: 6.30009983
2019-06-21 16:34:11,415 - root - INFO -   Epoch 57/150	 Time: 2.805	 Loss: 6.29903238
2019-06-21 16:34:14,198 - root - INFO -   Epoch 58/150	 Time: 2.783	 Loss: 6.30097066
2019-06-21 16:34:17,012 - root - INFO -   Epoch 59/150	 Time: 2.814	 Loss: 6.29735464
2019-06-21 16:34:19,816 - root - INFO -   Epoch 60/150	 Time: 2.804	 Loss: 6.29923799
2019-06-21 16:34:22,623 - root - INFO -   Epoch 61/150	 Time: 2.806	 Loss: 6.29715326
2019-06-21 16:34:25,417 - root - INFO -   Epoch 62/150	 Time: 2.795	 Loss: 6.30007789
2019-06-21 16:34:28,202 - root - INFO -   Epoch 63/150	 Time: 2.784	 Loss: 6.30193544
2019-06-21 16:34:30,985 - root - INFO -   Epoch 64/150	 Time: 2.783	 Loss: 6.29589925
2019-06-21 16:34:33,801 - root - INFO -   Epoch 65/150	 Time: 2.816	 Loss: 6.29317023
2019-06-21 16:34:36,598 - root - INFO -   Epoch 66/150	 Time: 2.796	 Loss: 6.29546502
2019-06-21 16:34:39,382 - root - INFO -   Epoch 67/150	 Time: 2.784	 Loss: 6.29417390
2019-06-21 16:34:42,179 - root - INFO -   Epoch 68/150	 Time: 2.796	 Loss: 6.29573738
2019-06-21 16:34:45,012 - root - INFO -   Epoch 69/150	 Time: 2.832	 Loss: 6.29326926
2019-06-21 16:34:47,813 - root - INFO -   Epoch 70/150	 Time: 2.801	 Loss: 6.29647227
2019-06-21 16:34:50,598 - root - INFO -   Epoch 71/150	 Time: 2.785	 Loss: 6.29240596
2019-06-21 16:34:53,469 - root - INFO -   Epoch 72/150	 Time: 2.871	 Loss: 6.29322713
2019-06-21 16:34:56,366 - root - INFO -   Epoch 73/150	 Time: 2.897	 Loss: 6.29352321
2019-06-21 16:34:59,261 - root - INFO -   Epoch 74/150	 Time: 2.895	 Loss: 6.29382302
2019-06-21 16:35:02,065 - root - INFO -   Epoch 75/150	 Time: 2.803	 Loss: 6.29185520
2019-06-21 16:35:04,859 - root - INFO -   Epoch 76/150	 Time: 2.794	 Loss: 6.28971171
2019-06-21 16:35:07,674 - root - INFO -   Epoch 77/150	 Time: 2.815	 Loss: 6.29001331
2019-06-21 16:35:10,457 - root - INFO -   Epoch 78/150	 Time: 2.783	 Loss: 6.29055204
2019-06-21 16:35:13,270 - root - INFO -   Epoch 79/150	 Time: 2.813	 Loss: 6.28751646
2019-06-21 16:35:16,051 - root - INFO -   Epoch 80/150	 Time: 2.781	 Loss: 6.28935427
2019-06-21 16:35:18,866 - root - INFO -   Epoch 81/150	 Time: 2.814	 Loss: 6.28810476
2019-06-21 16:35:21,657 - root - INFO -   Epoch 82/150	 Time: 2.791	 Loss: 6.28866128
2019-06-21 16:35:24,450 - root - INFO -   Epoch 83/150	 Time: 2.793	 Loss: 6.28736002
2019-06-21 16:35:27,255 - root - INFO -   Epoch 84/150	 Time: 2.805	 Loss: 6.28681538
2019-06-21 16:35:30,054 - root - INFO -   Epoch 85/150	 Time: 2.799	 Loss: 6.28873940
2019-06-21 16:35:32,848 - root - INFO -   Epoch 86/150	 Time: 2.794	 Loss: 6.28656818
2019-06-21 16:35:35,639 - root - INFO -   Epoch 87/150	 Time: 2.790	 Loss: 6.28972359
2019-06-21 16:35:38,533 - root - INFO -   Epoch 88/150	 Time: 2.894	 Loss: 6.28749849
2019-06-21 16:35:41,337 - root - INFO -   Epoch 89/150	 Time: 2.804	 Loss: 6.28408218
2019-06-21 16:35:44,149 - root - INFO -   Epoch 90/150	 Time: 2.811	 Loss: 6.28623302
2019-06-21 16:35:46,991 - root - INFO -   Epoch 91/150	 Time: 2.842	 Loss: 6.28482883
2019-06-21 16:35:49,784 - root - INFO -   Epoch 92/150	 Time: 2.793	 Loss: 6.28868581
2019-06-21 16:35:52,601 - root - INFO -   Epoch 93/150	 Time: 2.817	 Loss: 6.28348992
2019-06-21 16:35:55,446 - root - INFO -   Epoch 94/150	 Time: 2.845	 Loss: 6.28446983
2019-06-21 16:35:58,264 - root - INFO -   Epoch 95/150	 Time: 2.818	 Loss: 6.28225022
2019-06-21 16:36:01,067 - root - INFO -   Epoch 96/150	 Time: 2.803	 Loss: 6.28199165
2019-06-21 16:36:03,859 - root - INFO -   Epoch 97/150	 Time: 2.791	 Loss: 6.28144416
2019-06-21 16:36:06,656 - root - INFO -   Epoch 98/150	 Time: 2.797	 Loss: 6.28346121
2019-06-21 16:36:09,481 - root - INFO -   Epoch 99/150	 Time: 2.824	 Loss: 6.27974322
2019-06-21 16:36:12,290 - root - INFO -   Epoch 100/150	 Time: 2.809	 Loss: 6.27882895
2019-06-21 16:36:15,077 - root - INFO -   Epoch 101/150	 Time: 2.787	 Loss: 6.28105324
2019-06-21 16:36:17,910 - root - INFO -   Epoch 102/150	 Time: 2.833	 Loss: 6.27969319
2019-06-21 16:36:20,722 - root - INFO -   Epoch 103/150	 Time: 2.811	 Loss: 6.28043122
2019-06-21 16:36:23,543 - root - INFO -   Epoch 104/150	 Time: 2.821	 Loss: 6.27961666
2019-06-21 16:36:26,331 - root - INFO -   Epoch 105/150	 Time: 2.788	 Loss: 6.27902120
2019-06-21 16:36:29,106 - root - INFO -   Epoch 106/150	 Time: 2.774	 Loss: 6.27838493
2019-06-21 16:36:31,994 - root - INFO -   Epoch 107/150	 Time: 2.888	 Loss: 6.27657344
2019-06-21 16:36:34,763 - root - INFO -   Epoch 108/150	 Time: 2.768	 Loss: 6.27942065
2019-06-21 16:36:37,586 - root - INFO -   Epoch 109/150	 Time: 2.823	 Loss: 6.27812000
2019-06-21 16:36:40,375 - root - INFO -   Epoch 110/150	 Time: 2.789	 Loss: 6.27640953
2019-06-21 16:36:43,177 - root - INFO -   Epoch 111/150	 Time: 2.802	 Loss: 6.27665903
2019-06-21 16:36:46,007 - root - INFO -   Epoch 112/150	 Time: 2.830	 Loss: 6.27628374
2019-06-21 16:36:48,881 - root - INFO -   Epoch 113/150	 Time: 2.874	 Loss: 6.27562907
2019-06-21 16:36:51,763 - root - INFO -   Epoch 114/150	 Time: 2.881	 Loss: 6.27710776
2019-06-21 16:36:54,566 - root - INFO -   Epoch 115/150	 Time: 2.803	 Loss: 6.27754698
2019-06-21 16:36:57,353 - root - INFO -   Epoch 116/150	 Time: 2.787	 Loss: 6.27424259
2019-06-21 16:37:00,189 - root - INFO -   Epoch 117/150	 Time: 2.835	 Loss: 6.27666774
2019-06-21 16:37:02,986 - root - INFO -   Epoch 118/150	 Time: 2.797	 Loss: 6.27258923
2019-06-21 16:37:05,776 - root - INFO -   Epoch 119/150	 Time: 2.789	 Loss: 6.27800430
2019-06-21 16:37:08,586 - root - INFO -   Epoch 120/150	 Time: 2.810	 Loss: 6.27338413
2019-06-21 16:37:11,369 - root - INFO -   Epoch 121/150	 Time: 2.783	 Loss: 6.27373866
2019-06-21 16:37:14,129 - root - INFO -   Epoch 122/150	 Time: 2.759	 Loss: 6.27914964
2019-06-21 16:37:16,938 - root - INFO -   Epoch 123/150	 Time: 2.809	 Loss: 6.27425677
2019-06-21 16:37:19,734 - root - INFO -   Epoch 124/150	 Time: 2.796	 Loss: 6.27438603
2019-06-21 16:37:22,536 - root - INFO -   Epoch 125/150	 Time: 2.801	 Loss: 6.27191302
2019-06-21 16:37:25,377 - root - INFO -   Epoch 126/150	 Time: 2.841	 Loss: 6.27256599
2019-06-21 16:37:28,240 - root - INFO -   Epoch 127/150	 Time: 2.863	 Loss: 6.27269117
2019-06-21 16:37:31,080 - root - INFO -   Epoch 128/150	 Time: 2.840	 Loss: 6.26967274
2019-06-21 16:37:33,931 - root - INFO -   Epoch 129/150	 Time: 2.851	 Loss: 6.27362622
2019-06-21 16:37:36,714 - root - INFO -   Epoch 130/150	 Time: 2.782	 Loss: 6.27049353
2019-06-21 16:37:39,514 - root - INFO -   Epoch 131/150	 Time: 2.800	 Loss: 6.27220723
2019-06-21 16:37:42,367 - root - INFO -   Epoch 132/150	 Time: 2.853	 Loss: 6.27060049
2019-06-21 16:37:45,327 - root - INFO -   Epoch 133/150	 Time: 2.960	 Loss: 6.26800142
2019-06-21 16:37:48,160 - root - INFO -   Epoch 134/150	 Time: 2.832	 Loss: 6.27111739
2019-06-21 16:37:50,980 - root - INFO -   Epoch 135/150	 Time: 2.820	 Loss: 6.26912043
2019-06-21 16:37:53,805 - root - INFO -   Epoch 136/150	 Time: 2.824	 Loss: 6.26757497
2019-06-21 16:37:56,609 - root - INFO -   Epoch 137/150	 Time: 2.804	 Loss: 6.26660755
2019-06-21 16:37:59,414 - root - INFO -   Epoch 138/150	 Time: 2.804	 Loss: 6.26967950
2019-06-21 16:38:02,357 - root - INFO -   Epoch 139/150	 Time: 2.943	 Loss: 6.26673369
2019-06-21 16:38:05,169 - root - INFO -   Epoch 140/150	 Time: 2.812	 Loss: 6.26796733
2019-06-21 16:38:07,955 - root - INFO -   Epoch 141/150	 Time: 2.785	 Loss: 6.26653549
2019-06-21 16:38:10,850 - root - INFO -   Epoch 142/150	 Time: 2.895	 Loss: 6.26423757
2019-06-21 16:38:13,642 - root - INFO -   Epoch 143/150	 Time: 2.793	 Loss: 6.26916021
2019-06-21 16:38:16,427 - root - INFO -   Epoch 144/150	 Time: 2.784	 Loss: 6.26794795
2019-06-21 16:38:19,266 - root - INFO -   Epoch 145/150	 Time: 2.839	 Loss: 6.26928318
2019-06-21 16:38:22,039 - root - INFO -   Epoch 146/150	 Time: 2.773	 Loss: 6.26566369
2019-06-21 16:38:24,877 - root - INFO -   Epoch 147/150	 Time: 2.837	 Loss: 6.26524731
2019-06-21 16:38:27,745 - root - INFO -   Epoch 148/150	 Time: 2.868	 Loss: 6.26473885
2019-06-21 16:38:30,568 - root - INFO -   Epoch 149/150	 Time: 2.823	 Loss: 6.26491566
2019-06-21 16:38:33,372 - root - INFO -   Epoch 150/150	 Time: 2.804	 Loss: 6.26418002
2019-06-21 16:38:33,372 - root - INFO - Pretraining time: 425.198
2019-06-21 16:38:33,373 - root - INFO - Finished pretraining.
2019-06-21 16:38:33,373 - root - INFO - Testing autoencoder...
2019-06-21 16:38:34,963 - root - INFO - Test set Loss: 6.99641947
2019-06-21 16:38:35,039 - root - INFO - Test set AUC: 61.56%
2019-06-21 16:38:35,039 - root - INFO - Autoencoder testing time: 1.666
2019-06-21 16:38:35,039 - root - INFO - Finished testing autoencoder.
2019-06-21 16:38:35,042 - root - INFO - Training optimizer: adam
2019-06-21 16:38:35,043 - root - INFO - Training learning rate: 0.0001
2019-06-21 16:38:35,043 - root - INFO - Training epochs: 150
2019-06-21 16:38:35,043 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-21 16:38:35,043 - root - INFO - Training batch size: 200
2019-06-21 16:38:35,043 - root - INFO - Training weight decay: 5e-07
2019-06-21 16:38:35,043 - root - INFO - Initializing center c...
2019-06-21 16:38:36,315 - root - INFO - Center c initialized.
2019-06-21 16:38:36,315 - root - INFO - Starting training...
2019-06-21 16:38:38,133 - root - INFO -   Epoch 1/150	 Time: 1.818	 Loss: 2.07198642
2019-06-21 16:38:39,937 - root - INFO -   Epoch 2/150	 Time: 1.804	 Loss: 0.33513286
2019-06-21 16:38:41,721 - root - INFO -   Epoch 3/150	 Time: 1.784	 Loss: 0.18112303
2019-06-21 16:38:43,528 - root - INFO -   Epoch 4/150	 Time: 1.806	 Loss: 0.12269254
2019-06-21 16:38:45,324 - root - INFO -   Epoch 5/150	 Time: 1.796	 Loss: 0.09070479
2019-06-21 16:38:47,149 - root - INFO -   Epoch 6/150	 Time: 1.824	 Loss: 0.07127831
2019-06-21 16:38:48,946 - root - INFO -   Epoch 7/150	 Time: 1.797	 Loss: 0.05735505
2019-06-21 16:38:50,752 - root - INFO -   Epoch 8/150	 Time: 1.806	 Loss: 0.04755051
2019-06-21 16:38:52,601 - root - INFO -   Epoch 9/150	 Time: 1.848	 Loss: 0.03978895
2019-06-21 16:38:54,416 - root - INFO -   Epoch 10/150	 Time: 1.815	 Loss: 0.03384107
2019-06-21 16:38:56,214 - root - INFO -   Epoch 11/150	 Time: 1.799	 Loss: 0.02950115
2019-06-21 16:38:58,026 - root - INFO -   Epoch 12/150	 Time: 1.812	 Loss: 0.02533788
2019-06-21 16:38:59,865 - root - INFO -   Epoch 13/150	 Time: 1.838	 Loss: 0.02238703
2019-06-21 16:39:01,669 - root - INFO -   Epoch 14/150	 Time: 1.804	 Loss: 0.01978572
2019-06-21 16:39:03,492 - root - INFO -   Epoch 15/150	 Time: 1.823	 Loss: 0.01707360
2019-06-21 16:39:05,286 - root - INFO -   Epoch 16/150	 Time: 1.793	 Loss: 0.01549495
2019-06-21 16:39:07,065 - root - INFO -   Epoch 17/150	 Time: 1.780	 Loss: 0.01356977
2019-06-21 16:39:08,863 - root - INFO -   Epoch 18/150	 Time: 1.797	 Loss: 0.01232979
2019-06-21 16:39:10,644 - root - INFO -   Epoch 19/150	 Time: 1.781	 Loss: 0.01086714
2019-06-21 16:39:12,429 - root - INFO -   Epoch 20/150	 Time: 1.784	 Loss: 0.00979356
2019-06-21 16:39:14,242 - root - INFO -   Epoch 21/150	 Time: 1.813	 Loss: 0.00903769
2019-06-21 16:39:16,037 - root - INFO -   Epoch 22/150	 Time: 1.795	 Loss: 0.00845061
2019-06-21 16:39:17,871 - root - INFO -   Epoch 23/150	 Time: 1.834	 Loss: 0.00757073
2019-06-21 16:39:19,714 - root - INFO -   Epoch 24/150	 Time: 1.842	 Loss: 0.00704709
2019-06-21 16:39:21,513 - root - INFO -   Epoch 25/150	 Time: 1.799	 Loss: 0.00654564
2019-06-21 16:39:23,332 - root - INFO -   Epoch 26/150	 Time: 1.819	 Loss: 0.00583832
2019-06-21 16:39:25,163 - root - INFO -   Epoch 27/150	 Time: 1.831	 Loss: 0.00573731
2019-06-21 16:39:26,995 - root - INFO -   Epoch 28/150	 Time: 1.832	 Loss: 0.00514016
2019-06-21 16:39:28,885 - root - INFO -   Epoch 29/150	 Time: 1.890	 Loss: 0.00498641
2019-06-21 16:39:30,737 - root - INFO -   Epoch 30/150	 Time: 1.851	 Loss: 0.00456908
2019-06-21 16:39:32,545 - root - INFO -   Epoch 31/150	 Time: 1.808	 Loss: 0.00439198
2019-06-21 16:39:34,361 - root - INFO -   Epoch 32/150	 Time: 1.816	 Loss: 0.00408728
2019-06-21 16:39:36,165 - root - INFO -   Epoch 33/150	 Time: 1.803	 Loss: 0.00401555
2019-06-21 16:39:37,943 - root - INFO -   Epoch 34/150	 Time: 1.778	 Loss: 0.00373633
2019-06-21 16:39:39,743 - root - INFO -   Epoch 35/150	 Time: 1.800	 Loss: 0.00356305
2019-06-21 16:39:41,529 - root - INFO -   Epoch 36/150	 Time: 1.785	 Loss: 0.00344049
2019-06-21 16:39:43,333 - root - INFO -   Epoch 37/150	 Time: 1.804	 Loss: 0.00333898
2019-06-21 16:39:45,088 - root - INFO -   Epoch 38/150	 Time: 1.755	 Loss: 0.00313793
2019-06-21 16:39:46,914 - root - INFO -   Epoch 39/150	 Time: 1.825	 Loss: 0.00303711
2019-06-21 16:39:48,748 - root - INFO -   Epoch 40/150	 Time: 1.834	 Loss: 0.00296131
2019-06-21 16:39:50,533 - root - INFO -   Epoch 41/150	 Time: 1.784	 Loss: 0.00276096
2019-06-21 16:39:52,370 - root - INFO -   Epoch 42/150	 Time: 1.836	 Loss: 0.00271422
2019-06-21 16:39:54,147 - root - INFO -   Epoch 43/150	 Time: 1.777	 Loss: 0.00257244
2019-06-21 16:39:55,991 - root - INFO -   Epoch 44/150	 Time: 1.844	 Loss: 0.00247615
2019-06-21 16:39:57,808 - root - INFO -   Epoch 45/150	 Time: 1.817	 Loss: 0.00240054
2019-06-21 16:39:59,619 - root - INFO -   Epoch 46/150	 Time: 1.811	 Loss: 0.00240239
2019-06-21 16:40:01,428 - root - INFO -   Epoch 47/150	 Time: 1.809	 Loss: 0.00224000
2019-06-21 16:40:03,247 - root - INFO -   Epoch 48/150	 Time: 1.818	 Loss: 0.00230040
2019-06-21 16:40:05,080 - root - INFO -   Epoch 49/150	 Time: 1.833	 Loss: 0.00210986
2019-06-21 16:40:06,927 - root - INFO -   Epoch 50/150	 Time: 1.847	 Loss: 0.00184603
2019-06-21 16:40:06,927 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-21 16:40:08,723 - root - INFO -   Epoch 51/150	 Time: 1.796	 Loss: 0.00187773
2019-06-21 16:40:10,524 - root - INFO -   Epoch 52/150	 Time: 1.801	 Loss: 0.00185906
2019-06-21 16:40:12,357 - root - INFO -   Epoch 53/150	 Time: 1.833	 Loss: 0.00186083
2019-06-21 16:40:14,219 - root - INFO -   Epoch 54/150	 Time: 1.862	 Loss: 0.00184140
2019-06-21 16:40:16,048 - root - INFO -   Epoch 55/150	 Time: 1.829	 Loss: 0.00182457
2019-06-21 16:40:17,872 - root - INFO -   Epoch 56/150	 Time: 1.823	 Loss: 0.00179649
2019-06-21 16:40:19,669 - root - INFO -   Epoch 57/150	 Time: 1.797	 Loss: 0.00181186
2019-06-21 16:40:21,449 - root - INFO -   Epoch 58/150	 Time: 1.780	 Loss: 0.00177642
2019-06-21 16:40:23,275 - root - INFO -   Epoch 59/150	 Time: 1.825	 Loss: 0.00180258
2019-06-21 16:40:25,104 - root - INFO -   Epoch 60/150	 Time: 1.829	 Loss: 0.00181897
2019-06-21 16:40:26,930 - root - INFO -   Epoch 61/150	 Time: 1.825	 Loss: 0.00176520
2019-06-21 16:40:28,754 - root - INFO -   Epoch 62/150	 Time: 1.824	 Loss: 0.00177376
2019-06-21 16:40:30,575 - root - INFO -   Epoch 63/150	 Time: 1.821	 Loss: 0.00176254
2019-06-21 16:40:32,367 - root - INFO -   Epoch 64/150	 Time: 1.792	 Loss: 0.00176663
2019-06-21 16:40:34,175 - root - INFO -   Epoch 65/150	 Time: 1.808	 Loss: 0.00170664
2019-06-21 16:40:35,977 - root - INFO -   Epoch 66/150	 Time: 1.802	 Loss: 0.00173967
2019-06-21 16:40:37,793 - root - INFO -   Epoch 67/150	 Time: 1.816	 Loss: 0.00180674
2019-06-21 16:40:39,605 - root - INFO -   Epoch 68/150	 Time: 1.812	 Loss: 0.00172651
2019-06-21 16:40:41,476 - root - INFO -   Epoch 69/150	 Time: 1.870	 Loss: 0.00173681
2019-06-21 16:40:43,273 - root - INFO -   Epoch 70/150	 Time: 1.797	 Loss: 0.00168027
2019-06-21 16:40:45,126 - root - INFO -   Epoch 71/150	 Time: 1.852	 Loss: 0.00170526
2019-06-21 16:40:46,932 - root - INFO -   Epoch 72/150	 Time: 1.806	 Loss: 0.00168471
2019-06-21 16:40:48,745 - root - INFO -   Epoch 73/150	 Time: 1.812	 Loss: 0.00168604
2019-06-21 16:40:50,571 - root - INFO -   Epoch 74/150	 Time: 1.826	 Loss: 0.00170717
2019-06-21 16:40:52,400 - root - INFO -   Epoch 75/150	 Time: 1.829	 Loss: 0.00172294
2019-06-21 16:40:54,213 - root - INFO -   Epoch 76/150	 Time: 1.813	 Loss: 0.00166960
2019-06-21 16:40:56,023 - root - INFO -   Epoch 77/150	 Time: 1.810	 Loss: 0.00165931
2019-06-21 16:40:57,824 - root - INFO -   Epoch 78/150	 Time: 1.801	 Loss: 0.00166018
2019-06-21 16:40:59,647 - root - INFO -   Epoch 79/150	 Time: 1.822	 Loss: 0.00163456
2019-06-21 16:41:01,486 - root - INFO -   Epoch 80/150	 Time: 1.839	 Loss: 0.00166230
2019-06-21 16:41:03,291 - root - INFO -   Epoch 81/150	 Time: 1.805	 Loss: 0.00161720
2019-06-21 16:41:05,087 - root - INFO -   Epoch 82/150	 Time: 1.796	 Loss: 0.00161546
2019-06-21 16:41:06,904 - root - INFO -   Epoch 83/150	 Time: 1.816	 Loss: 0.00161982
2019-06-21 16:41:08,741 - root - INFO -   Epoch 84/150	 Time: 1.837	 Loss: 0.00163170
2019-06-21 16:41:10,594 - root - INFO -   Epoch 85/150	 Time: 1.853	 Loss: 0.00160301
2019-06-21 16:41:12,397 - root - INFO -   Epoch 86/150	 Time: 1.803	 Loss: 0.00161568
2019-06-21 16:41:14,215 - root - INFO -   Epoch 87/150	 Time: 1.817	 Loss: 0.00158943
2019-06-21 16:41:16,037 - root - INFO -   Epoch 88/150	 Time: 1.822	 Loss: 0.00159811
2019-06-21 16:41:17,849 - root - INFO -   Epoch 89/150	 Time: 1.812	 Loss: 0.00160250
2019-06-21 16:41:19,648 - root - INFO -   Epoch 90/150	 Time: 1.799	 Loss: 0.00159002
2019-06-21 16:41:21,476 - root - INFO -   Epoch 91/150	 Time: 1.827	 Loss: 0.00158689
2019-06-21 16:41:23,295 - root - INFO -   Epoch 92/150	 Time: 1.819	 Loss: 0.00157156
2019-06-21 16:41:25,098 - root - INFO -   Epoch 93/150	 Time: 1.802	 Loss: 0.00155511
2019-06-21 16:41:26,934 - root - INFO -   Epoch 94/150	 Time: 1.836	 Loss: 0.00155849
2019-06-21 16:41:28,721 - root - INFO -   Epoch 95/150	 Time: 1.786	 Loss: 0.00153682
2019-06-21 16:41:30,549 - root - INFO -   Epoch 96/150	 Time: 1.828	 Loss: 0.00150511
2019-06-21 16:41:32,342 - root - INFO -   Epoch 97/150	 Time: 1.793	 Loss: 0.00152509
2019-06-21 16:41:34,140 - root - INFO -   Epoch 98/150	 Time: 1.797	 Loss: 0.00153593
2019-06-21 16:41:35,940 - root - INFO -   Epoch 99/150	 Time: 1.800	 Loss: 0.00153056
2019-06-21 16:41:37,747 - root - INFO -   Epoch 100/150	 Time: 1.807	 Loss: 0.00151293
2019-06-21 16:41:39,564 - root - INFO -   Epoch 101/150	 Time: 1.817	 Loss: 0.00150331
2019-06-21 16:41:41,371 - root - INFO -   Epoch 102/150	 Time: 1.807	 Loss: 0.00148989
2019-06-21 16:41:43,190 - root - INFO -   Epoch 103/150	 Time: 1.818	 Loss: 0.00150987
2019-06-21 16:41:44,994 - root - INFO -   Epoch 104/150	 Time: 1.804	 Loss: 0.00149800
2019-06-21 16:41:46,806 - root - INFO -   Epoch 105/150	 Time: 1.813	 Loss: 0.00146884
2019-06-21 16:41:48,638 - root - INFO -   Epoch 106/150	 Time: 1.832	 Loss: 0.00148578
2019-06-21 16:41:50,484 - root - INFO -   Epoch 107/150	 Time: 1.846	 Loss: 0.00148860
2019-06-21 16:41:52,301 - root - INFO -   Epoch 108/150	 Time: 1.816	 Loss: 0.00147578
2019-06-21 16:41:54,110 - root - INFO -   Epoch 109/150	 Time: 1.809	 Loss: 0.00145604
2019-06-21 16:41:55,924 - root - INFO -   Epoch 110/150	 Time: 1.814	 Loss: 0.00144714
2019-06-21 16:41:57,747 - root - INFO -   Epoch 111/150	 Time: 1.823	 Loss: 0.00146257
2019-06-21 16:41:59,536 - root - INFO -   Epoch 112/150	 Time: 1.788	 Loss: 0.00144817
2019-06-21 16:42:01,367 - root - INFO -   Epoch 113/150	 Time: 1.831	 Loss: 0.00143667
2019-06-21 16:42:03,215 - root - INFO -   Epoch 114/150	 Time: 1.848	 Loss: 0.00146328
2019-06-21 16:42:05,044 - root - INFO -   Epoch 115/150	 Time: 1.828	 Loss: 0.00145461
2019-06-21 16:42:06,882 - root - INFO -   Epoch 116/150	 Time: 1.838	 Loss: 0.00142402
2019-06-21 16:42:08,712 - root - INFO -   Epoch 117/150	 Time: 1.829	 Loss: 0.00141590
2019-06-21 16:42:10,547 - root - INFO -   Epoch 118/150	 Time: 1.835	 Loss: 0.00139314
2019-06-21 16:42:12,375 - root - INFO -   Epoch 119/150	 Time: 1.828	 Loss: 0.00139746
2019-06-21 16:42:14,190 - root - INFO -   Epoch 120/150	 Time: 1.815	 Loss: 0.00139893
2019-06-21 16:42:16,034 - root - INFO -   Epoch 121/150	 Time: 1.844	 Loss: 0.00138729
2019-06-21 16:42:17,850 - root - INFO -   Epoch 122/150	 Time: 1.815	 Loss: 0.00138703
2019-06-21 16:42:19,661 - root - INFO -   Epoch 123/150	 Time: 1.811	 Loss: 0.00140883
2019-06-21 16:42:21,482 - root - INFO -   Epoch 124/150	 Time: 1.820	 Loss: 0.00139413
2019-06-21 16:42:23,281 - root - INFO -   Epoch 125/150	 Time: 1.798	 Loss: 0.00136972
2019-06-21 16:42:25,101 - root - INFO -   Epoch 126/150	 Time: 1.821	 Loss: 0.00137244
2019-06-21 16:42:26,931 - root - INFO -   Epoch 127/150	 Time: 1.830	 Loss: 0.00135994
2019-06-21 16:42:28,761 - root - INFO -   Epoch 128/150	 Time: 1.829	 Loss: 0.00135252
2019-06-21 16:42:30,565 - root - INFO -   Epoch 129/150	 Time: 1.804	 Loss: 0.00134717
2019-06-21 16:42:32,381 - root - INFO -   Epoch 130/150	 Time: 1.816	 Loss: 0.00132805
2019-06-21 16:42:34,176 - root - INFO -   Epoch 131/150	 Time: 1.794	 Loss: 0.00135182
2019-06-21 16:42:36,034 - root - INFO -   Epoch 132/150	 Time: 1.858	 Loss: 0.00133130
2019-06-21 16:42:37,868 - root - INFO -   Epoch 133/150	 Time: 1.834	 Loss: 0.00134429
2019-06-21 16:42:39,686 - root - INFO -   Epoch 134/150	 Time: 1.818	 Loss: 0.00133179
2019-06-21 16:42:41,491 - root - INFO -   Epoch 135/150	 Time: 1.805	 Loss: 0.00131698
2019-06-21 16:42:43,299 - root - INFO -   Epoch 136/150	 Time: 1.807	 Loss: 0.00133612
2019-06-21 16:42:45,121 - root - INFO -   Epoch 137/150	 Time: 1.822	 Loss: 0.00133700
2019-06-21 16:42:46,934 - root - INFO -   Epoch 138/150	 Time: 1.813	 Loss: 0.00132484
2019-06-21 16:42:48,719 - root - INFO -   Epoch 139/150	 Time: 1.784	 Loss: 0.00129562
2019-06-21 16:42:50,542 - root - INFO -   Epoch 140/150	 Time: 1.823	 Loss: 0.00129490
2019-06-21 16:42:52,352 - root - INFO -   Epoch 141/150	 Time: 1.810	 Loss: 0.00130779
2019-06-21 16:42:54,160 - root - INFO -   Epoch 142/150	 Time: 1.808	 Loss: 0.00128966
2019-06-21 16:42:55,990 - root - INFO -   Epoch 143/150	 Time: 1.829	 Loss: 0.00130450
2019-06-21 16:42:57,824 - root - INFO -   Epoch 144/150	 Time: 1.834	 Loss: 0.00128848
2019-06-21 16:42:59,610 - root - INFO -   Epoch 145/150	 Time: 1.786	 Loss: 0.00124863
2019-06-21 16:43:01,424 - root - INFO -   Epoch 146/150	 Time: 1.813	 Loss: 0.00126593
2019-06-21 16:43:03,203 - root - INFO -   Epoch 147/150	 Time: 1.779	 Loss: 0.00125931
2019-06-21 16:43:05,021 - root - INFO -   Epoch 148/150	 Time: 1.819	 Loss: 0.00125827
2019-06-21 16:43:06,841 - root - INFO -   Epoch 149/150	 Time: 1.819	 Loss: 0.00125245
2019-06-21 16:43:08,668 - root - INFO -   Epoch 150/150	 Time: 1.827	 Loss: 0.00127037
2019-06-21 16:43:08,669 - root - INFO - Training time: 272.354
2019-06-21 16:43:08,669 - root - INFO - Finished training.
2019-06-21 16:43:08,669 - root - INFO - Starting testing...
2019-06-21 16:43:09,896 - root - INFO - Testing time: 1.227
2019-06-21 16:43:09,972 - root - INFO - Test set AUC: 71.92%
2019-06-21 16:43:09,972 - root - INFO - Finished testing.
2019-06-21 16:44:17,274 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 16:44:17,274 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 16:44:17,274 - root - INFO - Export path is ../log/hits_test.
2019-06-21 16:44:17,274 - root - INFO - Dataset: hits
2019-06-21 16:44:17,274 - root - INFO - Normal class: 1
2019-06-21 16:44:17,274 - root - INFO - Network: hits_LeNet
2019-06-21 16:44:17,274 - root - INFO - Deep SVDD objective: one-class
2019-06-21 16:44:17,274 - root - INFO - Nu-paramerter: 0.10
2019-06-21 16:44:17,292 - root - INFO - Computation device: cuda
2019-06-21 16:44:17,292 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:44:29,229 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 16:44:29,230 - root - INFO - Starting testing...
2019-06-21 16:44:31,274 - root - INFO - Testing time: 2.044
2019-06-21 16:44:31,357 - root - INFO - Test set AUC: 71.92%
2019-06-21 16:44:31,357 - root - INFO - Finished testing.
2019-06-21 18:11:08,142 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 18:11:08,142 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 18:11:08,142 - root - INFO - Export path is ../log/hits_test.
2019-06-21 18:11:08,142 - root - INFO - Dataset: hits
2019-06-21 18:11:08,142 - root - INFO - Normal class: 1
2019-06-21 18:11:08,142 - root - INFO - Network: hits_LeNet
2019-06-21 18:11:08,142 - root - INFO - Deep SVDD objective: soft-boundary
2019-06-21 18:11:08,142 - root - INFO - Nu-paramerter: 0.10
2019-06-21 18:11:08,160 - root - INFO - Computation device: cuda
2019-06-21 18:11:08,160 - root - INFO - Number of dataloader workers: 16
2019-06-21 18:11:37,324 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 18:11:37,324 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 18:11:37,325 - root - INFO - Export path is ../log/hits_test.
2019-06-21 18:11:37,325 - root - INFO - Dataset: hits
2019-06-21 18:11:37,325 - root - INFO - Normal class: 1
2019-06-21 18:11:37,325 - root - INFO - Network: hits_LeNet
2019-06-21 18:11:37,325 - root - INFO - Deep SVDD objective: soft-boundary
2019-06-21 18:11:37,325 - root - INFO - Nu-paramerter: 0.10
2019-06-21 18:11:37,329 - root - INFO - Computation device: cuda
2019-06-21 18:11:37,329 - root - INFO - Number of dataloader workers: 16
2019-06-21 18:11:47,381 - root - INFO - Pretraining: True
2019-06-21 18:11:47,381 - root - INFO - Pretraining optimizer: adam
2019-06-21 18:11:47,381 - root - INFO - Pretraining learning rate: 0.0001
2019-06-21 18:11:47,381 - root - INFO - Pretraining epochs: 150
2019-06-21 18:11:47,381 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-21 18:11:47,381 - root - INFO - Pretraining batch size: 200
2019-06-21 18:11:47,381 - root - INFO - Pretraining weight decay: 0.0005
2019-06-21 18:11:49,455 - root - INFO - Starting pretraining...
2019-06-21 18:11:52,272 - root - INFO -   Epoch 1/150	 Time: 2.817	 Loss: 11.54416211
2019-06-21 18:11:54,823 - root - INFO -   Epoch 2/150	 Time: 2.551	 Loss: 7.62552868
2019-06-21 18:11:57,347 - root - INFO -   Epoch 3/150	 Time: 2.524	 Loss: 7.19054726
2019-06-21 18:11:59,868 - root - INFO -   Epoch 4/150	 Time: 2.520	 Loss: 7.02046041
2019-06-21 18:12:02,391 - root - INFO -   Epoch 5/150	 Time: 2.523	 Loss: 6.93275627
2019-06-21 18:12:04,956 - root - INFO -   Epoch 6/150	 Time: 2.565	 Loss: 6.88102706
2019-06-21 18:12:07,520 - root - INFO -   Epoch 7/150	 Time: 2.563	 Loss: 6.83350440
2019-06-21 18:12:10,057 - root - INFO -   Epoch 8/150	 Time: 2.537	 Loss: 6.79780482
2019-06-21 18:12:12,610 - root - INFO -   Epoch 9/150	 Time: 2.553	 Loss: 6.76653352
2019-06-21 18:12:15,138 - root - INFO -   Epoch 10/150	 Time: 2.528	 Loss: 6.74306654
2019-06-21 18:12:17,677 - root - INFO -   Epoch 11/150	 Time: 2.538	 Loss: 6.71290106
2019-06-21 18:12:20,235 - root - INFO -   Epoch 12/150	 Time: 2.557	 Loss: 6.69142326
2019-06-21 18:12:22,767 - root - INFO -   Epoch 13/150	 Time: 2.532	 Loss: 6.67758083
2019-06-21 18:12:25,315 - root - INFO -   Epoch 14/150	 Time: 2.547	 Loss: 6.65893538
2019-06-21 18:12:27,895 - root - INFO -   Epoch 15/150	 Time: 2.580	 Loss: 6.63611970
2019-06-21 18:12:30,549 - root - INFO -   Epoch 16/150	 Time: 2.654	 Loss: 6.62096434
2019-06-21 18:12:33,190 - root - INFO -   Epoch 17/150	 Time: 2.641	 Loss: 6.60750883
2019-06-21 18:12:35,887 - root - INFO -   Epoch 18/150	 Time: 2.696	 Loss: 6.59133475
2019-06-21 18:12:38,457 - root - INFO -   Epoch 19/150	 Time: 2.570	 Loss: 6.57837136
2019-06-21 18:12:41,061 - root - INFO -   Epoch 20/150	 Time: 2.604	 Loss: 6.56037179
2019-06-21 18:12:43,604 - root - INFO -   Epoch 21/150	 Time: 2.542	 Loss: 6.55283886
2019-06-21 18:12:46,130 - root - INFO -   Epoch 22/150	 Time: 2.526	 Loss: 6.54698378
2019-06-21 18:12:48,719 - root - INFO -   Epoch 23/150	 Time: 2.588	 Loss: 6.53932357
2019-06-21 18:12:51,274 - root - INFO -   Epoch 24/150	 Time: 2.555	 Loss: 6.52407118
2019-06-21 18:12:53,829 - root - INFO -   Epoch 25/150	 Time: 2.554	 Loss: 6.51895568
2019-06-21 18:12:56,411 - root - INFO -   Epoch 26/150	 Time: 2.582	 Loss: 6.50932310
2019-06-21 18:12:58,957 - root - INFO -   Epoch 27/150	 Time: 2.546	 Loss: 6.51126825
2019-06-21 18:13:01,637 - root - INFO -   Epoch 28/150	 Time: 2.680	 Loss: 6.49919616
2019-06-21 18:13:04,211 - root - INFO -   Epoch 29/150	 Time: 2.574	 Loss: 6.48822573
2019-06-21 18:13:06,841 - root - INFO -   Epoch 30/150	 Time: 2.629	 Loss: 6.48888063
2019-06-21 18:13:09,401 - root - INFO -   Epoch 31/150	 Time: 2.560	 Loss: 6.47941714
2019-06-21 18:13:11,979 - root - INFO -   Epoch 32/150	 Time: 2.577	 Loss: 6.47222716
2019-06-21 18:13:14,542 - root - INFO -   Epoch 33/150	 Time: 2.563	 Loss: 6.46490335
2019-06-21 18:13:17,114 - root - INFO -   Epoch 34/150	 Time: 2.572	 Loss: 6.45959702
2019-06-21 18:13:19,641 - root - INFO -   Epoch 35/150	 Time: 2.527	 Loss: 6.44952885
2019-06-21 18:13:22,211 - root - INFO -   Epoch 36/150	 Time: 2.569	 Loss: 6.44845476
2019-06-21 18:13:24,741 - root - INFO -   Epoch 37/150	 Time: 2.530	 Loss: 6.43677307
2019-06-21 18:13:27,313 - root - INFO -   Epoch 38/150	 Time: 2.571	 Loss: 6.43056676
2019-06-21 18:13:29,861 - root - INFO -   Epoch 39/150	 Time: 2.549	 Loss: 6.42781191
2019-06-21 18:13:32,459 - root - INFO -   Epoch 40/150	 Time: 2.598	 Loss: 6.42218049
2019-06-21 18:13:35,085 - root - INFO -   Epoch 41/150	 Time: 2.625	 Loss: 6.41212350
2019-06-21 18:13:37,706 - root - INFO -   Epoch 42/150	 Time: 2.621	 Loss: 6.40815405
2019-06-21 18:13:40,269 - root - INFO -   Epoch 43/150	 Time: 2.562	 Loss: 6.39879239
2019-06-21 18:13:42,968 - root - INFO -   Epoch 44/150	 Time: 2.699	 Loss: 6.40190564
2019-06-21 18:13:45,716 - root - INFO -   Epoch 45/150	 Time: 2.747	 Loss: 6.39508501
2019-06-21 18:13:48,437 - root - INFO -   Epoch 46/150	 Time: 2.721	 Loss: 6.39411607
2019-06-21 18:13:51,053 - root - INFO -   Epoch 47/150	 Time: 2.616	 Loss: 6.38135784
2019-06-21 18:13:53,759 - root - INFO -   Epoch 48/150	 Time: 2.705	 Loss: 6.37574049
2019-06-21 18:13:56,455 - root - INFO -   Epoch 49/150	 Time: 2.696	 Loss: 6.36967783
2019-06-21 18:13:59,078 - root - INFO -   Epoch 50/150	 Time: 2.623	 Loss: 6.36119182
2019-06-21 18:13:59,078 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-21 18:14:01,661 - root - INFO -   Epoch 51/150	 Time: 2.582	 Loss: 6.36026688
2019-06-21 18:14:04,240 - root - INFO -   Epoch 52/150	 Time: 2.578	 Loss: 6.35712767
2019-06-21 18:14:06,905 - root - INFO -   Epoch 53/150	 Time: 2.665	 Loss: 6.35641624
2019-06-21 18:14:09,552 - root - INFO -   Epoch 54/150	 Time: 2.647	 Loss: 6.35871873
2019-06-21 18:14:12,128 - root - INFO -   Epoch 55/150	 Time: 2.575	 Loss: 6.35427394
2019-06-21 18:14:14,685 - root - INFO -   Epoch 56/150	 Time: 2.557	 Loss: 6.35319168
2019-06-21 18:14:17,264 - root - INFO -   Epoch 57/150	 Time: 2.579	 Loss: 6.35393321
2019-06-21 18:14:19,809 - root - INFO -   Epoch 58/150	 Time: 2.544	 Loss: 6.35226818
2019-06-21 18:14:22,394 - root - INFO -   Epoch 59/150	 Time: 2.585	 Loss: 6.35342965
2019-06-21 18:14:24,995 - root - INFO -   Epoch 60/150	 Time: 2.600	 Loss: 6.35252139
2019-06-21 18:14:27,563 - root - INFO -   Epoch 61/150	 Time: 2.568	 Loss: 6.35013380
2019-06-21 18:14:30,161 - root - INFO -   Epoch 62/150	 Time: 2.598	 Loss: 6.35342678
2019-06-21 18:14:32,749 - root - INFO -   Epoch 63/150	 Time: 2.587	 Loss: 6.35090603
2019-06-21 18:14:35,305 - root - INFO -   Epoch 64/150	 Time: 2.555	 Loss: 6.35684981
2019-06-21 18:14:37,855 - root - INFO -   Epoch 65/150	 Time: 2.550	 Loss: 6.35013013
2019-06-21 18:14:40,413 - root - INFO -   Epoch 66/150	 Time: 2.558	 Loss: 6.35183074
2019-06-21 18:14:42,966 - root - INFO -   Epoch 67/150	 Time: 2.553	 Loss: 6.34777263
2019-06-21 18:14:45,514 - root - INFO -   Epoch 68/150	 Time: 2.548	 Loss: 6.34885309
2019-06-21 18:14:48,089 - root - INFO -   Epoch 69/150	 Time: 2.575	 Loss: 6.34589219
2019-06-21 18:14:50,633 - root - INFO -   Epoch 70/150	 Time: 2.543	 Loss: 6.34998112
2019-06-21 18:14:53,191 - root - INFO -   Epoch 71/150	 Time: 2.558	 Loss: 6.34625687
2019-06-21 18:14:55,758 - root - INFO -   Epoch 72/150	 Time: 2.567	 Loss: 6.34641307
2019-06-21 18:14:58,317 - root - INFO -   Epoch 73/150	 Time: 2.559	 Loss: 6.34529173
2019-06-21 18:15:00,873 - root - INFO -   Epoch 74/150	 Time: 2.555	 Loss: 6.34771222
2019-06-21 18:15:03,440 - root - INFO -   Epoch 75/150	 Time: 2.567	 Loss: 6.34286928
2019-06-21 18:15:05,998 - root - INFO -   Epoch 76/150	 Time: 2.558	 Loss: 6.34162438
2019-06-21 18:15:08,566 - root - INFO -   Epoch 77/150	 Time: 2.567	 Loss: 6.33980017
2019-06-21 18:15:11,112 - root - INFO -   Epoch 78/150	 Time: 2.545	 Loss: 6.34385869
2019-06-21 18:15:13,673 - root - INFO -   Epoch 79/150	 Time: 2.561	 Loss: 6.34060961
2019-06-21 18:15:16,231 - root - INFO -   Epoch 80/150	 Time: 2.558	 Loss: 6.33909455
2019-06-21 18:15:18,788 - root - INFO -   Epoch 81/150	 Time: 2.558	 Loss: 6.34573680
2019-06-21 18:15:21,344 - root - INFO -   Epoch 82/150	 Time: 2.556	 Loss: 6.33657701
2019-06-21 18:15:23,926 - root - INFO -   Epoch 83/150	 Time: 2.582	 Loss: 6.33990448
2019-06-21 18:15:26,477 - root - INFO -   Epoch 84/150	 Time: 2.550	 Loss: 6.33979921
2019-06-21 18:15:29,020 - root - INFO -   Epoch 85/150	 Time: 2.543	 Loss: 6.33789559
2019-06-21 18:15:31,575 - root - INFO -   Epoch 86/150	 Time: 2.555	 Loss: 6.33760592
2019-06-21 18:15:34,141 - root - INFO -   Epoch 87/150	 Time: 2.565	 Loss: 6.34297700
2019-06-21 18:15:36,697 - root - INFO -   Epoch 88/150	 Time: 2.556	 Loss: 6.33698204
2019-06-21 18:15:39,277 - root - INFO -   Epoch 89/150	 Time: 2.579	 Loss: 6.34093686
2019-06-21 18:15:41,838 - root - INFO -   Epoch 90/150	 Time: 2.561	 Loss: 6.33330736
2019-06-21 18:15:44,391 - root - INFO -   Epoch 91/150	 Time: 2.553	 Loss: 6.33684564
2019-06-21 18:15:46,972 - root - INFO -   Epoch 92/150	 Time: 2.580	 Loss: 6.33339239
2019-06-21 18:15:49,544 - root - INFO -   Epoch 93/150	 Time: 2.572	 Loss: 6.33396837
2019-06-21 18:15:52,107 - root - INFO -   Epoch 94/150	 Time: 2.562	 Loss: 6.33344818
2019-06-21 18:15:54,685 - root - INFO -   Epoch 95/150	 Time: 2.578	 Loss: 6.33310546
2019-06-21 18:15:57,234 - root - INFO -   Epoch 96/150	 Time: 2.550	 Loss: 6.33198531
2019-06-21 18:15:59,799 - root - INFO -   Epoch 97/150	 Time: 2.564	 Loss: 6.33517740
2019-06-21 18:16:02,357 - root - INFO -   Epoch 98/150	 Time: 2.558	 Loss: 6.32924668
2019-06-21 18:16:04,909 - root - INFO -   Epoch 99/150	 Time: 2.551	 Loss: 6.33145909
2019-06-21 18:16:07,475 - root - INFO -   Epoch 100/150	 Time: 2.566	 Loss: 6.32960293
2019-06-21 18:16:10,046 - root - INFO -   Epoch 101/150	 Time: 2.571	 Loss: 6.33097757
2019-06-21 18:16:12,636 - root - INFO -   Epoch 102/150	 Time: 2.590	 Loss: 6.32751958
2019-06-21 18:16:15,203 - root - INFO -   Epoch 103/150	 Time: 2.567	 Loss: 6.32840942
2019-06-21 18:16:17,752 - root - INFO -   Epoch 104/150	 Time: 2.549	 Loss: 6.33119593
2019-06-21 18:16:20,322 - root - INFO -   Epoch 105/150	 Time: 2.570	 Loss: 6.33025069
2019-06-21 18:16:22,884 - root - INFO -   Epoch 106/150	 Time: 2.561	 Loss: 6.32761550
2019-06-21 18:16:25,456 - root - INFO -   Epoch 107/150	 Time: 2.572	 Loss: 6.32454136
2019-06-21 18:16:28,023 - root - INFO -   Epoch 108/150	 Time: 2.567	 Loss: 6.32450426
2019-06-21 18:16:30,604 - root - INFO -   Epoch 109/150	 Time: 2.581	 Loss: 6.32605883
2019-06-21 18:16:33,172 - root - INFO -   Epoch 110/150	 Time: 2.567	 Loss: 6.32222093
2019-06-21 18:16:35,721 - root - INFO -   Epoch 111/150	 Time: 2.549	 Loss: 6.32446984
2019-06-21 18:16:38,271 - root - INFO -   Epoch 112/150	 Time: 2.550	 Loss: 6.32369344
2019-06-21 18:16:40,843 - root - INFO -   Epoch 113/150	 Time: 2.571	 Loss: 6.32070286
2019-06-21 18:16:43,370 - root - INFO -   Epoch 114/150	 Time: 2.527	 Loss: 6.32397056
2019-06-21 18:16:45,948 - root - INFO -   Epoch 115/150	 Time: 2.577	 Loss: 6.32277105
2019-06-21 18:16:48,511 - root - INFO -   Epoch 116/150	 Time: 2.563	 Loss: 6.31943245
2019-06-21 18:16:51,068 - root - INFO -   Epoch 117/150	 Time: 2.557	 Loss: 6.32111397
2019-06-21 18:16:53,651 - root - INFO -   Epoch 118/150	 Time: 2.582	 Loss: 6.31989167
2019-06-21 18:16:56,235 - root - INFO -   Epoch 119/150	 Time: 2.584	 Loss: 6.31722236
2019-06-21 18:16:58,785 - root - INFO -   Epoch 120/150	 Time: 2.549	 Loss: 6.32088303
2019-06-21 18:17:01,320 - root - INFO -   Epoch 121/150	 Time: 2.535	 Loss: 6.31769754
2019-06-21 18:17:03,865 - root - INFO -   Epoch 122/150	 Time: 2.544	 Loss: 6.31737895
2019-06-21 18:17:06,433 - root - INFO -   Epoch 123/150	 Time: 2.567	 Loss: 6.32154608
2019-06-21 18:17:09,002 - root - INFO -   Epoch 124/150	 Time: 2.569	 Loss: 6.31677551
2019-06-21 18:17:11,572 - root - INFO -   Epoch 125/150	 Time: 2.570	 Loss: 6.31542867
2019-06-21 18:17:14,141 - root - INFO -   Epoch 126/150	 Time: 2.569	 Loss: 6.31628576
2019-06-21 18:17:16,717 - root - INFO -   Epoch 127/150	 Time: 2.575	 Loss: 6.31697542
2019-06-21 18:17:19,284 - root - INFO -   Epoch 128/150	 Time: 2.567	 Loss: 6.31567149
2019-06-21 18:17:21,839 - root - INFO -   Epoch 129/150	 Time: 2.555	 Loss: 6.31501883
2019-06-21 18:17:24,393 - root - INFO -   Epoch 130/150	 Time: 2.553	 Loss: 6.31233544
2019-06-21 18:17:26,938 - root - INFO -   Epoch 131/150	 Time: 2.545	 Loss: 6.31434975
2019-06-21 18:17:29,502 - root - INFO -   Epoch 132/150	 Time: 2.563	 Loss: 6.31291900
2019-06-21 18:17:32,042 - root - INFO -   Epoch 133/150	 Time: 2.540	 Loss: 6.31563316
2019-06-21 18:17:34,623 - root - INFO -   Epoch 134/150	 Time: 2.580	 Loss: 6.31102656
2019-06-21 18:17:37,171 - root - INFO -   Epoch 135/150	 Time: 2.548	 Loss: 6.31729855
2019-06-21 18:17:39,739 - root - INFO -   Epoch 136/150	 Time: 2.568	 Loss: 6.31276068
2019-06-21 18:17:42,313 - root - INFO -   Epoch 137/150	 Time: 2.573	 Loss: 6.31210526
2019-06-21 18:17:44,876 - root - INFO -   Epoch 138/150	 Time: 2.563	 Loss: 6.31247783
2019-06-21 18:17:47,450 - root - INFO -   Epoch 139/150	 Time: 2.573	 Loss: 6.31096926
2019-06-21 18:17:49,987 - root - INFO -   Epoch 140/150	 Time: 2.537	 Loss: 6.30954399
2019-06-21 18:17:52,550 - root - INFO -   Epoch 141/150	 Time: 2.563	 Loss: 6.30950807
2019-06-21 18:17:55,100 - root - INFO -   Epoch 142/150	 Time: 2.550	 Loss: 6.30943172
2019-06-21 18:17:57,666 - root - INFO -   Epoch 143/150	 Time: 2.565	 Loss: 6.31309470
2019-06-21 18:18:00,214 - root - INFO -   Epoch 144/150	 Time: 2.548	 Loss: 6.31117812
2019-06-21 18:18:02,756 - root - INFO -   Epoch 145/150	 Time: 2.542	 Loss: 6.30921875
2019-06-21 18:18:05,318 - root - INFO -   Epoch 146/150	 Time: 2.561	 Loss: 6.30677990
2019-06-21 18:18:07,902 - root - INFO -   Epoch 147/150	 Time: 2.584	 Loss: 6.31180202
2019-06-21 18:18:10,481 - root - INFO -   Epoch 148/150	 Time: 2.579	 Loss: 6.30927439
2019-06-21 18:18:13,045 - root - INFO -   Epoch 149/150	 Time: 2.564	 Loss: 6.30428603
2019-06-21 18:18:15,605 - root - INFO -   Epoch 150/150	 Time: 2.560	 Loss: 6.30595026
2019-06-21 18:18:15,606 - root - INFO - Pretraining time: 386.150
2019-06-21 18:18:15,606 - root - INFO - Finished pretraining.
2019-06-21 18:18:15,606 - root - INFO - Testing autoencoder...
2019-06-21 18:18:17,297 - root - INFO - Test set Loss: 7.19614765
2019-06-21 18:18:17,371 - root - INFO - Test set AUC: 63.58%
2019-06-21 18:18:17,372 - root - INFO - Autoencoder testing time: 1.766
2019-06-21 18:18:17,372 - root - INFO - Finished testing autoencoder.
2019-06-21 18:18:17,375 - root - INFO - Training optimizer: adam
2019-06-21 18:18:17,375 - root - INFO - Training learning rate: 0.0001
2019-06-21 18:18:17,375 - root - INFO - Training epochs: 150
2019-06-21 18:18:17,376 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-21 18:18:17,376 - root - INFO - Training batch size: 200
2019-06-21 18:18:17,376 - root - INFO - Training weight decay: 5e-07
2019-06-21 18:18:17,376 - root - INFO - Initializing center c...
2019-06-21 18:18:18,645 - root - INFO - Center c initialized.
2019-06-21 18:18:18,645 - root - INFO - Starting training...
2019-06-21 18:18:20,468 - root - INFO -   Epoch 1/150	 Time: 1.823	 Loss: 10.63169858
2019-06-21 18:18:22,283 - root - INFO -   Epoch 2/150	 Time: 1.814	 Loss: 1.43958671
2019-06-21 18:18:24,094 - root - INFO -   Epoch 3/150	 Time: 1.811	 Loss: 0.83680617
2019-06-21 18:18:25,906 - root - INFO -   Epoch 4/150	 Time: 1.812	 Loss: 0.59583519
2019-06-21 18:18:27,697 - root - INFO -   Epoch 5/150	 Time: 1.791	 Loss: 0.45971607
2019-06-21 18:18:29,507 - root - INFO -   Epoch 6/150	 Time: 1.809	 Loss: 0.36491315
2019-06-21 18:18:31,319 - root - INFO -   Epoch 7/150	 Time: 1.812	 Loss: 0.30828746
2019-06-21 18:18:33,139 - root - INFO -   Epoch 8/150	 Time: 1.820	 Loss: 0.26287823
2019-06-21 18:18:34,972 - root - INFO -   Epoch 9/150	 Time: 1.832	 Loss: 0.22191495
2019-06-21 18:18:36,766 - root - INFO -   Epoch 10/150	 Time: 1.794	 Loss: 0.19329910
2019-06-21 18:18:38,660 - root - INFO -   Epoch 11/150	 Time: 1.894	 Loss: 0.05091471
2019-06-21 18:18:40,549 - root - INFO -   Epoch 12/150	 Time: 1.888	 Loss: 0.04587418
2019-06-21 18:18:42,433 - root - INFO -   Epoch 13/150	 Time: 1.884	 Loss: 0.04618274
2019-06-21 18:18:44,347 - root - INFO -   Epoch 14/150	 Time: 1.913	 Loss: 0.04232827
2019-06-21 18:18:46,204 - root - INFO -   Epoch 15/150	 Time: 1.858	 Loss: 0.03851370
2019-06-21 18:18:48,083 - root - INFO -   Epoch 16/150	 Time: 1.879	 Loss: 0.03845634
2019-06-21 18:18:49,953 - root - INFO -   Epoch 17/150	 Time: 1.869	 Loss: 0.03414855
2019-06-21 18:18:51,846 - root - INFO -   Epoch 18/150	 Time: 1.893	 Loss: 0.03058543
2019-06-21 18:18:53,754 - root - INFO -   Epoch 19/150	 Time: 1.908	 Loss: 0.03252463
2019-06-21 18:18:55,632 - root - INFO -   Epoch 20/150	 Time: 1.877	 Loss: 0.02728422
2019-06-21 18:18:57,532 - root - INFO -   Epoch 21/150	 Time: 1.900	 Loss: 0.02932048
2019-06-21 18:18:59,453 - root - INFO -   Epoch 22/150	 Time: 1.922	 Loss: 0.02702688
2019-06-21 18:19:01,362 - root - INFO -   Epoch 23/150	 Time: 1.908	 Loss: 0.02338527
2019-06-21 18:19:03,267 - root - INFO -   Epoch 24/150	 Time: 1.905	 Loss: 0.02214376
2019-06-21 18:19:05,167 - root - INFO -   Epoch 25/150	 Time: 1.900	 Loss: 0.02062586
2019-06-21 18:19:07,138 - root - INFO -   Epoch 26/150	 Time: 1.970	 Loss: 0.02093066
2019-06-21 18:19:09,071 - root - INFO -   Epoch 27/150	 Time: 1.933	 Loss: 0.01697809
2019-06-21 18:19:10,992 - root - INFO -   Epoch 28/150	 Time: 1.921	 Loss: 0.01776506
2019-06-21 18:19:12,900 - root - INFO -   Epoch 29/150	 Time: 1.908	 Loss: 0.01569010
2019-06-21 18:19:14,811 - root - INFO -   Epoch 30/150	 Time: 1.911	 Loss: 0.01451927
2019-06-21 18:19:16,709 - root - INFO -   Epoch 31/150	 Time: 1.898	 Loss: 0.01482328
2019-06-21 18:19:18,615 - root - INFO -   Epoch 32/150	 Time: 1.906	 Loss: 0.01347974
2019-06-21 18:19:20,515 - root - INFO -   Epoch 33/150	 Time: 1.900	 Loss: 0.01290822
2019-06-21 18:19:22,393 - root - INFO -   Epoch 34/150	 Time: 1.878	 Loss: 0.01167873
2019-06-21 18:19:24,311 - root - INFO -   Epoch 35/150	 Time: 1.917	 Loss: 0.01099992
2019-06-21 18:19:26,218 - root - INFO -   Epoch 36/150	 Time: 1.907	 Loss: 0.01107235
2019-06-21 18:19:28,120 - root - INFO -   Epoch 37/150	 Time: 1.902	 Loss: 0.01031069
2019-06-21 18:19:30,001 - root - INFO -   Epoch 38/150	 Time: 1.880	 Loss: 0.00843664
2019-06-21 18:19:31,896 - root - INFO -   Epoch 39/150	 Time: 1.895	 Loss: 0.00912386
2019-06-21 18:19:33,758 - root - INFO -   Epoch 40/150	 Time: 1.862	 Loss: 0.00830869
2019-06-21 18:19:35,614 - root - INFO -   Epoch 41/150	 Time: 1.856	 Loss: 0.00852278
2019-06-21 18:19:37,510 - root - INFO -   Epoch 42/150	 Time: 1.895	 Loss: 0.00800656
2019-06-21 18:19:39,414 - root - INFO -   Epoch 43/150	 Time: 1.904	 Loss: 0.00792915
2019-06-21 18:19:41,322 - root - INFO -   Epoch 44/150	 Time: 1.907	 Loss: 0.00732988
2019-06-21 18:19:43,216 - root - INFO -   Epoch 45/150	 Time: 1.893	 Loss: 0.00644045
2019-06-21 18:19:45,097 - root - INFO -   Epoch 46/150	 Time: 1.882	 Loss: 0.00580555
2019-06-21 18:19:47,001 - root - INFO -   Epoch 47/150	 Time: 1.903	 Loss: 0.00613198
2019-06-21 18:19:48,920 - root - INFO -   Epoch 48/150	 Time: 1.919	 Loss: 0.00619302
2019-06-21 18:19:50,806 - root - INFO -   Epoch 49/150	 Time: 1.886	 Loss: 0.00533468
2019-06-21 18:19:52,723 - root - INFO -   Epoch 50/150	 Time: 1.917	 Loss: 0.00452183
2019-06-21 18:19:52,723 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-21 18:19:54,608 - root - INFO -   Epoch 51/150	 Time: 1.884	 Loss: 0.00453148
2019-06-21 18:19:56,533 - root - INFO -   Epoch 52/150	 Time: 1.925	 Loss: 0.00483003
2019-06-21 18:19:58,420 - root - INFO -   Epoch 53/150	 Time: 1.887	 Loss: 0.00480972
2019-06-21 18:20:00,323 - root - INFO -   Epoch 54/150	 Time: 1.903	 Loss: 0.00442118
2019-06-21 18:20:02,204 - root - INFO -   Epoch 55/150	 Time: 1.881	 Loss: 0.00472066
2019-06-21 18:20:04,129 - root - INFO -   Epoch 56/150	 Time: 1.924	 Loss: 0.00427774
2019-06-21 18:20:06,005 - root - INFO -   Epoch 57/150	 Time: 1.876	 Loss: 0.00429512
2019-06-21 18:20:07,897 - root - INFO -   Epoch 58/150	 Time: 1.892	 Loss: 0.00421297
2019-06-21 18:20:09,794 - root - INFO -   Epoch 59/150	 Time: 1.897	 Loss: 0.00437095
2019-06-21 18:20:11,714 - root - INFO -   Epoch 60/150	 Time: 1.919	 Loss: 0.00434249
2019-06-21 18:20:13,608 - root - INFO -   Epoch 61/150	 Time: 1.894	 Loss: 0.00414557
2019-06-21 18:20:15,525 - root - INFO -   Epoch 62/150	 Time: 1.917	 Loss: 0.00412441
2019-06-21 18:20:17,414 - root - INFO -   Epoch 63/150	 Time: 1.888	 Loss: 0.00432513
2019-06-21 18:20:19,258 - root - INFO -   Epoch 64/150	 Time: 1.843	 Loss: 0.00411591
2019-06-21 18:20:21,143 - root - INFO -   Epoch 65/150	 Time: 1.885	 Loss: 0.00412620
2019-06-21 18:20:23,050 - root - INFO -   Epoch 66/150	 Time: 1.907	 Loss: 0.00394579
2019-06-21 18:20:24,898 - root - INFO -   Epoch 67/150	 Time: 1.847	 Loss: 0.00433491
2019-06-21 18:20:26,831 - root - INFO -   Epoch 68/150	 Time: 1.933	 Loss: 0.00416359
2019-06-21 18:20:28,734 - root - INFO -   Epoch 69/150	 Time: 1.903	 Loss: 0.00401793
2019-06-21 18:20:30,637 - root - INFO -   Epoch 70/150	 Time: 1.903	 Loss: 0.00395487
2019-06-21 18:20:32,537 - root - INFO -   Epoch 71/150	 Time: 1.900	 Loss: 0.00385614
2019-06-21 18:20:34,409 - root - INFO -   Epoch 72/150	 Time: 1.871	 Loss: 0.00379075
2019-06-21 18:20:36,349 - root - INFO -   Epoch 73/150	 Time: 1.940	 Loss: 0.00389155
2019-06-21 18:20:38,244 - root - INFO -   Epoch 74/150	 Time: 1.895	 Loss: 0.00383879
2019-06-21 18:20:40,152 - root - INFO -   Epoch 75/150	 Time: 1.908	 Loss: 0.00394091
2019-06-21 18:20:42,060 - root - INFO -   Epoch 76/150	 Time: 1.907	 Loss: 0.00381100
2019-06-21 18:20:43,943 - root - INFO -   Epoch 77/150	 Time: 1.883	 Loss: 0.00381344
2019-06-21 18:20:45,848 - root - INFO -   Epoch 78/150	 Time: 1.905	 Loss: 0.00387029
2019-06-21 18:20:47,772 - root - INFO -   Epoch 79/150	 Time: 1.924	 Loss: 0.00375883
2019-06-21 18:20:49,677 - root - INFO -   Epoch 80/150	 Time: 1.904	 Loss: 0.00378004
2019-06-21 18:20:51,598 - root - INFO -   Epoch 81/150	 Time: 1.921	 Loss: 0.00363543
2019-06-21 18:20:53,476 - root - INFO -   Epoch 82/150	 Time: 1.877	 Loss: 0.00432839
2019-06-21 18:20:55,407 - root - INFO -   Epoch 83/150	 Time: 1.931	 Loss: 0.00363232
2019-06-21 18:20:57,297 - root - INFO -   Epoch 84/150	 Time: 1.889	 Loss: 0.00374825
2019-06-21 18:20:59,147 - root - INFO -   Epoch 85/150	 Time: 1.850	 Loss: 0.00371680
2019-06-21 18:21:01,054 - root - INFO -   Epoch 86/150	 Time: 1.907	 Loss: 0.00369691
2019-06-21 18:21:02,947 - root - INFO -   Epoch 87/150	 Time: 1.892	 Loss: 0.00352358
2019-06-21 18:21:04,851 - root - INFO -   Epoch 88/150	 Time: 1.903	 Loss: 0.00374758
2019-06-21 18:21:06,749 - root - INFO -   Epoch 89/150	 Time: 1.898	 Loss: 0.00359974
2019-06-21 18:21:08,606 - root - INFO -   Epoch 90/150	 Time: 1.857	 Loss: 0.00325851
2019-06-21 18:21:10,502 - root - INFO -   Epoch 91/150	 Time: 1.896	 Loss: 0.00347385
2019-06-21 18:21:12,399 - root - INFO -   Epoch 92/150	 Time: 1.896	 Loss: 0.00330452
2019-06-21 18:21:14,320 - root - INFO -   Epoch 93/150	 Time: 1.920	 Loss: 0.00356931
2019-06-21 18:21:16,240 - root - INFO -   Epoch 94/150	 Time: 1.920	 Loss: 0.00348405
2019-06-21 18:21:18,156 - root - INFO -   Epoch 95/150	 Time: 1.916	 Loss: 0.00333526
2019-06-21 18:21:20,086 - root - INFO -   Epoch 96/150	 Time: 1.930	 Loss: 0.00320289
2019-06-21 18:21:21,990 - root - INFO -   Epoch 97/150	 Time: 1.903	 Loss: 0.00345632
2019-06-21 18:21:23,921 - root - INFO -   Epoch 98/150	 Time: 1.931	 Loss: 0.00321899
2019-06-21 18:21:25,830 - root - INFO -   Epoch 99/150	 Time: 1.909	 Loss: 0.00319872
2019-06-21 18:21:27,730 - root - INFO -   Epoch 100/150	 Time: 1.900	 Loss: 0.00326148
2019-06-21 18:21:29,630 - root - INFO -   Epoch 101/150	 Time: 1.900	 Loss: 0.00327402
2019-06-21 18:21:31,533 - root - INFO -   Epoch 102/150	 Time: 1.903	 Loss: 0.00321784
2019-06-21 18:21:33,396 - root - INFO -   Epoch 103/150	 Time: 1.863	 Loss: 0.00320354
2019-06-21 18:21:35,292 - root - INFO -   Epoch 104/150	 Time: 1.895	 Loss: 0.00318866
2019-06-21 18:21:37,199 - root - INFO -   Epoch 105/150	 Time: 1.907	 Loss: 0.00305436
2019-06-21 18:21:39,076 - root - INFO -   Epoch 106/150	 Time: 1.877	 Loss: 0.00320083
2019-06-21 18:21:40,978 - root - INFO -   Epoch 107/150	 Time: 1.901	 Loss: 0.00296770
2019-06-21 18:21:42,877 - root - INFO -   Epoch 108/150	 Time: 1.899	 Loss: 0.00312827
2019-06-21 18:21:44,780 - root - INFO -   Epoch 109/150	 Time: 1.904	 Loss: 0.00318335
2019-06-21 18:21:46,693 - root - INFO -   Epoch 110/150	 Time: 1.912	 Loss: 0.00296654
2019-06-21 18:21:48,592 - root - INFO -   Epoch 111/150	 Time: 1.899	 Loss: 0.00285632
2019-06-21 18:21:50,485 - root - INFO -   Epoch 112/150	 Time: 1.893	 Loss: 0.00290053
2019-06-21 18:21:52,400 - root - INFO -   Epoch 113/150	 Time: 1.915	 Loss: 0.00289973
2019-06-21 18:21:54,289 - root - INFO -   Epoch 114/150	 Time: 1.889	 Loss: 0.00317089
2019-06-21 18:21:56,174 - root - INFO -   Epoch 115/150	 Time: 1.885	 Loss: 0.00299158
2019-06-21 18:21:58,076 - root - INFO -   Epoch 116/150	 Time: 1.902	 Loss: 0.00283403
2019-06-21 18:21:59,948 - root - INFO -   Epoch 117/150	 Time: 1.872	 Loss: 0.00282744
2019-06-21 18:22:01,836 - root - INFO -   Epoch 118/150	 Time: 1.887	 Loss: 0.00280423
2019-06-21 18:22:03,754 - root - INFO -   Epoch 119/150	 Time: 1.918	 Loss: 0.00287725
2019-06-21 18:22:05,667 - root - INFO -   Epoch 120/150	 Time: 1.912	 Loss: 0.00287783
2019-06-21 18:22:07,569 - root - INFO -   Epoch 121/150	 Time: 1.902	 Loss: 0.00286156
2019-06-21 18:22:09,501 - root - INFO -   Epoch 122/150	 Time: 1.932	 Loss: 0.00293409
2019-06-21 18:22:11,430 - root - INFO -   Epoch 123/150	 Time: 1.929	 Loss: 0.00283034
2019-06-21 18:22:13,337 - root - INFO -   Epoch 124/150	 Time: 1.906	 Loss: 0.00285239
2019-06-21 18:22:15,257 - root - INFO -   Epoch 125/150	 Time: 1.920	 Loss: 0.00283098
2019-06-21 18:22:17,139 - root - INFO -   Epoch 126/150	 Time: 1.882	 Loss: 0.00269106
2019-06-21 18:22:19,057 - root - INFO -   Epoch 127/150	 Time: 1.917	 Loss: 0.00270447
2019-06-21 18:22:20,952 - root - INFO -   Epoch 128/150	 Time: 1.895	 Loss: 0.00266423
2019-06-21 18:22:22,847 - root - INFO -   Epoch 129/150	 Time: 1.895	 Loss: 0.00269768
2019-06-21 18:22:24,751 - root - INFO -   Epoch 130/150	 Time: 1.904	 Loss: 0.00263227
2019-06-21 18:22:26,660 - root - INFO -   Epoch 131/150	 Time: 1.908	 Loss: 0.00265488
2019-06-21 18:22:28,526 - root - INFO -   Epoch 132/150	 Time: 1.866	 Loss: 0.00263220
2019-06-21 18:22:30,457 - root - INFO -   Epoch 133/150	 Time: 1.930	 Loss: 0.00253518
2019-06-21 18:22:32,364 - root - INFO -   Epoch 134/150	 Time: 1.907	 Loss: 0.00250013
2019-06-21 18:22:34,270 - root - INFO -   Epoch 135/150	 Time: 1.906	 Loss: 0.00248802
2019-06-21 18:22:36,169 - root - INFO -   Epoch 136/150	 Time: 1.898	 Loss: 0.00248053
2019-06-21 18:22:38,064 - root - INFO -   Epoch 137/150	 Time: 1.896	 Loss: 0.00254772
2019-06-21 18:22:39,982 - root - INFO -   Epoch 138/150	 Time: 1.918	 Loss: 0.00260856
2019-06-21 18:22:41,888 - root - INFO -   Epoch 139/150	 Time: 1.906	 Loss: 0.00251093
2019-06-21 18:22:43,808 - root - INFO -   Epoch 140/150	 Time: 1.920	 Loss: 0.00262451
2019-06-21 18:22:45,683 - root - INFO -   Epoch 141/150	 Time: 1.874	 Loss: 0.00259054
2019-06-21 18:22:47,586 - root - INFO -   Epoch 142/150	 Time: 1.903	 Loss: 0.00246626
2019-06-21 18:22:49,459 - root - INFO -   Epoch 143/150	 Time: 1.873	 Loss: 0.00259053
2019-06-21 18:22:51,344 - root - INFO -   Epoch 144/150	 Time: 1.884	 Loss: 0.00253192
2019-06-21 18:22:53,236 - root - INFO -   Epoch 145/150	 Time: 1.892	 Loss: 0.00240978
2019-06-21 18:22:55,148 - root - INFO -   Epoch 146/150	 Time: 1.912	 Loss: 0.00233393
2019-06-21 18:22:57,040 - root - INFO -   Epoch 147/150	 Time: 1.891	 Loss: 0.00243382
2019-06-21 18:22:58,956 - root - INFO -   Epoch 148/150	 Time: 1.916	 Loss: 0.00233296
2019-06-21 18:23:00,865 - root - INFO -   Epoch 149/150	 Time: 1.908	 Loss: 0.00233455
2019-06-21 18:23:02,768 - root - INFO -   Epoch 150/150	 Time: 1.902	 Loss: 0.00243551
2019-06-21 18:23:02,768 - root - INFO - Training time: 284.122
2019-06-21 18:23:02,768 - root - INFO - Finished training.
2019-06-21 18:23:02,768 - root - INFO - Starting testing...
2019-06-21 18:23:04,070 - root - INFO - Testing time: 1.302
2019-06-21 18:23:04,146 - root - INFO - Test set AUC: 75.37%
2019-06-21 18:23:04,146 - root - INFO - Finished testing.
2019-06-24 16:56:12,108 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 16:56:12,116 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 16:56:12,116 - root - INFO - Export path is ../log/hits_test.
2019-06-24 16:56:12,117 - root - INFO - Dataset: hits
2019-06-24 16:56:12,117 - root - INFO - Normal class: 1
2019-06-24 16:56:12,117 - root - INFO - Network: hits_LeNet
2019-06-24 16:56:12,117 - root - INFO - Deep SVDD objective: one-class
2019-06-24 16:56:12,117 - root - INFO - Nu-paramerter: 0.10
2019-06-24 16:56:12,194 - root - INFO - Computation device: cuda
2019-06-24 16:56:12,194 - root - INFO - Number of dataloader workers: 16
2019-06-24 16:56:59,333 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 16:56:59,333 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 16:56:59,333 - root - INFO - Export path is ../log/hits_test.
2019-06-24 16:56:59,333 - root - INFO - Dataset: hits
2019-06-24 16:56:59,333 - root - INFO - Normal class: 1
2019-06-24 16:56:59,333 - root - INFO - Network: hits_LeNet
2019-06-24 16:56:59,333 - root - INFO - Deep SVDD objective: one-class
2019-06-24 16:56:59,333 - root - INFO - Nu-paramerter: 0.10
2019-06-24 16:56:59,368 - root - INFO - Computation device: cuda
2019-06-24 16:56:59,368 - root - INFO - Number of dataloader workers: 16
2019-06-24 16:57:09,426 - root - INFO - Pretraining: True
2019-06-24 16:57:09,427 - root - INFO - Pretraining optimizer: adam
2019-06-24 16:57:09,427 - root - INFO - Pretraining learning rate: 0.0001
2019-06-24 16:57:09,427 - root - INFO - Pretraining epochs: 0
2019-06-24 16:57:09,427 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-24 16:57:09,427 - root - INFO - Pretraining batch size: 200
2019-06-24 16:57:09,427 - root - INFO - Pretraining weight decay: 0.0005
2019-06-24 16:57:16,119 - root - INFO - Starting pretraining...
2019-06-24 16:57:16,119 - root - INFO - Pretraining time: 0.000
2019-06-24 16:57:16,119 - root - INFO - Finished pretraining.
2019-06-24 16:57:16,119 - root - INFO - Testing autoencoder...
2019-06-24 16:57:18,902 - root - INFO - Test set Loss: 19.72662818
2019-06-24 16:57:18,996 - root - INFO - Test set AUC: 43.13%
2019-06-24 16:57:18,996 - root - INFO - Autoencoder testing time: 2.877
2019-06-24 16:57:18,996 - root - INFO - Finished testing autoencoder.
2019-06-24 16:57:19,001 - root - INFO - Training optimizer: adam
2019-06-24 16:57:19,001 - root - INFO - Training learning rate: 0.0001
2019-06-24 16:57:19,001 - root - INFO - Training epochs: 150
2019-06-24 16:57:19,001 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 16:57:19,001 - root - INFO - Training batch size: 200
2019-06-24 16:57:19,001 - root - INFO - Training weight decay: 5e-07
2019-06-24 16:57:19,002 - root - INFO - Initializing center c...
2019-06-24 16:57:20,203 - root - INFO - Center c initialized.
2019-06-24 16:57:20,203 - root - INFO - Starting training...
2019-06-24 16:58:06,492 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 16:58:06,492 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 16:58:06,492 - root - INFO - Export path is ../log/hits_test.
2019-06-24 16:58:06,492 - root - INFO - Dataset: hits
2019-06-24 16:58:06,492 - root - INFO - Normal class: 1
2019-06-24 16:58:06,492 - root - INFO - Network: hits_LeNet
2019-06-24 16:58:06,492 - root - INFO - Deep SVDD objective: one-class
2019-06-24 16:58:06,492 - root - INFO - Nu-paramerter: 0.10
2019-06-24 16:58:06,530 - root - INFO - Computation device: cuda
2019-06-24 16:58:06,530 - root - INFO - Number of dataloader workers: 16
2019-06-24 16:58:16,445 - root - INFO - Pretraining: True
2019-06-24 16:58:16,445 - root - INFO - Pretraining optimizer: adam
2019-06-24 16:58:16,445 - root - INFO - Pretraining learning rate: 0.0001
2019-06-24 16:58:16,445 - root - INFO - Pretraining epochs: 0
2019-06-24 16:58:16,445 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-24 16:58:16,445 - root - INFO - Pretraining batch size: 200
2019-06-24 16:58:16,445 - root - INFO - Pretraining weight decay: 0.0005
2019-06-24 16:58:18,506 - root - INFO - Starting pretraining...
2019-06-24 16:58:18,506 - root - INFO - Pretraining time: 0.000
2019-06-24 16:58:18,507 - root - INFO - Finished pretraining.
2019-06-24 16:58:18,507 - root - INFO - Testing autoencoder...
2019-06-24 16:58:20,349 - root - INFO - Test set Loss: 19.78744334
2019-06-24 16:58:20,419 - root - INFO - Test set AUC: 42.68%
2019-06-24 16:58:20,419 - root - INFO - Autoencoder testing time: 1.912
2019-06-24 16:58:20,419 - root - INFO - Finished testing autoencoder.
2019-06-24 16:58:20,423 - root - INFO - Training optimizer: adam
2019-06-24 16:58:20,423 - root - INFO - Training learning rate: 0.0001
2019-06-24 16:58:20,423 - root - INFO - Training epochs: 150
2019-06-24 16:58:20,423 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 16:58:20,423 - root - INFO - Training batch size: 200
2019-06-24 16:58:20,423 - root - INFO - Training weight decay: 5e-07
2019-06-24 16:58:20,423 - root - INFO - Initializing center c...
2019-06-24 16:58:21,557 - root - INFO - Center c initialized.
2019-06-24 16:58:21,557 - root - INFO - Starting training...
2019-06-24 17:00:25,677 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 17:00:25,677 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 17:00:25,677 - root - INFO - Export path is ../log/hits_test.
2019-06-24 17:00:25,677 - root - INFO - Dataset: hits
2019-06-24 17:00:25,677 - root - INFO - Normal class: 1
2019-06-24 17:00:25,677 - root - INFO - Network: hits_LeNet
2019-06-24 17:00:25,677 - root - INFO - Deep SVDD objective: one-class
2019-06-24 17:00:25,677 - root - INFO - Nu-paramerter: 0.10
2019-06-24 17:00:25,713 - root - INFO - Computation device: cuda
2019-06-24 17:00:25,714 - root - INFO - Number of dataloader workers: 16
2019-06-24 17:00:35,519 - root - INFO - Pretraining: True
2019-06-24 17:00:35,519 - root - INFO - Pretraining optimizer: adam
2019-06-24 17:00:35,519 - root - INFO - Pretraining learning rate: 0.0001
2019-06-24 17:00:35,519 - root - INFO - Pretraining epochs: 0
2019-06-24 17:00:35,519 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-24 17:00:35,519 - root - INFO - Pretraining batch size: 200
2019-06-24 17:00:35,519 - root - INFO - Pretraining weight decay: 0.0005
2019-06-24 17:00:37,582 - root - INFO - Starting pretraining...
2019-06-24 17:00:37,582 - root - INFO - Pretraining time: 0.000
2019-06-24 17:00:37,582 - root - INFO - Finished pretraining.
2019-06-24 17:00:37,582 - root - INFO - Testing autoencoder...
2019-06-24 17:00:39,430 - root - INFO - Test set Loss: 19.86799578
2019-06-24 17:00:39,502 - root - INFO - Test set AUC: 42.17%
2019-06-24 17:00:39,502 - root - INFO - Autoencoder testing time: 1.920
2019-06-24 17:00:39,502 - root - INFO - Finished testing autoencoder.
2019-06-24 17:00:39,506 - root - INFO - Training optimizer: adam
2019-06-24 17:00:39,506 - root - INFO - Training learning rate: 0.0001
2019-06-24 17:00:39,506 - root - INFO - Training epochs: 150
2019-06-24 17:00:39,506 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 17:00:39,506 - root - INFO - Training batch size: 200
2019-06-24 17:00:39,506 - root - INFO - Training weight decay: 5e-07
2019-06-24 17:00:39,507 - root - INFO - Initializing center c...
2019-06-24 17:00:40,635 - root - INFO - Center c initialized.
2019-06-24 17:00:40,635 - root - INFO - Starting training...
2019-06-24 17:01:35,609 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 17:01:35,609 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 17:01:35,609 - root - INFO - Export path is ../log/hits_test.
2019-06-24 17:01:35,609 - root - INFO - Dataset: hits
2019-06-24 17:01:35,609 - root - INFO - Normal class: 1
2019-06-24 17:01:35,609 - root - INFO - Network: hits_LeNet
2019-06-24 17:01:35,609 - root - INFO - Deep SVDD objective: one-class
2019-06-24 17:01:35,609 - root - INFO - Nu-paramerter: 0.10
2019-06-24 17:01:35,648 - root - INFO - Computation device: cuda
2019-06-24 17:01:35,648 - root - INFO - Number of dataloader workers: 16
2019-06-24 17:01:45,509 - root - INFO - Pretraining: False
2019-06-24 17:01:45,509 - root - INFO - Training optimizer: adam
2019-06-24 17:01:45,509 - root - INFO - Training learning rate: 0.0001
2019-06-24 17:01:45,509 - root - INFO - Training epochs: 150
2019-06-24 17:01:45,509 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 17:01:45,509 - root - INFO - Training batch size: 200
2019-06-24 17:01:45,509 - root - INFO - Training weight decay: 5e-07
2019-06-24 17:01:47,581 - root - INFO - Initializing center c...
2019-06-24 17:01:48,903 - root - INFO - Center c initialized.
2019-06-24 17:01:48,903 - root - INFO - Starting training...
2019-06-24 17:05:11,877 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 17:05:11,877 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 17:05:11,877 - root - INFO - Export path is ../log/hits_test.
2019-06-24 17:05:11,877 - root - INFO - Dataset: hits
2019-06-24 17:05:11,877 - root - INFO - Normal class: 1
2019-06-24 17:05:11,877 - root - INFO - Network: hits_LeNet
2019-06-24 17:05:11,877 - root - INFO - Deep SVDD objective: one-class
2019-06-24 17:05:11,877 - root - INFO - Nu-paramerter: 0.10
2019-06-24 17:05:11,913 - root - INFO - Computation device: cuda
2019-06-24 17:05:11,913 - root - INFO - Number of dataloader workers: 16
2019-06-24 17:05:21,777 - root - INFO - Pretraining: False
2019-06-24 17:05:21,777 - root - INFO - Training optimizer: adam
2019-06-24 17:05:21,777 - root - INFO - Training learning rate: 0.0001
2019-06-24 17:05:21,778 - root - INFO - Training epochs: 150
2019-06-24 17:05:21,778 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 17:05:21,778 - root - INFO - Training batch size: 200
2019-06-24 17:05:21,778 - root - INFO - Training weight decay: 5e-07
2019-06-24 17:05:23,834 - root - INFO - Initializing center c...
2019-06-24 17:05:25,140 - root - INFO - Center c initialized.
2019-06-24 17:05:25,140 - root - INFO - Starting training...
2019-06-24 17:05:27,246 - root - INFO -   Validation Time: 1.572	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.14742230
2019-06-24 17:05:28,795 - root - INFO -   Validation Time: 1.543	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.16165128
2019-06-24 17:05:30,369 - root - INFO -   Validation Time: 1.570	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.18860147
2019-06-24 17:05:31,907 - root - INFO -   Validation Time: 1.535	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.23007948
2019-06-24 17:05:33,479 - root - INFO -   Validation Time: 1.568	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.28684876
2019-06-24 17:05:35,041 - root - INFO -   Validation Time: 1.552	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.35592752
2019-06-24 17:05:36,729 - root - INFO -   Validation Time: 1.685	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.43378155
2019-06-24 17:05:38,268 - root - INFO -   Validation Time: 1.535	 Acc_all: 0.50337747	 Acc_Normal: 1.00000000	 Loss_Normal: 0.52018007
2019-06-24 17:05:39,835 - root - INFO -   Validation Time: 1.564	 Acc_all: 0.53367548	 Acc_Normal: 0.99926667	 Loss_Normal: 0.61353842
2019-06-24 17:05:41,377 - root - INFO -   Validation Time: 1.533	 Acc_all: 0.51129138	 Acc_Normal: 0.90272187	 Loss_Normal: 0.70971941
2019-06-24 17:05:42,919 - root - INFO -   Validation Time: 1.538	 Acc_all: 0.46509933	 Acc_Normal: 0.77136698	 Loss_Normal: 0.81504229
2019-06-24 17:05:44,481 - root - INFO -   Validation Time: 1.559	 Acc_all: 0.43950330	 Acc_Normal: 0.65341682	 Loss_Normal: 0.91924967
2019-06-24 17:05:46,026 - root - INFO -   Validation Time: 1.542	 Acc_all: 0.41367549	 Acc_Normal: 0.51433197	 Loss_Normal: 1.02702815
2019-06-24 17:05:47,585 - root - INFO -   Validation Time: 1.556	 Acc_all: 0.39860926	 Acc_Normal: 0.38685252	 Loss_Normal: 1.12520895
2019-06-24 17:05:49,103 - root - INFO -   Validation Time: 1.516	 Acc_all: 0.39119204	 Acc_Normal: 0.26090235	 Loss_Normal: 1.23276014
2019-06-24 17:05:50,660 - root - INFO -   Validation Time: 1.554	 Acc_all: 0.39599337	 Acc_Normal: 0.17135488	 Loss_Normal: 1.32956888
2019-06-24 17:05:52,185 - root - INFO -   Validation Time: 1.522	 Acc_all: 0.40566224	 Acc_Normal: 0.11241481	 Loss_Normal: 1.41825394
2019-06-24 17:05:53,721 - root - INFO -   Validation Time: 1.533	 Acc_all: 0.41695363	 Acc_Normal: 0.07594209	 Loss_Normal: 1.49903625
2019-06-24 17:05:55,275 - root - INFO -   Validation Time: 1.552	 Acc_all: 0.43258277	 Acc_Normal: 0.04973872	 Loss_Normal: 1.58017874
2019-06-24 17:05:56,826 - root - INFO -   Validation Time: 1.547	 Acc_all: 0.44837747	 Acc_Normal: 0.03840269	 Loss_Normal: 1.63515449
2019-06-24 17:05:58,358 - root - INFO -   Validation Time: 1.529	 Acc_all: 0.46692052	 Acc_Normal: 0.02960135	 Loss_Normal: 1.68943536
2019-06-24 17:05:59,929 - root - INFO -   Validation Time: 1.569	 Acc_all: 0.48062913	 Acc_Normal: 0.02320135	 Loss_Normal: 1.73823797
2019-06-24 17:06:01,489 - root - INFO -   Validation Time: 1.557	 Acc_all: 0.48923840	 Acc_Normal: 0.02140135	 Loss_Normal: 1.76812971
2019-06-24 17:06:03,018 - root - INFO -   Validation Time: 1.525	 Acc_all: 0.49367548	 Acc_Normal: 0.01886869	 Loss_Normal: 1.79855360
2019-06-24 17:06:04,564 - root - INFO -   Validation Time: 1.544	 Acc_all: 0.49635760	 Acc_Normal: 0.01640202	 Loss_Normal: 1.82940047
2019-06-24 17:06:06,095 - root - INFO -   Validation Time: 1.527	 Acc_all: 0.49811257	 Acc_Normal: 0.01633535	 Loss_Normal: 1.84373580
2019-06-24 17:06:07,650 - root - INFO -   Validation Time: 1.551	 Acc_all: 0.49841058	 Acc_Normal: 0.01546801	 Loss_Normal: 1.85965682
2019-06-24 17:06:09,200 - root - INFO -   Validation Time: 1.547	 Acc_all: 0.49907284	 Acc_Normal: 0.01626869	 Loss_Normal: 1.85689769
2019-06-24 17:06:10,745 - root - INFO -   Validation Time: 1.542	 Acc_all: 0.50009933	 Acc_Normal: 0.01740202	 Loss_Normal: 1.86091775
2019-06-24 17:06:12,322 - root - INFO -   Validation Time: 1.574	 Acc_all: 0.50082780	 Acc_Normal: 0.01860337	 Loss_Normal: 1.85824317
2019-06-24 17:06:13,870 - root - INFO -   Validation Time: 1.545	 Acc_all: 0.50119204	 Acc_Normal: 0.01947003	 Loss_Normal: 1.85624993
2019-06-24 17:06:15,404 - root - INFO -   Validation Time: 1.531	 Acc_all: 0.50182118	 Acc_Normal: 0.02013670	 Loss_Normal: 1.85753090
2019-06-24 17:06:16,940 - root - INFO -   Validation Time: 1.533	 Acc_all: 0.50254966	 Acc_Normal: 0.02160337	 Loss_Normal: 1.84549952
2019-06-24 17:06:18,513 - root - INFO -   Validation Time: 1.569	 Acc_all: 0.50288078	 Acc_Normal: 0.02273670	 Loss_Normal: 1.83784578
2019-06-24 17:06:20,095 - root - INFO -   Validation Time: 1.579	 Acc_all: 0.50397350	 Acc_Normal: 0.02447071	 Loss_Normal: 1.83516971
2019-06-24 17:06:21,684 - root - INFO -   Validation Time: 1.585	 Acc_all: 0.50516555	 Acc_Normal: 0.02640404	 Loss_Normal: 1.83339210
2019-06-24 17:06:23,234 - root - INFO -   Validation Time: 1.546	 Acc_all: 0.50586092	 Acc_Normal: 0.02707205	 Loss_Normal: 1.83859982
2019-06-24 17:06:24,824 - root - INFO -   Validation Time: 1.586	 Acc_all: 0.50658939	 Acc_Normal: 0.02807205	 Loss_Normal: 1.84035567
2019-06-24 17:06:26,403 - root - INFO -   Validation Time: 1.575	 Acc_all: 0.50692052	 Acc_Normal: 0.02840539	 Loss_Normal: 1.85079409
2019-06-24 17:06:27,961 - root - INFO -   Validation Time: 1.555	 Acc_all: 0.50771522	 Acc_Normal: 0.03040539	 Loss_Normal: 1.85347485
2019-06-24 17:06:29,549 - root - INFO -   Validation Time: 1.584	 Acc_all: 0.50844370	 Acc_Normal: 0.03300539	 Loss_Normal: 1.85107583
2019-06-24 17:06:31,091 - root - INFO -   Validation Time: 1.538	 Acc_all: 0.50937085	 Acc_Normal: 0.03467138	 Loss_Normal: 1.85209599
2019-06-24 17:06:32,674 - root - INFO -   Validation Time: 1.580	 Acc_all: 0.50900661	 Acc_Normal: 0.03427071	 Loss_Normal: 1.86071492
2019-06-24 17:06:34,251 - root - INFO -   Validation Time: 1.574	 Acc_all: 0.50913906	 Acc_Normal: 0.03473737	 Loss_Normal: 1.87204206
2019-06-24 17:06:35,827 - root - INFO -   Validation Time: 1.572	 Acc_all: 0.50927151	 Acc_Normal: 0.03540337	 Loss_Normal: 1.87895295
2019-06-24 17:06:37,368 - root - INFO -   Validation Time: 1.537	 Acc_all: 0.50956952	 Acc_Normal: 0.03607071	 Loss_Normal: 1.88291152
2019-06-24 17:06:38,963 - root - INFO -   Validation Time: 1.592	 Acc_all: 0.50933774	 Acc_Normal: 0.03580337	 Loss_Normal: 1.89187085
2019-06-24 17:06:40,503 - root - INFO -   Validation Time: 1.536	 Acc_all: 0.50903972	 Acc_Normal: 0.03547003	 Loss_Normal: 1.89758315
2019-06-24 17:06:42,064 - root - INFO -   Validation Time: 1.557	 Acc_all: 0.50940396	 Acc_Normal: 0.03653670	 Loss_Normal: 1.89881888
2019-06-24 17:06:43,607 - root - INFO -   Validation Time: 1.540	 Acc_all: 0.50956952	 Acc_Normal: 0.03767071	 Loss_Normal: 1.89824864
2019-06-24 17:06:45,172 - root - INFO -   Validation Time: 1.561	 Acc_all: 0.50943707	 Acc_Normal: 0.03727071	 Loss_Normal: 1.90261443
2019-06-24 17:06:46,742 - root - INFO -   Validation Time: 1.566	 Acc_all: 0.50973509	 Acc_Normal: 0.03780404	 Loss_Normal: 1.90478701
2019-06-24 17:06:48,326 - root - INFO -   Validation Time: 1.580	 Acc_all: 0.51003310	 Acc_Normal: 0.03887071	 Loss_Normal: 1.90098068
2019-06-24 17:06:49,905 - root - INFO -   Validation Time: 1.576	 Acc_all: 0.51036423	 Acc_Normal: 0.04047138	 Loss_Normal: 1.90127607
2019-06-24 17:06:51,477 - root - INFO -   Validation Time: 1.568	 Acc_all: 0.51079469	 Acc_Normal: 0.04220471	 Loss_Normal: 1.89824172
2019-06-24 17:06:53,046 - root - INFO -   Validation Time: 1.565	 Acc_all: 0.51079469	 Acc_Normal: 0.04227138	 Loss_Normal: 1.89889654
2019-06-24 17:06:54,583 - root - INFO -   Validation Time: 1.534	 Acc_all: 0.51152317	 Acc_Normal: 0.04400471	 Loss_Normal: 1.89282490
2019-06-24 17:06:56,145 - root - INFO -   Validation Time: 1.558	 Acc_all: 0.51182118	 Acc_Normal: 0.04493805	 Loss_Normal: 1.88971008
2019-06-24 17:06:57,756 - root - INFO -   Validation Time: 1.607	 Acc_all: 0.51258277	 Acc_Normal: 0.04653805	 Loss_Normal: 1.88450831
2019-06-24 17:06:59,335 - root - INFO -   Validation Time: 1.575	 Acc_all: 0.51377482	 Acc_Normal: 0.04900471	 Loss_Normal: 1.87697002
2019-06-24 17:07:00,881 - root - INFO -   Validation Time: 1.543	 Acc_all: 0.51420529	 Acc_Normal: 0.05040539	 Loss_Normal: 1.86770971
2019-06-24 17:07:02,462 - root - INFO -   Validation Time: 1.577	 Acc_all: 0.51526489	 Acc_Normal: 0.05287138	 Loss_Normal: 1.85801430
2019-06-24 17:07:04,091 - root - INFO -   Validation Time: 1.625	 Acc_all: 0.51615893	 Acc_Normal: 0.05473805	 Loss_Normal: 1.84901059
2019-06-24 17:07:05,700 - root - INFO -   Validation Time: 1.605	 Acc_all: 0.51728476	 Acc_Normal: 0.05740471	 Loss_Normal: 1.83566094
2019-06-24 17:07:07,299 - root - INFO -   Validation Time: 1.595	 Acc_all: 0.51877482	 Acc_Normal: 0.06060471	 Loss_Normal: 1.82132637
2019-06-24 17:07:08,987 - root - INFO -   Validation Time: 1.685	 Acc_all: 0.52009932	 Acc_Normal: 0.06407273	 Loss_Normal: 1.80524352
2019-06-24 17:07:10,662 - root - INFO -   Validation Time: 1.670	 Acc_all: 0.52139071	 Acc_Normal: 0.06714007	 Loss_Normal: 1.78953502
2019-06-24 17:07:12,251 - root - INFO -   Validation Time: 1.586	 Acc_all: 0.52307946	 Acc_Normal: 0.07094007	 Loss_Normal: 1.77355320
2019-06-24 17:07:13,842 - root - INFO -   Validation Time: 1.587	 Acc_all: 0.52470197	 Acc_Normal: 0.07454074	 Loss_Normal: 1.76151385
2019-06-24 17:07:15,492 - root - INFO -   Validation Time: 1.646	 Acc_all: 0.52539734	 Acc_Normal: 0.07687407	 Loss_Normal: 1.74894280
2019-06-24 17:07:17,059 - root - INFO -   Validation Time: 1.563	 Acc_all: 0.52688740	 Acc_Normal: 0.08094141	 Loss_Normal: 1.73244411
2019-06-24 17:07:18,675 - root - INFO -   Validation Time: 1.612	 Acc_all: 0.52844369	 Acc_Normal: 0.08440875	 Loss_Normal: 1.71646195
2019-06-24 17:07:20,308 - root - INFO -   Validation Time: 1.629	 Acc_all: 0.52976820	 Acc_Normal: 0.08774209	 Loss_Normal: 1.70200539
2019-06-24 17:07:21,921 - root - INFO -   Validation Time: 1.609	 Acc_all: 0.53129138	 Acc_Normal: 0.09140875	 Loss_Normal: 1.68960391
2019-06-24 17:07:23,455 - root - INFO -   Validation Time: 1.531	 Acc_all: 0.53284767	 Acc_Normal: 0.09507542	 Loss_Normal: 1.67463226
2019-06-24 17:07:24,975 - root - INFO -   Validation Time: 1.516	 Acc_all: 0.53503310	 Acc_Normal: 0.10034209	 Loss_Normal: 1.65876712
2019-06-24 17:07:26,584 - root - INFO -   Validation Time: 1.606	 Acc_all: 0.53655628	 Acc_Normal: 0.10494410	 Loss_Normal: 1.64292503
2019-06-24 17:07:28,171 - root - INFO -   Validation Time: 1.583	 Acc_all: 0.53947019	 Acc_Normal: 0.11194410	 Loss_Normal: 1.62975194
2019-06-24 17:07:29,749 - root - INFO -   Validation Time: 1.575	 Acc_all: 0.54211919	 Acc_Normal: 0.11867744	 Loss_Normal: 1.61175519
2019-06-24 17:07:31,348 - root - INFO -   Validation Time: 1.595	 Acc_all: 0.54450330	 Acc_Normal: 0.12454612	 Loss_Normal: 1.59595069
2019-06-24 17:07:32,904 - root - INFO -   Validation Time: 1.553	 Acc_all: 0.54745032	 Acc_Normal: 0.13148080	 Loss_Normal: 1.58114526
2019-06-24 17:07:34,477 - root - INFO -   Validation Time: 1.569	 Acc_all: 0.55662251	 Acc_Normal: 0.13761481	 Loss_Normal: 1.56567620
2019-06-24 17:07:36,063 - root - INFO -   Validation Time: 1.582	 Acc_all: 0.55963575	 Acc_Normal: 0.14481481	 Loss_Normal: 1.54795506
2019-06-24 17:07:37,649 - root - INFO -   Validation Time: 1.582	 Acc_all: 0.56221853	 Acc_Normal: 0.15188148	 Loss_Normal: 1.53375458
2019-06-24 17:07:39,244 - root - INFO -   Validation Time: 1.591	 Acc_all: 0.56612581	 Acc_Normal: 0.16114949	 Loss_Normal: 1.51777751
2019-06-24 17:07:40,832 - root - INFO -   Validation Time: 1.584	 Acc_all: 0.56801323	 Acc_Normal: 0.16628282	 Loss_Normal: 1.50322385
2019-06-24 17:07:42,401 - root - INFO -   Validation Time: 1.566	 Acc_all: 0.57327813	 Acc_Normal: 0.17948484	 Loss_Normal: 1.48378528
2019-06-24 17:07:44,006 - root - INFO -   Validation Time: 1.601	 Acc_all: 0.57675495	 Acc_Normal: 0.18808754	 Loss_Normal: 1.46821087
2019-06-24 17:07:45,563 - root - INFO -   Validation Time: 1.553	 Acc_all: 0.58046356	 Acc_Normal: 0.19815622	 Loss_Normal: 1.45181868
2019-06-24 17:07:47,106 - root - INFO -   Validation Time: 1.539	 Acc_all: 0.58288078	 Acc_Normal: 0.20415690	 Loss_Normal: 1.43752275
2019-06-24 17:07:48,674 - root - INFO -   Validation Time: 1.564	 Acc_all: 0.58658939	 Acc_Normal: 0.21349158	 Loss_Normal: 1.42110541
2019-06-24 17:07:50,254 - root - INFO -   Validation Time: 1.577	 Acc_all: 0.59062913	 Acc_Normal: 0.22409292	 Loss_Normal: 1.40451756
2019-06-24 17:07:51,838 - root - INFO -   Validation Time: 1.580	 Acc_all: 0.59490065	 Acc_Normal: 0.23562760	 Loss_Normal: 1.38706163
2019-06-24 17:07:53,436 - root - INFO -   Validation Time: 1.594	 Acc_all: 0.59884105	 Acc_Normal: 0.24536228	 Loss_Normal: 1.37279505
2019-06-24 17:07:55,008 - root - INFO -   Validation Time: 1.567	 Acc_all: 0.60341058	 Acc_Normal: 0.25796430	 Loss_Normal: 1.35466124
2019-06-24 17:07:56,647 - root - INFO -   Validation Time: 1.636	 Acc_all: 0.60695363	 Acc_Normal: 0.26689966	 Loss_Normal: 1.33989988
2019-06-24 17:07:58,267 - root - INFO -   Validation Time: 1.615	 Acc_all: 0.61029800	 Acc_Normal: 0.27523232	 Loss_Normal: 1.32690527
2019-06-24 17:07:59,856 - root - INFO -   Validation Time: 1.586	 Acc_all: 0.61552979	 Acc_Normal: 0.28850370	 Loss_Normal: 1.31027534
2019-06-24 17:08:02,627 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 17:08:02,628 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 17:08:02,628 - root - INFO - Export path is ../log/hits_test.
2019-06-24 17:08:02,628 - root - INFO - Dataset: hits
2019-06-24 17:08:02,628 - root - INFO - Normal class: 1
2019-06-24 17:08:02,628 - root - INFO - Network: hits_LeNet
2019-06-24 17:08:02,628 - root - INFO - Deep SVDD objective: one-class
2019-06-24 17:08:02,628 - root - INFO - Nu-paramerter: 0.10
2019-06-24 17:08:02,632 - root - INFO - Computation device: cuda
2019-06-24 17:08:02,632 - root - INFO - Number of dataloader workers: 16
2019-06-24 17:08:12,668 - root - INFO - Pretraining: False
2019-06-24 17:08:12,668 - root - INFO - Training optimizer: adam
2019-06-24 17:08:12,668 - root - INFO - Training learning rate: 0.0001
2019-06-24 17:08:12,668 - root - INFO - Training epochs: 150
2019-06-24 17:08:12,668 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 17:08:12,668 - root - INFO - Training batch size: 200
2019-06-24 17:08:12,668 - root - INFO - Training weight decay: 5e-07
2019-06-24 17:08:14,815 - root - INFO - Initializing center c...
2019-06-24 17:08:16,228 - root - INFO - Center c initialized.
2019-06-24 17:08:16,228 - root - INFO - Starting training...
2019-06-24 17:08:17,941 - root - INFO -   Epoch 1/150	 Time: 1.712	 Loss: 1.26117732
2019-06-24 17:08:19,635 - root - INFO -   Epoch 2/150	 Time: 1.694	 Loss: 0.21651641
2019-06-24 17:08:21,336 - root - INFO -   Epoch 3/150	 Time: 1.701	 Loss: 0.12901738
2019-06-24 17:08:23,025 - root - INFO -   Epoch 4/150	 Time: 1.689	 Loss: 0.08746593
2019-06-24 17:08:24,728 - root - INFO -   Epoch 5/150	 Time: 1.702	 Loss: 0.06152400
2019-06-24 17:08:26,417 - root - INFO -   Epoch 6/150	 Time: 1.689	 Loss: 0.04512289
2019-06-24 17:08:28,174 - root - INFO -   Epoch 7/150	 Time: 1.757	 Loss: 0.03461054
2019-06-24 17:08:29,894 - root - INFO -   Epoch 8/150	 Time: 1.719	 Loss: 0.02715318
2019-06-24 17:08:31,594 - root - INFO -   Epoch 9/150	 Time: 1.700	 Loss: 0.02175111
2019-06-24 17:08:33,237 - root - INFO -   Epoch 10/150	 Time: 1.642	 Loss: 0.01761547
2019-06-24 17:08:37,192 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 17:08:37,192 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 17:08:37,192 - root - INFO - Export path is ../log/hits_test.
2019-06-24 17:08:37,192 - root - INFO - Dataset: hits
2019-06-24 17:08:37,192 - root - INFO - Normal class: 1
2019-06-24 17:08:37,193 - root - INFO - Network: hits_LeNet
2019-06-24 17:08:37,193 - root - INFO - Deep SVDD objective: one-class
2019-06-24 17:08:37,193 - root - INFO - Nu-paramerter: 0.10
2019-06-24 17:08:37,222 - root - INFO - Computation device: cuda
2019-06-24 17:08:37,222 - root - INFO - Number of dataloader workers: 16
2019-06-24 17:08:47,113 - root - INFO - Pretraining: False
2019-06-24 17:08:47,113 - root - INFO - Training optimizer: adam
2019-06-24 17:08:47,113 - root - INFO - Training learning rate: 0.0001
2019-06-24 17:08:47,113 - root - INFO - Training epochs: 150
2019-06-24 17:08:47,113 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 17:08:47,113 - root - INFO - Training batch size: 200
2019-06-24 17:08:47,113 - root - INFO - Training weight decay: 5e-07
2019-06-24 17:08:49,164 - root - INFO - Initializing center c...
2019-06-24 17:08:50,498 - root - INFO - Center c initialized.
2019-06-24 17:08:50,498 - root - INFO - Starting training...
2019-06-24 17:08:52,206 - root - INFO -   Epoch 1/150	 Time: 1.708	 Loss: 0.86223313
2019-06-24 17:08:53,753 - root - INFO -   Validation Time: 1.547	 Acc_all: 0.61456952	 Acc_Normal: 0.99906667	 Loss_Normal: 0.24470290
2019-06-24 17:08:55,426 - root - INFO -   Epoch 2/150	 Time: 1.672	 Loss: 0.16999734
2019-06-24 17:08:56,971 - root - INFO -   Validation Time: 1.545	 Acc_all: 0.51923840	 Acc_Normal: 0.99993333	 Loss_Normal: 0.12282479
2019-06-24 17:08:58,655 - root - INFO -   Epoch 3/150	 Time: 1.683	 Loss: 0.09709337
2019-06-24 17:09:00,192 - root - INFO -   Validation Time: 1.537	 Acc_all: 0.50417217	 Acc_Normal: 1.00000000	 Loss_Normal: 0.07612120
2019-06-24 17:09:01,898 - root - INFO -   Epoch 4/150	 Time: 1.706	 Loss: 0.06336672
2019-06-24 17:09:03,428 - root - INFO -   Validation Time: 1.529	 Acc_all: 0.50341058	 Acc_Normal: 1.00000000	 Loss_Normal: 0.05191982
2019-06-24 17:09:05,076 - root - INFO -   Epoch 5/150	 Time: 1.648	 Loss: 0.04420491
2019-06-24 17:09:06,633 - root - INFO -   Validation Time: 1.556	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.03768376
2019-06-24 17:09:08,408 - root - INFO -   Epoch 6/150	 Time: 1.774	 Loss: 0.03221047
2019-06-24 17:09:09,937 - root - INFO -   Validation Time: 1.529	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.02796412
2019-06-24 17:09:11,625 - root - INFO -   Epoch 7/150	 Time: 1.688	 Loss: 0.02418662
2019-06-24 17:09:13,160 - root - INFO -   Validation Time: 1.535	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.02064474
2019-06-24 17:09:14,794 - root - INFO -   Epoch 8/150	 Time: 1.633	 Loss: 0.01856908
2019-06-24 17:09:16,322 - root - INFO -   Validation Time: 1.528	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.01598881
2019-06-24 17:09:18,024 - root - INFO -   Epoch 9/150	 Time: 1.701	 Loss: 0.01454244
2019-06-24 17:09:19,538 - root - INFO -   Validation Time: 1.514	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.01246948
2019-06-24 17:09:21,201 - root - INFO -   Epoch 10/150	 Time: 1.662	 Loss: 0.01155429
2019-06-24 17:09:22,747 - root - INFO -   Validation Time: 1.546	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.01018749
2019-06-24 17:09:24,436 - root - INFO -   Epoch 11/150	 Time: 1.688	 Loss: 0.00921452
2019-06-24 17:09:25,983 - root - INFO -   Validation Time: 1.547	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00806502
2019-06-24 17:09:27,653 - root - INFO -   Epoch 12/150	 Time: 1.669	 Loss: 0.00743155
2019-06-24 17:09:29,186 - root - INFO -   Validation Time: 1.532	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00659688
2019-06-24 17:09:30,883 - root - INFO -   Epoch 13/150	 Time: 1.697	 Loss: 0.00609333
2019-06-24 17:09:32,405 - root - INFO -   Validation Time: 1.523	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00570628
2019-06-24 17:09:34,073 - root - INFO -   Epoch 14/150	 Time: 1.667	 Loss: 0.00496221
2019-06-24 17:09:35,617 - root - INFO -   Validation Time: 1.543	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00430607
2019-06-24 17:09:37,288 - root - INFO -   Epoch 15/150	 Time: 1.672	 Loss: 0.00407917
2019-06-24 17:09:38,814 - root - INFO -   Validation Time: 1.526	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00362148
2019-06-24 17:09:40,457 - root - INFO -   Epoch 16/150	 Time: 1.642	 Loss: 0.00337892
2019-06-24 17:09:41,984 - root - INFO -   Validation Time: 1.527	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00295683
2019-06-24 17:09:43,691 - root - INFO -   Epoch 17/150	 Time: 1.707	 Loss: 0.00275750
2019-06-24 17:09:45,228 - root - INFO -   Validation Time: 1.536	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00236650
2019-06-24 17:09:46,892 - root - INFO -   Epoch 18/150	 Time: 1.664	 Loss: 0.00232304
2019-06-24 17:09:48,428 - root - INFO -   Validation Time: 1.536	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00203199
2019-06-24 17:09:50,122 - root - INFO -   Epoch 19/150	 Time: 1.694	 Loss: 0.00192474
2019-06-24 17:09:51,661 - root - INFO -   Validation Time: 1.538	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00162081
2019-06-24 17:09:53,323 - root - INFO -   Epoch 20/150	 Time: 1.662	 Loss: 0.00167192
2019-06-24 17:09:54,862 - root - INFO -   Validation Time: 1.539	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00139226
2019-06-24 17:09:56,567 - root - INFO -   Epoch 21/150	 Time: 1.705	 Loss: 0.00141872
2019-06-24 17:09:58,116 - root - INFO -   Validation Time: 1.548	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00116378
2019-06-24 17:09:59,784 - root - INFO -   Epoch 22/150	 Time: 1.668	 Loss: 0.00120629
2019-06-24 17:10:01,352 - root - INFO -   Validation Time: 1.567	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00120812
2019-06-24 17:10:02,990 - root - INFO -   Epoch 23/150	 Time: 1.638	 Loss: 0.00109320
2019-06-24 17:10:04,530 - root - INFO -   Validation Time: 1.539	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00083360
2019-06-24 17:10:06,212 - root - INFO -   Epoch 24/150	 Time: 1.681	 Loss: 0.00096065
2019-06-24 17:10:07,755 - root - INFO -   Validation Time: 1.543	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00073999
2019-06-24 17:10:09,422 - root - INFO -   Epoch 25/150	 Time: 1.667	 Loss: 0.00080306
2019-06-24 17:10:10,956 - root - INFO -   Validation Time: 1.533	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00061772
2019-06-24 17:10:12,620 - root - INFO -   Epoch 26/150	 Time: 1.663	 Loss: 0.00073655
2019-06-24 17:10:14,179 - root - INFO -   Validation Time: 1.559	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00069714
2019-06-24 17:10:15,852 - root - INFO -   Epoch 27/150	 Time: 1.672	 Loss: 0.00065402
2019-06-24 17:10:17,424 - root - INFO -   Validation Time: 1.572	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00049261
2019-06-24 17:10:19,089 - root - INFO -   Epoch 28/150	 Time: 1.664	 Loss: 0.00062164
2019-06-24 17:10:20,637 - root - INFO -   Validation Time: 1.548	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00046636
2019-06-24 17:10:22,310 - root - INFO -   Epoch 29/150	 Time: 1.673	 Loss: 0.00056449
2019-06-24 17:10:23,843 - root - INFO -   Validation Time: 1.533	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00037434
2019-06-24 17:10:25,511 - root - INFO -   Epoch 30/150	 Time: 1.668	 Loss: 0.00049500
2019-06-24 17:10:27,044 - root - INFO -   Validation Time: 1.532	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00032654
2019-06-24 17:10:28,725 - root - INFO -   Epoch 31/150	 Time: 1.680	 Loss: 0.00049252
2019-06-24 17:10:30,256 - root - INFO -   Validation Time: 1.531	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00030268
2019-06-24 17:10:31,907 - root - INFO -   Epoch 32/150	 Time: 1.650	 Loss: 0.00046730
2019-06-24 17:10:33,439 - root - INFO -   Validation Time: 1.532	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00031533
2019-06-24 17:10:35,045 - root - INFO -   Epoch 33/150	 Time: 1.606	 Loss: 0.00041880
2019-06-24 17:10:36,581 - root - INFO -   Validation Time: 1.536	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00033702
2019-06-24 17:10:38,274 - root - INFO -   Epoch 34/150	 Time: 1.692	 Loss: 0.00041293
2019-06-24 17:10:39,813 - root - INFO -   Validation Time: 1.539	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00040399
2019-06-24 17:10:41,453 - root - INFO -   Epoch 35/150	 Time: 1.639	 Loss: 0.00034780
2019-06-24 17:10:43,001 - root - INFO -   Validation Time: 1.548	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00022581
2019-06-24 17:10:44,684 - root - INFO -   Epoch 36/150	 Time: 1.682	 Loss: 0.00036815
2019-06-24 17:10:46,265 - root - INFO -   Validation Time: 1.581	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00023468
2019-06-24 17:10:47,928 - root - INFO -   Epoch 37/150	 Time: 1.663	 Loss: 0.00038679
2019-06-24 17:10:49,454 - root - INFO -   Validation Time: 1.526	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00017602
2019-06-24 17:10:51,098 - root - INFO -   Epoch 38/150	 Time: 1.643	 Loss: 0.00036511
2019-06-24 17:10:52,658 - root - INFO -   Validation Time: 1.560	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00016880
2019-06-24 17:10:54,342 - root - INFO -   Epoch 39/150	 Time: 1.684	 Loss: 0.00033494
2019-06-24 17:10:55,896 - root - INFO -   Validation Time: 1.553	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00033008
2019-06-24 17:10:57,585 - root - INFO -   Epoch 40/150	 Time: 1.688	 Loss: 0.00031775
2019-06-24 17:10:59,136 - root - INFO -   Validation Time: 1.551	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00041177
2019-06-24 17:11:00,811 - root - INFO -   Epoch 41/150	 Time: 1.674	 Loss: 0.00029838
2019-06-24 17:11:02,350 - root - INFO -   Validation Time: 1.540	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00019806
2019-06-24 17:11:04,041 - root - INFO -   Epoch 42/150	 Time: 1.691	 Loss: 0.00031123
2019-06-24 17:11:05,616 - root - INFO -   Validation Time: 1.574	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00016229
2019-06-24 17:11:07,323 - root - INFO -   Epoch 43/150	 Time: 1.706	 Loss: 0.00028265
2019-06-24 17:11:08,890 - root - INFO -   Validation Time: 1.566	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00040796
2019-06-24 17:11:10,619 - root - INFO -   Epoch 44/150	 Time: 1.729	 Loss: 0.00028621
2019-06-24 17:11:12,210 - root - INFO -   Validation Time: 1.590	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00011452
2019-06-24 17:11:13,890 - root - INFO -   Epoch 45/150	 Time: 1.680	 Loss: 0.00024585
2019-06-24 17:11:15,472 - root - INFO -   Validation Time: 1.582	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00021188
2019-06-24 17:11:17,161 - root - INFO -   Epoch 46/150	 Time: 1.689	 Loss: 0.00024862
2019-06-24 17:11:18,733 - root - INFO -   Validation Time: 1.572	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00017750
2019-06-24 17:11:20,430 - root - INFO -   Epoch 47/150	 Time: 1.696	 Loss: 0.00023568
2019-06-24 17:11:21,975 - root - INFO -   Validation Time: 1.545	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00012249
2019-06-24 17:11:23,688 - root - INFO -   Epoch 48/150	 Time: 1.712	 Loss: 0.00024446
2019-06-24 17:11:25,245 - root - INFO -   Validation Time: 1.556	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00016055
2019-06-24 17:11:26,954 - root - INFO -   Epoch 49/150	 Time: 1.709	 Loss: 0.00025742
2019-06-24 17:11:28,500 - root - INFO -   Validation Time: 1.546	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00010693
2019-06-24 17:11:30,164 - root - INFO -   Epoch 50/150	 Time: 1.664	 Loss: 0.00015719
2019-06-24 17:11:31,709 - root - INFO -   Validation Time: 1.545	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00009293
2019-06-24 17:11:31,710 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-24 17:11:33,392 - root - INFO -   Epoch 51/150	 Time: 1.682	 Loss: 0.00015354
2019-06-24 17:11:34,930 - root - INFO -   Validation Time: 1.538	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008723
2019-06-24 17:11:36,617 - root - INFO -   Epoch 52/150	 Time: 1.686	 Loss: 0.00015991
2019-06-24 17:11:38,222 - root - INFO -   Validation Time: 1.605	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008558
2019-06-24 17:11:39,869 - root - INFO -   Epoch 53/150	 Time: 1.647	 Loss: 0.00014861
2019-06-24 17:11:41,413 - root - INFO -   Validation Time: 1.544	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00009355
2019-06-24 17:11:43,143 - root - INFO -   Epoch 54/150	 Time: 1.730	 Loss: 0.00015851
2019-06-24 17:11:44,681 - root - INFO -   Validation Time: 1.537	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008927
2019-06-24 17:11:46,339 - root - INFO -   Epoch 55/150	 Time: 1.657	 Loss: 0.00015820
2019-06-24 17:11:47,897 - root - INFO -   Validation Time: 1.557	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00007944
2019-06-24 17:11:49,591 - root - INFO -   Epoch 56/150	 Time: 1.694	 Loss: 0.00015583
2019-06-24 17:11:51,125 - root - INFO -   Validation Time: 1.533	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008837
2019-06-24 17:11:52,762 - root - INFO -   Epoch 57/150	 Time: 1.637	 Loss: 0.00016458
2019-06-24 17:11:54,318 - root - INFO -   Validation Time: 1.556	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008901
2019-06-24 17:11:56,000 - root - INFO -   Epoch 58/150	 Time: 1.682	 Loss: 0.00016178
2019-06-24 17:11:57,525 - root - INFO -   Validation Time: 1.524	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008499
2019-06-24 17:11:59,183 - root - INFO -   Epoch 59/150	 Time: 1.658	 Loss: 0.00016205
2019-06-24 17:12:00,730 - root - INFO -   Validation Time: 1.546	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008079
2019-06-24 17:12:02,383 - root - INFO -   Epoch 60/150	 Time: 1.652	 Loss: 0.00014631
2019-06-24 17:12:03,922 - root - INFO -   Validation Time: 1.539	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008624
2019-06-24 17:12:05,572 - root - INFO -   Epoch 61/150	 Time: 1.649	 Loss: 0.00014594
2019-06-24 17:12:07,100 - root - INFO -   Validation Time: 1.528	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008098
2019-06-24 17:12:08,783 - root - INFO -   Epoch 62/150	 Time: 1.682	 Loss: 0.00015440
2019-06-24 17:12:10,306 - root - INFO -   Validation Time: 1.523	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00009701
2019-06-24 17:12:11,950 - root - INFO -   Epoch 63/150	 Time: 1.643	 Loss: 0.00015652
2019-06-24 17:12:13,488 - root - INFO -   Validation Time: 1.538	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00009968
2019-06-24 17:12:15,153 - root - INFO -   Epoch 64/150	 Time: 1.665	 Loss: 0.00015035
2019-06-24 17:12:16,716 - root - INFO -   Validation Time: 1.563	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00007992
2019-06-24 17:12:18,369 - root - INFO -   Epoch 65/150	 Time: 1.652	 Loss: 0.00014533
2019-06-24 17:12:19,900 - root - INFO -   Validation Time: 1.531	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00007844
2019-06-24 17:12:21,544 - root - INFO -   Epoch 66/150	 Time: 1.643	 Loss: 0.00015328
2019-06-24 17:12:23,081 - root - INFO -   Validation Time: 1.537	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00007845
2019-06-24 17:12:24,763 - root - INFO -   Epoch 67/150	 Time: 1.681	 Loss: 0.00016697
2019-06-24 17:12:26,279 - root - INFO -   Validation Time: 1.515	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008587
2019-06-24 17:12:27,944 - root - INFO -   Epoch 68/150	 Time: 1.664	 Loss: 0.00014923
2019-06-24 17:12:29,490 - root - INFO -   Validation Time: 1.546	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00007919
2019-06-24 17:12:31,157 - root - INFO -   Epoch 69/150	 Time: 1.667	 Loss: 0.00015124
2019-06-24 17:12:32,699 - root - INFO -   Validation Time: 1.541	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00008413
2019-06-24 17:12:34,359 - root - INFO -   Epoch 70/150	 Time: 1.660	 Loss: 0.00014742
2019-06-24 17:12:35,891 - root - INFO -   Validation Time: 1.532	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00007378
2019-06-24 17:12:37,571 - root - INFO -   Epoch 71/150	 Time: 1.679	 Loss: 0.00014143
2019-06-24 17:12:39,119 - root - INFO -   Validation Time: 1.548	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.00009455
2019-06-24 17:12:40,838 - root - INFO -   Epoch 72/150	 Time: 1.719	 Loss: 0.00014672
2019-06-24 17:12:52,954 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-24 17:12:52,954 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-24 17:12:52,954 - root - INFO - Export path is ../log/hits_test.
2019-06-24 17:12:52,954 - root - INFO - Dataset: hits
2019-06-24 17:12:52,954 - root - INFO - Normal class: 1
2019-06-24 17:12:52,954 - root - INFO - Network: hits_LeNet
2019-06-24 17:12:52,954 - root - INFO - Deep SVDD objective: one-class
2019-06-24 17:12:52,954 - root - INFO - Nu-paramerter: 0.10
2019-06-24 17:12:52,991 - root - INFO - Computation device: cuda
2019-06-24 17:12:52,991 - root - INFO - Number of dataloader workers: 16
2019-06-24 17:13:02,932 - root - INFO - Pretraining: False
2019-06-24 17:13:02,932 - root - INFO - Training optimizer: adam
2019-06-24 17:13:02,932 - root - INFO - Training learning rate: 0.0001
2019-06-24 17:13:02,932 - root - INFO - Training epochs: 150
2019-06-24 17:13:02,932 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-24 17:13:02,932 - root - INFO - Training batch size: 200
2019-06-24 17:13:02,932 - root - INFO - Training weight decay: 5e-07
2019-06-24 17:13:04,993 - root - INFO - Initializing center c...
2019-06-24 17:13:06,350 - root - INFO - Center c initialized.
2019-06-24 17:13:06,350 - root - INFO - Starting training...
2019-06-24 17:13:08,563 - root - INFO -   Validation Time: 1.662	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.16517669
2019-06-24 17:13:10,213 - root - INFO -   Validation Time: 1.647	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.18502854
2019-06-24 17:13:11,872 - root - INFO -   Validation Time: 1.655	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.20278598
2019-06-24 17:13:13,522 - root - INFO -   Validation Time: 1.645	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.21650172
2019-06-24 17:13:15,190 - root - INFO -   Validation Time: 1.665	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.22526824
2019-06-24 17:13:16,846 - root - INFO -   Validation Time: 1.651	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.23134081
2019-06-24 17:13:18,590 - root - INFO -   Validation Time: 1.741	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.23581020
2019-06-24 17:13:20,284 - root - INFO -   Validation Time: 1.690	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.23937750
2019-06-24 17:13:22,043 - root - INFO -   Validation Time: 1.744	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.24211299
2019-06-24 17:13:23,751 - root - INFO -   Validation Time: 1.704	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.24424362
2019-06-24 17:13:25,467 - root - INFO -   Validation Time: 1.710	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.24590702
2019-06-24 17:13:27,117 - root - INFO -   Validation Time: 1.648	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.24744556
2019-06-24 17:13:28,728 - root - INFO -   Validation Time: 1.608	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.24891166
2019-06-24 17:13:30,364 - root - INFO -   Validation Time: 1.633	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.25061076
2019-06-24 17:13:32,015 - root - INFO -   Validation Time: 1.648	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.25266422
2019-06-24 17:13:33,664 - root - INFO -   Validation Time: 1.646	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.25461588
2019-06-24 17:13:35,318 - root - INFO -   Validation Time: 1.651	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.25729807
2019-06-24 17:13:36,978 - root - INFO -   Validation Time: 1.657	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.26054288
2019-06-24 17:13:38,631 - root - INFO -   Validation Time: 1.650	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.26508610
2019-06-24 17:13:40,296 - root - INFO -   Validation Time: 1.662	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.27032126
2019-06-24 17:13:41,923 - root - INFO -   Validation Time: 1.625	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.27665398
2019-06-24 17:13:43,557 - root - INFO -   Validation Time: 1.631	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.28492844
2019-06-24 17:13:45,256 - root - INFO -   Validation Time: 1.696	 Acc_all: 0.50321191	 Acc_Normal: 1.00000000	 Loss_Normal: 0.29438223
2019-06-24 17:13:46,933 - root - INFO -   Validation Time: 1.674	 Acc_all: 0.50347681	 Acc_Normal: 1.00000000	 Loss_Normal: 0.30580105
2019-06-24 17:13:48,565 - root - INFO -   Validation Time: 1.628	 Acc_all: 0.50526489	 Acc_Normal: 1.00000000	 Loss_Normal: 0.31958650
2019-06-24 17:13:50,290 - root - INFO -   Validation Time: 1.723	 Acc_all: 0.50947019	 Acc_Normal: 1.00000000	 Loss_Normal: 0.33571599
2019-06-24 17:13:52,028 - root - INFO -   Validation Time: 1.734	 Acc_all: 0.51791389	 Acc_Normal: 1.00000000	 Loss_Normal: 0.35544647
2019-06-24 17:13:53,708 - root - INFO -   Validation Time: 1.677	 Acc_all: 0.53036423	 Acc_Normal: 0.99933266	 Loss_Normal: 0.37949342
2019-06-24 17:13:55,363 - root - INFO -   Validation Time: 1.652	 Acc_all: 0.54615893	 Acc_Normal: 0.99699932	 Loss_Normal: 0.40758542
2019-06-24 17:13:56,998 - root - INFO -   Validation Time: 1.633	 Acc_all: 0.56622515	 Acc_Normal: 0.99146597	 Loss_Normal: 0.43984878
2019-06-24 17:13:58,658 - root - INFO -   Validation Time: 1.657	 Acc_all: 0.58917217	 Acc_Normal: 0.98093263	 Loss_Normal: 0.47603912
2019-06-24 17:14:00,272 - root - INFO -   Validation Time: 1.611	 Acc_all: 0.61122515	 Acc_Normal: 0.96266530	 Loss_Normal: 0.51551091
2019-06-24 17:14:01,884 - root - INFO -   Validation Time: 1.609	 Acc_all: 0.63509932	 Acc_Normal: 0.93726126	 Loss_Normal: 0.56164993
2019-06-24 17:14:03,555 - root - INFO -   Validation Time: 1.667	 Acc_all: 0.65258277	 Acc_Normal: 0.90518719	 Loss_Normal: 0.61040306
2019-06-24 17:14:05,249 - root - INFO -   Validation Time: 1.691	 Acc_all: 0.66953641	 Acc_Normal: 0.87058180	 Loss_Normal: 0.66199209
2019-06-24 17:14:06,909 - root - INFO -   Validation Time: 1.656	 Acc_all: 0.67837747	 Acc_Normal: 0.82770974	 Loss_Normal: 0.71725772
2019-06-24 17:14:08,567 - root - INFO -   Validation Time: 1.655	 Acc_all: 0.68241720	 Acc_Normal: 0.77936968	 Loss_Normal: 0.77767627
2019-06-24 17:14:10,240 - root - INFO -   Validation Time: 1.669	 Acc_all: 0.68082780	 Acc_Normal: 0.73236295	 Loss_Normal: 0.83873934
2019-06-24 17:14:11,903 - root - INFO -   Validation Time: 1.659	 Acc_all: 0.67526488	 Acc_Normal: 0.68428887	 Loss_Normal: 0.90298621
2019-06-24 17:14:13,536 - root - INFO -   Validation Time: 1.629	 Acc_all: 0.66715230	 Acc_Normal: 0.63654881	 Loss_Normal: 0.96768582
2019-06-24 17:14:15,185 - root - INFO -   Validation Time: 1.645	 Acc_all: 0.65695363	 Acc_Normal: 0.59074679	 Loss_Normal: 1.02859718
2019-06-24 17:14:16,810 - root - INFO -   Validation Time: 1.622	 Acc_all: 0.64705297	 Acc_Normal: 0.54567541	 Loss_Normal: 1.09170746
2019-06-24 17:14:18,432 - root - INFO -   Validation Time: 1.618	 Acc_all: 0.63582780	 Acc_Normal: 0.50093804	 Loss_Normal: 1.15828286
2019-06-24 17:14:20,067 - root - INFO -   Validation Time: 1.632	 Acc_all: 0.62380793	 Acc_Normal: 0.45726800	 Loss_Normal: 1.22135269
2019-06-24 17:14:21,739 - root - INFO -   Validation Time: 1.667	 Acc_all: 0.61122515	 Acc_Normal: 0.41459393	 Loss_Normal: 1.28269415
2019-06-24 17:14:23,395 - root - INFO -   Validation Time: 1.652	 Acc_all: 0.60003310	 Acc_Normal: 0.37652053	 Loss_Normal: 1.34323273
2019-06-24 17:14:25,078 - root - INFO -   Validation Time: 1.680	 Acc_all: 0.58970197	 Acc_Normal: 0.34071851	 Loss_Normal: 1.39428859
2019-06-24 17:14:26,716 - root - INFO -   Validation Time: 1.634	 Acc_all: 0.57973508	 Acc_Normal: 0.30777710	 Loss_Normal: 1.44748780
2019-06-24 17:14:28,366 - root - INFO -   Validation Time: 1.646	 Acc_all: 0.56973509	 Acc_Normal: 0.27510437	 Loss_Normal: 1.49959367
2019-06-24 17:14:30,058 - root - INFO -   Validation Time: 1.689	 Acc_all: 0.56139071	 Acc_Normal: 0.24843501	 Loss_Normal: 1.55029420
2019-06-24 17:14:31,732 - root - INFO -   Validation Time: 1.670	 Acc_all: 0.55496688	 Acc_Normal: 0.22396700	 Loss_Normal: 1.59810019
2019-06-24 17:14:33,360 - root - INFO -   Validation Time: 1.624	 Acc_all: 0.54827813	 Acc_Normal: 0.20136296	 Loss_Normal: 1.63467996
2019-06-24 17:14:35,013 - root - INFO -   Validation Time: 1.649	 Acc_all: 0.54360926	 Acc_Normal: 0.18456161	 Loss_Normal: 1.66808407
2019-06-24 17:14:36,680 - root - INFO -   Validation Time: 1.663	 Acc_all: 0.54092714	 Acc_Normal: 0.17349360	 Loss_Normal: 1.69039642
2019-06-24 17:14:38,347 - root - INFO -   Validation Time: 1.664	 Acc_all: 0.53751655	 Acc_Normal: 0.16142559	 Loss_Normal: 1.71661511
2019-06-24 17:14:39,996 - root - INFO -   Validation Time: 1.645	 Acc_all: 0.53413906	 Acc_Normal: 0.14755623	 Loss_Normal: 1.74880133
2019-06-24 17:14:41,653 - root - INFO -   Validation Time: 1.653	 Acc_all: 0.53311257	 Acc_Normal: 0.14162222	 Loss_Normal: 1.76125189
2019-06-24 17:14:43,331 - root - INFO -   Validation Time: 1.674	 Acc_all: 0.53145694	 Acc_Normal: 0.13515421	 Loss_Normal: 1.77613166
2019-06-24 17:14:45,066 - root - INFO -   Validation Time: 1.731	 Acc_all: 0.52986754	 Acc_Normal: 0.12902087	 Loss_Normal: 1.79127699
2019-06-24 17:14:46,770 - root - INFO -   Validation Time: 1.701	 Acc_all: 0.52327813	 Acc_Normal: 0.12562020	 Loss_Normal: 1.79809098
2019-06-24 17:14:48,432 - root - INFO -   Validation Time: 1.658	 Acc_all: 0.52344370	 Acc_Normal: 0.12348619	 Loss_Normal: 1.80042195
2019-06-24 17:14:50,073 - root - INFO -   Validation Time: 1.637	 Acc_all: 0.52380793	 Acc_Normal: 0.12281885	 Loss_Normal: 1.80534480
2019-06-24 17:14:51,762 - root - INFO -   Validation Time: 1.686	 Acc_all: 0.52397350	 Acc_Normal: 0.12181885	 Loss_Normal: 1.80557055
2019-06-24 17:14:53,456 - root - INFO -   Validation Time: 1.690	 Acc_all: 0.52311257	 Acc_Normal: 0.11795219	 Loss_Normal: 1.81703612
2019-06-24 17:14:55,154 - root - INFO -   Validation Time: 1.694	 Acc_all: 0.52397350	 Acc_Normal: 0.11821885	 Loss_Normal: 1.81427089
2019-06-24 17:14:56,828 - root - INFO -   Validation Time: 1.670	 Acc_all: 0.52473509	 Acc_Normal: 0.11875219	 Loss_Normal: 1.80792387
2019-06-24 17:14:58,524 - root - INFO -   Validation Time: 1.692	 Acc_all: 0.52609270	 Acc_Normal: 0.12095218	 Loss_Normal: 1.79687731
2019-06-24 17:15:00,167 - root - INFO -   Validation Time: 1.640	 Acc_all: 0.52731787	 Acc_Normal: 0.12255218	 Loss_Normal: 1.78934929
2019-06-24 17:15:01,871 - root - INFO -   Validation Time: 1.700	 Acc_all: 0.52930462	 Acc_Normal: 0.12555219	 Loss_Normal: 1.77855405
2019-06-24 17:15:03,547 - root - INFO -   Validation Time: 1.672	 Acc_all: 0.53013244	 Acc_Normal: 0.12661885	 Loss_Normal: 1.77578912
2019-06-24 17:15:05,225 - root - INFO -   Validation Time: 1.674	 Acc_all: 0.53745032	 Acc_Normal: 0.12795353	 Loss_Normal: 1.77279188
2019-06-24 17:15:06,886 - root - INFO -   Validation Time: 1.656	 Acc_all: 0.53920529	 Acc_Normal: 0.13155421	 Loss_Normal: 1.75643842
2019-06-24 17:15:08,669 - root - INFO -   Validation Time: 1.779	 Acc_all: 0.54125827	 Acc_Normal: 0.13495488	 Loss_Normal: 1.74372468
2019-06-24 17:15:10,325 - root - INFO -   Validation Time: 1.652	 Acc_all: 0.54367548	 Acc_Normal: 0.13995623	 Loss_Normal: 1.72914392
2019-06-24 17:15:12,076 - root - INFO -   Validation Time: 1.747	 Acc_all: 0.54711919	 Acc_Normal: 0.14722289	 Loss_Normal: 1.71143949
2019-06-24 17:15:13,803 - root - INFO -   Validation Time: 1.723	 Acc_all: 0.54894038	 Acc_Normal: 0.15122424	 Loss_Normal: 1.70172190
2019-06-24 17:15:15,477 - root - INFO -   Validation Time: 1.670	 Acc_all: 0.55122515	 Acc_Normal: 0.15629090	 Loss_Normal: 1.68766670
2019-06-24 17:15:17,176 - root - INFO -   Validation Time: 1.696	 Acc_all: 0.55364237	 Acc_Normal: 0.16155892	 Loss_Normal: 1.67660393
2019-06-24 17:15:18,870 - root - INFO -   Validation Time: 1.690	 Acc_all: 0.55649006	 Acc_Normal: 0.16755892	 Loss_Normal: 1.66352647
2019-06-24 17:15:20,625 - root - INFO -   Validation Time: 1.752	 Acc_all: 0.56023178	 Acc_Normal: 0.17562828	 Loss_Normal: 1.64013736
2019-06-24 17:15:22,276 - root - INFO -   Validation Time: 1.646	 Acc_all: 0.56195363	 Acc_Normal: 0.17929495	 Loss_Normal: 1.63540188
2019-06-24 17:15:23,964 - root - INFO -   Validation Time: 1.684	 Acc_all: 0.56456953	 Acc_Normal: 0.18476161	 Loss_Normal: 1.62496652
2019-06-24 17:15:25,604 - root - INFO -   Validation Time: 1.636	 Acc_all: 0.56609270	 Acc_Normal: 0.18869629	 Loss_Normal: 1.61688389
2019-06-24 17:15:27,296 - root - INFO -   Validation Time: 1.689	 Acc_all: 0.56986754	 Acc_Normal: 0.19676363	 Loss_Normal: 1.60072848
2019-06-24 17:15:28,991 - root - INFO -   Validation Time: 1.691	 Acc_all: 0.57331125	 Acc_Normal: 0.20409966	 Loss_Normal: 1.58448404
2019-06-24 17:15:30,637 - root - INFO -   Validation Time: 1.642	 Acc_all: 0.57579469	 Acc_Normal: 0.21003299	 Loss_Normal: 1.57212663
2019-06-24 17:15:32,279 - root - INFO -   Validation Time: 1.638	 Acc_all: 0.57801323	 Acc_Normal: 0.21516700	 Loss_Normal: 1.56269960
2019-06-24 17:15:33,945 - root - INFO -   Validation Time: 1.663	 Acc_all: 0.58059601	 Acc_Normal: 0.22076767	 Loss_Normal: 1.55157414
2019-06-24 17:15:35,615 - root - INFO -   Validation Time: 1.666	 Acc_all: 0.58543045	 Acc_Normal: 0.23170235	 Loss_Normal: 1.53310267
2019-06-24 17:15:37,244 - root - INFO -   Validation Time: 1.625	 Acc_all: 0.58847681	 Acc_Normal: 0.23897037	 Loss_Normal: 1.52089344
2019-06-24 17:15:38,880 - root - INFO -   Validation Time: 1.632	 Acc_all: 0.59165562	 Acc_Normal: 0.24610437	 Loss_Normal: 1.50716127
2019-06-24 17:15:40,509 - root - INFO -   Validation Time: 1.626	 Acc_all: 0.59493376	 Acc_Normal: 0.25403838	 Loss_Normal: 1.49328379
2019-06-24 17:15:42,150 - root - INFO -   Validation Time: 1.637	 Acc_all: 0.59923840	 Acc_Normal: 0.26503972	 Loss_Normal: 1.47771148
2019-06-24 17:15:43,835 - root - INFO -   Validation Time: 1.681	 Acc_all: 0.60294701	 Acc_Normal: 0.27377373	 Loss_Normal: 1.46354077
2019-06-24 17:15:45,545 - root - INFO -   Validation Time: 1.705	 Acc_all: 0.60658939	 Acc_Normal: 0.28217373	 Loss_Normal: 1.45260496
2019-06-24 17:15:47,227 - root - INFO -   Validation Time: 1.678	 Acc_all: 0.61115893	 Acc_Normal: 0.29351110	 Loss_Normal: 1.43165538
2019-06-24 17:15:48,896 - root - INFO -   Validation Time: 1.665	 Acc_all: 0.61450330	 Acc_Normal: 0.30231178	 Loss_Normal: 1.41516924
2019-06-24 17:15:50,578 - root - INFO -   Validation Time: 1.678	 Acc_all: 0.61774833	 Acc_Normal: 0.30971312	 Loss_Normal: 1.40244040
2019-06-24 17:15:52,233 - root - INFO -   Validation Time: 1.652	 Acc_all: 0.62112581	 Acc_Normal: 0.31751380	 Loss_Normal: 1.39063392
2019-06-24 17:15:53,908 - root - INFO -   Validation Time: 1.671	 Acc_all: 0.62503310	 Acc_Normal: 0.32644780	 Loss_Normal: 1.37584356
2019-06-24 17:15:55,555 - root - INFO -   Validation Time: 1.644	 Acc_all: 0.62692052	 Acc_Normal: 0.33051515	 Loss_Normal: 1.36876946
2019-06-24 17:15:57,256 - root - INFO -   Validation Time: 1.697	 Acc_all: 0.63036423	 Acc_Normal: 0.33924982	 Loss_Normal: 1.35538108
2019-06-24 17:15:58,954 - root - INFO -   Validation Time: 1.695	 Acc_all: 0.63420528	 Acc_Normal: 0.34905184	 Loss_Normal: 1.34132804
2019-06-24 17:16:00,603 - root - INFO -   Validation Time: 1.645	 Acc_all: 0.63685429	 Acc_Normal: 0.35591851	 Loss_Normal: 1.33313221
2019-06-24 17:16:02,255 - root - INFO -   Validation Time: 1.648	 Acc_all: 0.63910595	 Acc_Normal: 0.36151851	 Loss_Normal: 1.32125256
2019-06-24 17:16:03,912 - root - INFO -   Validation Time: 1.653	 Acc_all: 0.64086091	 Acc_Normal: 0.36625184	 Loss_Normal: 1.31681090
2019-06-24 17:16:05,639 - root - INFO -   Validation Time: 1.723	 Acc_all: 0.64208608	 Acc_Normal: 0.36885252	 Loss_Normal: 1.31294504
2019-06-24 17:16:07,312 - root - INFO -   Validation Time: 1.670	 Acc_all: 0.64400661	 Acc_Normal: 0.37365319	 Loss_Normal: 1.30749522
2019-06-24 17:16:08,979 - root - INFO -   Validation Time: 1.663	 Acc_all: 0.64758277	 Acc_Normal: 0.38265319	 Loss_Normal: 1.29417998
2019-06-24 17:16:10,609 - root - INFO -   Validation Time: 1.627	 Acc_all: 0.64976820	 Acc_Normal: 0.38865454	 Loss_Normal: 1.28509465
2019-06-24 17:16:12,263 - root - INFO -   Validation Time: 1.650	 Acc_all: 0.65291389	 Acc_Normal: 0.39639056	 Loss_Normal: 1.27341107
2019-06-24 17:16:13,911 - root - INFO -   Validation Time: 1.644	 Acc_all: 0.65599336	 Acc_Normal: 0.40425723	 Loss_Normal: 1.26276770
2019-06-24 17:16:15,614 - root - INFO -   Validation Time: 1.700	 Acc_all: 0.65870859	 Acc_Normal: 0.41125723	 Loss_Normal: 1.25206414
2019-06-24 17:16:17,334 - root - INFO -   Validation Time: 1.714	 Acc_all: 0.66043045	 Acc_Normal: 0.41605858	 Loss_Normal: 1.24397791
2019-06-24 17:16:19,020 - root - INFO -   Validation Time: 1.683	 Acc_all: 0.66228475	 Acc_Normal: 0.42052659	 Loss_Normal: 1.23721511
2019-06-24 17:16:20,680 - root - INFO -   Validation Time: 1.656	 Acc_all: 0.66499999	 Acc_Normal: 0.42725992	 Loss_Normal: 1.22930022
2019-06-24 17:16:22,302 - root - INFO -   Validation Time: 1.618	 Acc_all: 0.66635760	 Acc_Normal: 0.43112659	 Loss_Normal: 1.22403190
2019-06-24 17:16:23,956 - root - INFO -   Validation Time: 1.650	 Acc_all: 0.67003310	 Acc_Normal: 0.44086060	 Loss_Normal: 1.21081207
2019-06-24 17:16:25,602 - root - INFO -   Validation Time: 1.643	 Acc_all: 0.67281455	 Acc_Normal: 0.44792996	 Loss_Normal: 1.20055610
2019-06-24 17:16:27,291 - root - INFO -   Validation Time: 1.685	 Acc_all: 0.67675495	 Acc_Normal: 0.45859730	 Loss_Normal: 1.18544659
2019-06-24 17:16:28,923 - root - INFO -   Validation Time: 1.629	 Acc_all: 0.67857614	 Acc_Normal: 0.46353198	 Loss_Normal: 1.17728289
2019-06-24 17:16:30,574 - root - INFO -   Validation Time: 1.647	 Acc_all: 0.67837747	 Acc_Normal: 0.46313130	 Loss_Normal: 1.17718522
2019-06-24 17:16:32,241 - root - INFO -   Validation Time: 1.664	 Acc_all: 0.67996687	 Acc_Normal: 0.46719864	 Loss_Normal: 1.17262219
2019-06-24 17:16:33,919 - root - INFO -   Validation Time: 1.674	 Acc_all: 0.68155628	 Acc_Normal: 0.47286531	 Loss_Normal: 1.16601291
2019-06-24 17:16:35,626 - root - INFO -   Validation Time: 1.702	 Acc_all: 0.68483442	 Acc_Normal: 0.48099932	 Loss_Normal: 1.15425185
2019-06-24 17:16:37,275 - root - INFO -   Validation Time: 1.645	 Acc_all: 0.68579469	 Acc_Normal: 0.48406665	 Loss_Normal: 1.14965391
2019-06-24 17:16:38,956 - root - INFO -   Validation Time: 1.677	 Acc_all: 0.68675495	 Acc_Normal: 0.48786733	 Loss_Normal: 1.14284774
2019-06-24 17:16:40,636 - root - INFO -   Validation Time: 1.676	 Acc_all: 0.68817879	 Acc_Normal: 0.49193399	 Loss_Normal: 1.13701211
2019-06-24 17:16:42,306 - root - INFO -   Validation Time: 1.666	 Acc_all: 0.69019866	 Acc_Normal: 0.49666733	 Loss_Normal: 1.13168246
2019-06-24 17:16:43,976 - root - INFO -   Validation Time: 1.667	 Acc_all: 0.69208608	 Acc_Normal: 0.50226800	 Loss_Normal: 1.12431295
2019-06-24 17:16:45,630 - root - INFO -   Validation Time: 1.650	 Acc_all: 0.69331124	 Acc_Normal: 0.50720133	 Loss_Normal: 1.11576515
2019-06-24 17:16:47,327 - root - INFO -   Validation Time: 1.693	 Acc_all: 0.69384104	 Acc_Normal: 0.51086868	 Loss_Normal: 1.10953046
2019-06-24 17:16:49,002 - root - INFO -   Validation Time: 1.671	 Acc_all: 0.69486753	 Acc_Normal: 0.51446868	 Loss_Normal: 1.10413949
2019-06-24 17:16:50,653 - root - INFO -   Validation Time: 1.647	 Acc_all: 0.69649005	 Acc_Normal: 0.51946935	 Loss_Normal: 1.09774759
2019-06-24 17:16:52,315 - root - INFO -   Validation Time: 1.658	 Acc_all: 0.69688740	 Acc_Normal: 0.52193601	 Loss_Normal: 1.09457435
2019-06-24 17:16:53,962 - root - INFO -   Validation Time: 1.643	 Acc_all: 0.70006621	 Acc_Normal: 0.53007069	 Loss_Normal: 1.08518661
2019-06-24 17:16:55,616 - root - INFO -   Validation Time: 1.651	 Acc_all: 0.70112581	 Acc_Normal: 0.53493803	 Loss_Normal: 1.07839754
2019-06-24 17:16:57,297 - root - INFO -   Validation Time: 1.677	 Acc_all: 0.70294700	 Acc_Normal: 0.54047137	 Loss_Normal: 1.07110273
2019-06-24 17:16:58,963 - root - INFO -   Validation Time: 1.661	 Acc_all: 0.70364237	 Acc_Normal: 0.54393871	 Loss_Normal: 1.06665473
2019-06-24 17:17:00,609 - root - INFO -   Validation Time: 1.643	 Acc_all: 0.70725164	 Acc_Normal: 0.55387339	 Loss_Normal: 1.05142731
2019-06-24 17:17:02,279 - root - INFO -   Validation Time: 1.666	 Acc_all: 0.70821191	 Acc_Normal: 0.55647339	 Loss_Normal: 1.04698911
2019-06-24 17:17:03,957 - root - INFO -   Validation Time: 1.674	 Acc_all: 0.70897349	 Acc_Normal: 0.56034208	 Loss_Normal: 1.03997849
2019-06-24 17:17:05,601 - root - INFO -   Validation Time: 1.640	 Acc_all: 0.71043045	 Acc_Normal: 0.56647608	 Loss_Normal: 1.03138034
2019-06-24 17:17:07,241 - root - INFO -   Validation Time: 1.636	 Acc_all: 0.71158939	 Acc_Normal: 0.57054275	 Loss_Normal: 1.02415268
2019-06-24 17:17:08,996 - root - INFO -   Validation Time: 1.751	 Acc_all: 0.71261588	 Acc_Normal: 0.57447675	 Loss_Normal: 1.01704733
2019-06-24 17:17:10,682 - root - INFO -   Validation Time: 1.683	 Acc_all: 0.71463575	 Acc_Normal: 0.58087743	 Loss_Normal: 1.00966320
2019-06-24 17:17:12,325 - root - INFO -   Validation Time: 1.639	 Acc_all: 0.71576158	 Acc_Normal: 0.58541211	 Loss_Normal: 1.00382950
2019-06-24 17:17:13,981 - root - INFO -   Validation Time: 1.652	 Acc_all: 0.71728475	 Acc_Normal: 0.59081211	 Loss_Normal: 0.99696299
2019-06-24 17:17:15,619 - root - INFO -   Validation Time: 1.635	 Acc_all: 0.71811257	 Acc_Normal: 0.59387878	 Loss_Normal: 0.99276634
2019-06-24 17:17:17,300 - root - INFO -   Validation Time: 1.677	 Acc_all: 0.72099336	 Acc_Normal: 0.60234612	 Loss_Normal: 0.98332732
2019-06-24 17:17:18,928 - root - INFO -   Validation Time: 1.625	 Acc_all: 0.72235098	 Acc_Normal: 0.60708079	 Loss_Normal: 0.97702694
2019-06-24 17:17:20,606 - root - INFO -   Validation Time: 1.674	 Acc_all: 0.72370859	 Acc_Normal: 0.61201615	 Loss_Normal: 0.97116982
2019-06-24 17:17:22,256 - root - INFO -   Validation Time: 1.646	 Acc_all: 0.72483442	 Acc_Normal: 0.61781682	 Loss_Normal: 0.96382439
2019-06-24 17:17:23,898 - root - INFO -   Validation Time: 1.638	 Acc_all: 0.72642382	 Acc_Normal: 0.62441749	 Loss_Normal: 0.95572574
2019-06-24 17:17:25,546 - root - INFO -   Validation Time: 1.644	 Acc_all: 0.72791389	 Acc_Normal: 0.62935150	 Loss_Normal: 0.95052845
2019-06-24 17:17:27,185 - root - INFO -   Validation Time: 1.635	 Acc_all: 0.72764899	 Acc_Normal: 0.62888483	 Loss_Normal: 0.95074796
2019-06-24 17:17:28,839 - root - INFO -   Validation Time: 1.650	 Acc_all: 0.72768210	 Acc_Normal: 0.63101884	 Loss_Normal: 0.94716250
2019-06-24 17:17:30,491 - root - INFO -   Validation Time: 1.648	 Acc_all: 0.72804634	 Acc_Normal: 0.63295218	 Loss_Normal: 0.94427607
2019-06-24 17:17:32,131 - root - INFO -   Validation Time: 1.636	 Acc_all: 0.72990065	 Acc_Normal: 0.63795218	 Loss_Normal: 0.93927865
2019-06-24 17:17:33,828 - root - INFO -   Validation Time: 1.693	 Acc_all: 0.73026488	 Acc_Normal: 0.64015285	 Loss_Normal: 0.93589203
2019-06-24 17:17:35,526 - root - INFO -   Validation Time: 1.694	 Acc_all: 0.73102647	 Acc_Normal: 0.64355285	 Loss_Normal: 0.93219779
2019-06-24 17:17:37,208 - root - INFO -   Validation Time: 1.678	 Acc_all: 0.73235098	 Acc_Normal: 0.64895352	 Loss_Normal: 0.92563403
2019-06-24 17:17:38,856 - root - INFO -   Validation Time: 1.645	 Acc_all: 0.73251654	 Acc_Normal: 0.65055352	 Loss_Normal: 0.92303068
2019-06-24 17:17:40,511 - root - INFO -   Validation Time: 1.651	 Acc_all: 0.73347680	 Acc_Normal: 0.65382019	 Loss_Normal: 0.91873178
2019-06-24 17:17:42,136 - root - INFO -   Validation Time: 1.621	 Acc_all: 0.73466886	 Acc_Normal: 0.65755420	 Loss_Normal: 0.91504200
2019-06-24 17:17:43,815 - root - INFO -   Validation Time: 1.675	 Acc_all: 0.73450329	 Acc_Normal: 0.65762019	 Loss_Normal: 0.91443815
2019-06-24 17:17:45,479 - root - INFO -   Validation Time: 1.661	 Acc_all: 0.73556289	 Acc_Normal: 0.66068753	 Loss_Normal: 0.91151662
2019-06-24 17:17:47,144 - root - INFO -   Validation Time: 1.661	 Acc_all: 0.73645693	 Acc_Normal: 0.66488955	 Loss_Normal: 0.90666983
2019-06-24 17:17:48,820 - root - INFO -   Validation Time: 1.672	 Acc_all: 0.73831124	 Acc_Normal: 0.67002288	 Loss_Normal: 0.89948834
2019-06-24 17:17:50,481 - root - INFO -   Validation Time: 1.658	 Acc_all: 0.73854303	 Acc_Normal: 0.67108955	 Loss_Normal: 0.89773161
2019-06-24 17:17:52,136 - root - INFO -   Validation Time: 1.651	 Acc_all: 0.74039733	 Acc_Normal: 0.67788955	 Loss_Normal: 0.88893221
2019-06-24 17:17:53,793 - root - INFO -   Validation Time: 1.654	 Acc_all: 0.74198673	 Acc_Normal: 0.68268955	 Loss_Normal: 0.88288011
2019-06-24 17:17:55,435 - root - INFO -   Validation Time: 1.638	 Acc_all: 0.74417216	 Acc_Normal: 0.68889022	 Loss_Normal: 0.87562660
2019-06-24 17:17:57,096 - root - INFO -   Validation Time: 1.657	 Acc_all: 0.74423839	 Acc_Normal: 0.68942490	 Loss_Normal: 0.87445617
2019-06-24 17:17:58,740 - root - INFO -   Validation Time: 1.641	 Acc_all: 0.74499998	 Acc_Normal: 0.69169156	 Loss_Normal: 0.87142612
2019-06-24 17:18:00,364 - root - INFO -   Validation Time: 1.620	 Acc_all: 0.74665561	 Acc_Normal: 0.69722490	 Loss_Normal: 0.86449327
2019-06-24 17:18:01,991 - root - INFO -   Validation Time: 1.624	 Acc_all: 0.74751654	 Acc_Normal: 0.70042490	 Loss_Normal: 0.86068708
2019-06-24 17:18:03,688 - root - INFO -   Validation Time: 1.692	 Acc_all: 0.74874170	 Acc_Normal: 0.70582692	 Loss_Normal: 0.85411514
2019-06-24 17:18:05,443 - root - INFO -   Validation Time: 1.752	 Acc_all: 0.74903971	 Acc_Normal: 0.70842692	 Loss_Normal: 0.85025263
2019-06-24 17:18:07,161 - root - INFO -   Validation Time: 1.713	 Acc_all: 0.75043044	 Acc_Normal: 0.71436093	 Loss_Normal: 0.84309081
2019-06-24 17:18:08,913 - root - INFO -   Validation Time: 1.749	 Acc_all: 0.75155627	 Acc_Normal: 0.71936227	 Loss_Normal: 0.83736426
2019-06-24 17:18:10,576 - root - INFO -   Validation Time: 1.659	 Acc_all: 0.75215230	 Acc_Normal: 0.72169561	 Loss_Normal: 0.83471198
2019-06-24 17:18:12,269 - root - INFO -   Validation Time: 1.689	 Acc_all: 0.75291389	 Acc_Normal: 0.72469560	 Loss_Normal: 0.83142386
2019-06-24 17:18:13,911 - root - INFO -   Validation Time: 1.638	 Acc_all: 0.75288077	 Acc_Normal: 0.72689560	 Loss_Normal: 0.82835918
2019-06-24 17:18:15,571 - root - INFO -   Validation Time: 1.656	 Acc_all: 0.75294700	 Acc_Normal: 0.72809628	 Loss_Normal: 0.82665067
2019-06-24 17:18:17,255 - root - INFO -   Validation Time: 1.681	 Acc_all: 0.75460263	 Acc_Normal: 0.73336362	 Loss_Normal: 0.82068126
2019-06-24 17:18:18,902 - root - INFO -   Validation Time: 1.643	 Acc_all: 0.75539733	 Acc_Normal: 0.73703230	 Loss_Normal: 0.81631415
2019-06-24 17:18:20,556 - root - INFO -   Validation Time: 1.650	 Acc_all: 0.75622515	 Acc_Normal: 0.74056698	 Loss_Normal: 0.81213179
2019-06-24 17:18:22,202 - root - INFO -   Validation Time: 1.642	 Acc_all: 0.75682117	 Acc_Normal: 0.74423365	 Loss_Normal: 0.80775259
2019-06-24 17:18:23,874 - root - INFO -   Validation Time: 1.669	 Acc_all: 0.75791389	 Acc_Normal: 0.74910032	 Loss_Normal: 0.80137409
2019-06-24 17:18:25,512 - root - INFO -   Validation Time: 1.634	 Acc_all: 0.75768210	 Acc_Normal: 0.74903365	 Loss_Normal: 0.80098866
2019-06-24 17:18:27,229 - root - INFO -   Validation Time: 1.713	 Acc_all: 0.75788078	 Acc_Normal: 0.75150032	 Loss_Normal: 0.79802841
2019-06-24 17:18:28,905 - root - INFO -   Validation Time: 1.672	 Acc_all: 0.75884104	 Acc_Normal: 0.75450032	 Loss_Normal: 0.79498335
2019-06-24 17:18:30,601 - root - INFO -   Validation Time: 1.693	 Acc_all: 0.75870859	 Acc_Normal: 0.75463365	 Loss_Normal: 0.79430542
2019-06-24 17:18:32,280 - root - INFO -   Validation Time: 1.675	 Acc_all: 0.75927151	 Acc_Normal: 0.75790032	 Loss_Normal: 0.78898124
2019-06-24 17:18:33,950 - root - INFO -   Validation Time: 1.666	 Acc_all: 0.75947018	 Acc_Normal: 0.76043366	 Loss_Normal: 0.78552430
2019-06-24 17:18:35,613 - root - INFO -   Validation Time: 1.660	 Acc_all: 0.75990065	 Acc_Normal: 0.76270099	 Loss_Normal: 0.78233806
2019-06-24 17:18:37,273 - root - INFO -   Validation Time: 1.656	 Acc_all: 0.76033111	 Acc_Normal: 0.76483500	 Loss_Normal: 0.77985955
2019-06-24 17:18:38,926 - root - INFO -   Validation Time: 1.649	 Acc_all: 0.76092713	 Acc_Normal: 0.76936833	 Loss_Normal: 0.77477349
2019-06-24 17:18:40,555 - root - INFO -   Validation Time: 1.625	 Acc_all: 0.76139071	 Acc_Normal: 0.77083567	 Loss_Normal: 0.77307034
2019-06-24 17:18:42,215 - root - INFO -   Validation Time: 1.657	 Acc_all: 0.76175495	 Acc_Normal: 0.77403567	 Loss_Normal: 0.76979771
2019-06-24 17:18:43,876 - root - INFO -   Validation Time: 1.657	 Acc_all: 0.76215230	 Acc_Normal: 0.77490234	 Loss_Normal: 0.76853586
2019-06-24 17:18:45,527 - root - INFO -   Validation Time: 1.647	 Acc_all: 0.76334435	 Acc_Normal: 0.77936968	 Loss_Normal: 0.76413638
2019-06-24 17:18:47,166 - root - INFO -   Validation Time: 1.636	 Acc_all: 0.76453641	 Acc_Normal: 0.78343634	 Loss_Normal: 0.75972674
2019-06-24 17:18:48,829 - root - INFO -   Validation Time: 1.659	 Acc_all: 0.76639071	 Acc_Normal: 0.78977035	 Loss_Normal: 0.75304791
2019-06-24 17:18:50,470 - root - INFO -   Validation Time: 1.636	 Acc_all: 0.76662250	 Acc_Normal: 0.79110436	 Loss_Normal: 0.75128567
2019-06-24 17:18:52,149 - root - INFO -   Validation Time: 1.676	 Acc_all: 0.76705296	 Acc_Normal: 0.79290436	 Loss_Normal: 0.74879421
2019-06-24 17:18:53,784 - root - INFO -   Validation Time: 1.631	 Acc_all: 0.76698674	 Acc_Normal: 0.79557237	 Loss_Normal: 0.74418648
2019-06-24 17:18:55,425 - root - INFO -   Validation Time: 1.637	 Acc_all: 0.76758276	 Acc_Normal: 0.79863904	 Loss_Normal: 0.74136799
2019-06-24 17:18:57,088 - root - INFO -   Validation Time: 1.659	 Acc_all: 0.76847680	 Acc_Normal: 0.80197237	 Loss_Normal: 0.73782744
2019-06-24 17:18:58,780 - root - INFO -   Validation Time: 1.688	 Acc_all: 0.76844369	 Acc_Normal: 0.80383904	 Loss_Normal: 0.73418753
2019-06-24 17:19:00,405 - root - INFO -   Validation Time: 1.622	 Acc_all: 0.76867548	 Acc_Normal: 0.80443904	 Loss_Normal: 0.73352063
2019-06-24 17:19:02,075 - root - INFO -   Validation Time: 1.666	 Acc_all: 0.76930462	 Acc_Normal: 0.80710638	 Loss_Normal: 0.72997059
2019-06-24 17:19:03,769 - root - INFO -   Validation Time: 1.690	 Acc_all: 0.77006621	 Acc_Normal: 0.81010705	 Loss_Normal: 0.72666116
2019-06-24 17:19:05,409 - root - INFO -   Validation Time: 1.636	 Acc_all: 0.77099336	 Acc_Normal: 0.81304039	 Loss_Normal: 0.72389104
2019-06-24 17:19:07,078 - root - INFO -   Validation Time: 1.665	 Acc_all: 0.77185429	 Acc_Normal: 0.81610705	 Loss_Normal: 0.72070866
2019-06-24 17:19:08,744 - root - INFO -   Validation Time: 1.662	 Acc_all: 0.77350991	 Acc_Normal: 0.82224174	 Loss_Normal: 0.71424020
2019-06-24 17:19:10,398 - root - INFO -   Validation Time: 1.650	 Acc_all: 0.77390726	 Acc_Normal: 0.82497776	 Loss_Normal: 0.71032849
2019-06-24 17:19:12,083 - root - INFO -   Validation Time: 1.681	 Acc_all: 0.77377481	 Acc_Normal: 0.82491109	 Loss_Normal: 0.71010455
2019-06-24 17:19:13,721 - root - INFO -   Validation Time: 1.634	 Acc_all: 0.77407283	 Acc_Normal: 0.82617776	 Loss_Normal: 0.70891861
2019-06-24 17:19:15,374 - root - INFO -   Validation Time: 1.649	 Acc_all: 0.77394038	 Acc_Normal: 0.82791109	 Loss_Normal: 0.70627763
2019-06-24 17:19:17,054 - root - INFO -   Validation Time: 1.676	 Acc_all: 0.77430462	 Acc_Normal: 0.82917776	 Loss_Normal: 0.70510743
2019-06-24 17:19:18,702 - root - INFO -   Validation Time: 1.645	 Acc_all: 0.77463574	 Acc_Normal: 0.83097776	 Loss_Normal: 0.70288719
2019-06-24 17:19:20,386 - root - INFO -   Validation Time: 1.680	 Acc_all: 0.77473508	 Acc_Normal: 0.83364443	 Loss_Normal: 0.69836839
2019-06-24 17:19:22,061 - root - INFO -   Validation Time: 1.671	 Acc_all: 0.77493375	 Acc_Normal: 0.83497776	 Loss_Normal: 0.69706888
2019-06-24 17:19:23,763 - root - INFO -   Validation Time: 1.698	 Acc_all: 0.77533110	 Acc_Normal: 0.83784443	 Loss_Normal: 0.69337054
2019-06-24 17:19:25,429 - root - INFO -   Validation Time: 1.662	 Acc_all: 0.77513243	 Acc_Normal: 0.83824442	 Loss_Normal: 0.69240036
2019-06-24 17:19:27,089 - root - INFO -   Validation Time: 1.657	 Acc_all: 0.77536422	 Acc_Normal: 0.84104510	 Loss_Normal: 0.68868661
2019-06-24 17:19:28,735 - root - INFO -   Validation Time: 1.642	 Acc_all: 0.77599336	 Acc_Normal: 0.84784510	 Loss_Normal: 0.68053298
2019-06-24 17:19:30,417 - root - INFO -   Validation Time: 1.678	 Acc_all: 0.77612581	 Acc_Normal: 0.84757843	 Loss_Normal: 0.68129412
2019-06-24 17:19:32,113 - root - INFO -   Validation Time: 1.693	 Acc_all: 0.77605958	 Acc_Normal: 0.84831176	 Loss_Normal: 0.67952717
2019-06-24 17:19:33,819 - root - INFO -   Validation Time: 1.702	 Acc_all: 0.77619203	 Acc_Normal: 0.84997843	 Loss_Normal: 0.67776980
2019-06-24 17:19:35,467 - root - INFO -   Validation Time: 1.644	 Acc_all: 0.77632448	 Acc_Normal: 0.85131244	 Loss_Normal: 0.67594154
2019-06-24 17:19:37,137 - root - INFO -   Validation Time: 1.666	 Acc_all: 0.77645693	 Acc_Normal: 0.85351244	 Loss_Normal: 0.67303053
2019-06-24 17:19:38,826 - root - INFO -   Validation Time: 1.686	 Acc_all: 0.77639071	 Acc_Normal: 0.85571311	 Loss_Normal: 0.66953270
