2019-06-20 16:07:53,150 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:07:53,150 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:07:53,150 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:07:53,150 - root - INFO - Dataset: hits
2019-06-20 16:07:53,150 - root - INFO - Normal class: 1
2019-06-20 16:07:53,150 - root - INFO - Network: mnist_LeNet
2019-06-20 16:07:53,151 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:07:53,151 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:07:53,187 - root - INFO - Computation device: cuda
2019-06-20 16:07:53,187 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:12:36,303 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:12:36,303 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:12:36,303 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:12:36,303 - root - INFO - Dataset: hits
2019-06-20 16:12:36,303 - root - INFO - Normal class: 1
2019-06-20 16:12:36,303 - root - INFO - Network: mnist_LeNet
2019-06-20 16:12:36,303 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:12:36,303 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:12:36,341 - root - INFO - Computation device: cuda
2019-06-20 16:12:36,341 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:14:20,518 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:14:20,518 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:14:20,518 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:14:20,518 - root - INFO - Dataset: hits
2019-06-20 16:14:20,518 - root - INFO - Normal class: 1
2019-06-20 16:14:20,518 - root - INFO - Network: mnist_LeNet
2019-06-20 16:14:20,519 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:14:20,519 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:14:20,558 - root - INFO - Computation device: cuda
2019-06-20 16:14:20,558 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:14:30,248 - root - INFO - Pretraining: True
2019-06-20 16:14:30,248 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:14:30,249 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:14:30,249 - root - INFO - Pretraining epochs: 150
2019-06-20 16:14:30,249 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:14:30,249 - root - INFO - Pretraining batch size: 200
2019-06-20 16:14:30,249 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:14:32,352 - root - INFO - Starting pretraining...
2019-06-20 16:15:21,605 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:15:21,605 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:15:21,605 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:15:21,605 - root - INFO - Dataset: hits
2019-06-20 16:15:21,605 - root - INFO - Normal class: 1
2019-06-20 16:15:21,605 - root - INFO - Network: mnist_LeNet
2019-06-20 16:15:21,605 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:15:21,605 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:15:21,641 - root - INFO - Computation device: cuda
2019-06-20 16:15:21,641 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:15:31,304 - root - INFO - Pretraining: True
2019-06-20 16:15:31,304 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:15:31,304 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:15:31,304 - root - INFO - Pretraining epochs: 150
2019-06-20 16:15:31,304 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:15:31,304 - root - INFO - Pretraining batch size: 200
2019-06-20 16:15:31,304 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:15:33,366 - root - INFO - Starting pretraining...
2019-06-20 16:36:37,598 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:36:37,598 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:36:37,599 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:36:37,599 - root - INFO - Dataset: hits
2019-06-20 16:36:37,600 - root - INFO - Normal class: 1
2019-06-20 16:36:37,600 - root - INFO - Network: mnist_LeNet
2019-06-20 16:36:37,600 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:36:37,600 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:36:37,629 - root - INFO - Computation device: cuda
2019-06-20 16:36:37,629 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:36:47,453 - root - INFO - Pretraining: True
2019-06-20 16:36:47,453 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:36:47,453 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:36:47,453 - root - INFO - Pretraining epochs: 150
2019-06-20 16:36:47,453 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:36:47,453 - root - INFO - Pretraining batch size: 200
2019-06-20 16:36:47,453 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:36:49,525 - root - INFO - Starting pretraining...
2019-06-20 16:37:44,770 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 16:37:44,770 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 16:37:44,770 - root - INFO - Export path is ../log/hits_test.
2019-06-20 16:37:44,770 - root - INFO - Dataset: hits
2019-06-20 16:37:44,770 - root - INFO - Normal class: 1
2019-06-20 16:37:44,770 - root - INFO - Network: mnist_LeNet
2019-06-20 16:37:44,770 - root - INFO - Deep SVDD objective: one-class
2019-06-20 16:37:44,770 - root - INFO - Nu-paramerter: 0.10
2019-06-20 16:37:44,808 - root - INFO - Computation device: cuda
2019-06-20 16:37:44,808 - root - INFO - Number of dataloader workers: 0
2019-06-20 16:37:54,582 - root - INFO - Pretraining: True
2019-06-20 16:37:54,582 - root - INFO - Pretraining optimizer: adam
2019-06-20 16:37:54,583 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 16:37:54,583 - root - INFO - Pretraining epochs: 150
2019-06-20 16:37:54,583 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2019-06-20 16:37:54,583 - root - INFO - Pretraining batch size: 200
2019-06-20 16:37:54,583 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 16:37:56,882 - root - INFO - Starting pretraining...
2019-06-20 17:05:11,280 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:05:11,280 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:05:11,280 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:05:11,280 - root - INFO - Dataset: hits
2019-06-20 17:05:11,280 - root - INFO - Normal class: 1
2019-06-20 17:05:11,280 - root - INFO - Network: mnist_LeNet
2019-06-20 17:05:11,280 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:05:11,280 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:05:11,317 - root - INFO - Computation device: cuda
2019-06-20 17:05:11,317 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:05:21,204 - root - INFO - Pretraining: True
2019-06-20 17:05:21,204 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:05:21,204 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:05:21,204 - root - INFO - Pretraining epochs: 150
2019-06-20 17:05:21,204 - root - INFO - Pretraining learning rate scheduler milestones: 50
2019-06-20 17:05:21,204 - root - INFO - Pretraining batch size: 200
2019-06-20 17:05:21,204 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:07:42,028 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:07:42,028 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:07:42,028 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:07:42,028 - root - INFO - Dataset: hits
2019-06-20 17:07:42,028 - root - INFO - Normal class: 1
2019-06-20 17:07:42,028 - root - INFO - Network: mnist_LeNet
2019-06-20 17:07:42,028 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:07:42,028 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:07:42,062 - root - INFO - Computation device: cuda
2019-06-20 17:07:42,062 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:07:51,850 - root - INFO - Pretraining: True
2019-06-20 17:07:51,850 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:07:51,850 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:07:51,850 - root - INFO - Pretraining epochs: 150
2019-06-20 17:07:51,850 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:07:51,850 - root - INFO - Pretraining batch size: 200
2019-06-20 17:07:51,850 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:07:53,932 - root - INFO - Starting pretraining...
2019-06-20 17:08:31,874 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:08:31,874 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:08:31,875 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:08:31,875 - root - INFO - Dataset: hits
2019-06-20 17:08:31,875 - root - INFO - Normal class: 1
2019-06-20 17:08:31,875 - root - INFO - Network: mnist_LeNet
2019-06-20 17:08:31,875 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:08:31,875 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:08:31,911 - root - INFO - Computation device: cuda
2019-06-20 17:08:31,911 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:08:41,747 - root - INFO - Pretraining: True
2019-06-20 17:08:41,747 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:08:41,747 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:08:41,747 - root - INFO - Pretraining epochs: 150
2019-06-20 17:08:41,747 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:08:41,747 - root - INFO - Pretraining batch size: 200
2019-06-20 17:08:41,747 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:08:43,824 - root - INFO - Starting pretraining...
2019-06-20 17:13:23,431 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:13:23,431 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:13:23,431 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:13:23,431 - root - INFO - Dataset: hits
2019-06-20 17:13:23,431 - root - INFO - Normal class: 1
2019-06-20 17:13:23,431 - root - INFO - Network: hits_LeNet
2019-06-20 17:13:23,431 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:13:23,431 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:13:23,467 - root - INFO - Computation device: cuda
2019-06-20 17:13:23,467 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:13:33,261 - root - INFO - Pretraining: True
2019-06-20 17:13:33,261 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:13:33,261 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:13:33,261 - root - INFO - Pretraining epochs: 150
2019-06-20 17:13:33,261 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:13:33,261 - root - INFO - Pretraining batch size: 200
2019-06-20 17:13:33,261 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:14:29,614 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:14:29,614 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:14:29,615 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:14:29,615 - root - INFO - Dataset: hits
2019-06-20 17:14:29,615 - root - INFO - Normal class: 1
2019-06-20 17:14:29,615 - root - INFO - Network: hits_LeNet
2019-06-20 17:14:29,615 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:14:29,615 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:14:29,649 - root - INFO - Computation device: cuda
2019-06-20 17:14:29,649 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:14:39,431 - root - INFO - Pretraining: True
2019-06-20 17:14:39,431 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:14:39,431 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:14:39,431 - root - INFO - Pretraining epochs: 150
2019-06-20 17:14:39,431 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:14:39,431 - root - INFO - Pretraining batch size: 200
2019-06-20 17:14:39,431 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:14:41,510 - root - INFO - Starting pretraining...
2019-06-20 17:16:21,853 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:16:21,854 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:16:21,854 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:16:21,854 - root - INFO - Dataset: hits
2019-06-20 17:16:21,854 - root - INFO - Normal class: 1
2019-06-20 17:16:21,854 - root - INFO - Network: hits_LeNet
2019-06-20 17:16:21,854 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:16:21,854 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:16:21,890 - root - INFO - Computation device: cuda
2019-06-20 17:16:21,890 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:16:31,630 - root - INFO - Pretraining: True
2019-06-20 17:16:31,630 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:16:31,630 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:16:31,631 - root - INFO - Pretraining epochs: 150
2019-06-20 17:16:31,631 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:16:31,631 - root - INFO - Pretraining batch size: 200
2019-06-20 17:16:31,631 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:16:33,707 - root - INFO - Starting pretraining...
2019-06-20 17:18:05,415 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:18:05,415 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:18:05,415 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:18:05,415 - root - INFO - Dataset: hits
2019-06-20 17:18:05,415 - root - INFO - Normal class: 1
2019-06-20 17:18:05,416 - root - INFO - Network: hits_LeNet
2019-06-20 17:18:05,416 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:18:05,416 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:18:05,452 - root - INFO - Computation device: cuda
2019-06-20 17:18:05,453 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:18:15,253 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:18:15,253 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:18:15,253 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:18:15,253 - root - INFO - Dataset: hits
2019-06-20 17:18:15,253 - root - INFO - Normal class: 1
2019-06-20 17:18:15,254 - root - INFO - Network: hits_LeNet
2019-06-20 17:18:15,254 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:18:15,254 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:18:15,293 - root - INFO - Computation device: cuda
2019-06-20 17:18:15,293 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:18:25,205 - root - INFO - Pretraining: True
2019-06-20 17:18:25,206 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:18:25,206 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:18:25,206 - root - INFO - Pretraining epochs: 150
2019-06-20 17:18:25,206 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:18:25,206 - root - INFO - Pretraining batch size: 200
2019-06-20 17:18:25,206 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:18:27,311 - root - INFO - Starting pretraining...
2019-06-20 17:22:20,915 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:22:20,915 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:22:20,915 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:22:20,915 - root - INFO - Dataset: hits
2019-06-20 17:22:20,915 - root - INFO - Normal class: 1
2019-06-20 17:22:20,915 - root - INFO - Network: hits_LeNet
2019-06-20 17:22:20,915 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:22:20,915 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:22:20,951 - root - INFO - Computation device: cuda
2019-06-20 17:22:20,952 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:22:30,970 - root - INFO - Pretraining: True
2019-06-20 17:22:30,970 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:22:30,970 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:22:30,970 - root - INFO - Pretraining epochs: 150
2019-06-20 17:22:30,970 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:22:30,970 - root - INFO - Pretraining batch size: 200
2019-06-20 17:22:30,970 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:22:33,067 - root - INFO - Starting pretraining...
2019-06-20 17:22:35,992 - root - INFO -   Epoch 1/150	 Time: 2.925	 Loss: 11.33173425
2019-06-20 17:22:38,654 - root - INFO -   Epoch 2/150	 Time: 2.661	 Loss: 7.48575881
2019-06-20 17:22:41,315 - root - INFO -   Epoch 3/150	 Time: 2.661	 Loss: 7.17361083
2019-06-20 17:22:43,971 - root - INFO -   Epoch 4/150	 Time: 2.656	 Loss: 7.03975483
2019-06-20 17:22:46,697 - root - INFO -   Epoch 5/150	 Time: 2.726	 Loss: 6.95310752
2019-06-20 17:22:49,424 - root - INFO -   Epoch 6/150	 Time: 2.726	 Loss: 6.89141204
2019-06-20 17:22:52,227 - root - INFO -   Epoch 7/150	 Time: 2.803	 Loss: 6.84585164
2019-06-20 17:22:55,050 - root - INFO -   Epoch 8/150	 Time: 2.823	 Loss: 6.80797648
2019-06-20 17:22:57,843 - root - INFO -   Epoch 9/150	 Time: 2.793	 Loss: 6.76440492
2019-06-20 17:23:01,192 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:23:01,192 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:23:01,192 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:23:01,192 - root - INFO - Dataset: hits
2019-06-20 17:23:01,192 - root - INFO - Normal class: 1
2019-06-20 17:23:01,192 - root - INFO - Network: hits_LeNet
2019-06-20 17:23:01,192 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:23:01,192 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:23:01,219 - root - INFO - Computation device: cuda
2019-06-20 17:23:01,220 - root - INFO - Number of dataloader workers: 0
2019-06-20 17:23:11,047 - root - INFO - Pretraining: True
2019-06-20 17:23:11,047 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:23:11,047 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:23:11,047 - root - INFO - Pretraining epochs: 150
2019-06-20 17:23:11,047 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:23:11,047 - root - INFO - Pretraining batch size: 200
2019-06-20 17:23:11,047 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:23:13,162 - root - INFO - Starting pretraining...
2019-06-20 17:23:16,050 - root - INFO -   Epoch 1/150	 Time: 2.887	 Loss: 10.84813132
2019-06-20 17:23:18,727 - root - INFO -   Epoch 2/150	 Time: 2.677	 Loss: 7.61841553
2019-06-20 17:23:21,376 - root - INFO -   Epoch 3/150	 Time: 2.649	 Loss: 7.26817422
2019-06-20 17:23:24,014 - root - INFO -   Epoch 4/150	 Time: 2.637	 Loss: 7.10173927
2019-06-20 17:23:26,669 - root - INFO -   Epoch 5/150	 Time: 2.655	 Loss: 6.99342669
2019-06-20 17:23:29,383 - root - INFO -   Epoch 6/150	 Time: 2.714	 Loss: 6.90969832
2019-06-20 17:23:32,081 - root - INFO -   Epoch 7/150	 Time: 2.697	 Loss: 6.83642267
2019-06-20 17:23:34,725 - root - INFO -   Epoch 8/150	 Time: 2.644	 Loss: 6.77654856
2019-06-20 17:23:37,384 - root - INFO -   Epoch 9/150	 Time: 2.659	 Loss: 6.72785154
2019-06-20 17:23:40,056 - root - INFO -   Epoch 10/150	 Time: 2.672	 Loss: 6.68749217
2019-06-20 17:23:42,752 - root - INFO -   Epoch 11/150	 Time: 2.696	 Loss: 6.65747369
2019-06-20 17:23:45,500 - root - INFO -   Epoch 12/150	 Time: 2.748	 Loss: 6.63078036
2019-06-20 17:23:48,261 - root - INFO -   Epoch 13/150	 Time: 2.761	 Loss: 6.60749839
2019-06-20 17:23:50,952 - root - INFO -   Epoch 14/150	 Time: 2.691	 Loss: 6.58332027
2019-06-20 17:23:53,632 - root - INFO -   Epoch 15/150	 Time: 2.679	 Loss: 6.56512005
2019-06-20 17:23:56,391 - root - INFO -   Epoch 16/150	 Time: 2.759	 Loss: 6.53927390
2019-06-20 17:23:59,045 - root - INFO -   Epoch 17/150	 Time: 2.654	 Loss: 6.52859460
2019-06-20 17:24:01,712 - root - INFO -   Epoch 18/150	 Time: 2.667	 Loss: 6.50863774
2019-06-20 17:24:04,373 - root - INFO -   Epoch 19/150	 Time: 2.662	 Loss: 6.49756993
2019-06-20 17:24:07,026 - root - INFO -   Epoch 20/150	 Time: 2.653	 Loss: 6.48298678
2019-06-20 17:24:09,691 - root - INFO -   Epoch 21/150	 Time: 2.664	 Loss: 6.47297244
2019-06-20 17:24:12,365 - root - INFO -   Epoch 22/150	 Time: 2.674	 Loss: 6.45477151
2019-06-20 17:24:15,033 - root - INFO -   Epoch 23/150	 Time: 2.668	 Loss: 6.44558006
2019-06-20 17:24:17,760 - root - INFO -   Epoch 24/150	 Time: 2.726	 Loss: 6.43630643
2019-06-20 17:24:20,477 - root - INFO -   Epoch 25/150	 Time: 2.717	 Loss: 6.42849579
2019-06-20 17:24:23,162 - root - INFO -   Epoch 26/150	 Time: 2.685	 Loss: 6.41617077
2019-06-20 17:24:25,823 - root - INFO -   Epoch 27/150	 Time: 2.661	 Loss: 6.40695681
2019-06-20 17:24:28,512 - root - INFO -   Epoch 28/150	 Time: 2.689	 Loss: 6.40045967
2019-06-20 17:24:31,210 - root - INFO -   Epoch 29/150	 Time: 2.698	 Loss: 6.38870850
2019-06-20 17:24:33,882 - root - INFO -   Epoch 30/150	 Time: 2.672	 Loss: 6.38480808
2019-06-20 17:24:36,568 - root - INFO -   Epoch 31/150	 Time: 2.685	 Loss: 6.37211437
2019-06-20 17:24:39,245 - root - INFO -   Epoch 32/150	 Time: 2.677	 Loss: 6.36749736
2019-06-20 17:24:41,917 - root - INFO -   Epoch 33/150	 Time: 2.672	 Loss: 6.35869768
2019-06-20 17:24:44,602 - root - INFO -   Epoch 34/150	 Time: 2.685	 Loss: 6.35014580
2019-06-20 17:24:47,272 - root - INFO -   Epoch 35/150	 Time: 2.670	 Loss: 6.34388324
2019-06-20 17:24:49,941 - root - INFO -   Epoch 36/150	 Time: 2.669	 Loss: 6.34087182
2019-06-20 17:24:52,602 - root - INFO -   Epoch 37/150	 Time: 2.661	 Loss: 6.32995935
2019-06-20 17:24:55,278 - root - INFO -   Epoch 38/150	 Time: 2.676	 Loss: 6.32579105
2019-06-20 17:24:57,920 - root - INFO -   Epoch 39/150	 Time: 2.642	 Loss: 6.31995302
2019-06-20 17:25:00,553 - root - INFO -   Epoch 40/150	 Time: 2.633	 Loss: 6.31248970
2019-06-20 17:25:03,180 - root - INFO -   Epoch 41/150	 Time: 2.627	 Loss: 6.30549742
2019-06-20 17:25:05,827 - root - INFO -   Epoch 42/150	 Time: 2.647	 Loss: 6.30304794
2019-06-20 17:25:08,498 - root - INFO -   Epoch 43/150	 Time: 2.671	 Loss: 6.29661477
2019-06-20 17:25:11,155 - root - INFO -   Epoch 44/150	 Time: 2.657	 Loss: 6.29032967
2019-06-20 17:25:13,816 - root - INFO -   Epoch 45/150	 Time: 2.661	 Loss: 6.28211379
2019-06-20 17:25:16,488 - root - INFO -   Epoch 46/150	 Time: 2.672	 Loss: 6.28089020
2019-06-20 17:25:19,150 - root - INFO -   Epoch 47/150	 Time: 2.662	 Loss: 6.27510845
2019-06-20 17:25:21,829 - root - INFO -   Epoch 48/150	 Time: 2.678	 Loss: 6.27069571
2019-06-20 17:25:24,504 - root - INFO -   Epoch 49/150	 Time: 2.675	 Loss: 6.26801757
2019-06-20 17:25:27,209 - root - INFO -   Epoch 50/150	 Time: 2.705	 Loss: 6.25416291
2019-06-20 17:25:27,209 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:25:29,883 - root - INFO -   Epoch 51/150	 Time: 2.674	 Loss: 6.25371410
2019-06-20 17:25:32,545 - root - INFO -   Epoch 52/150	 Time: 2.662	 Loss: 6.25313416
2019-06-20 17:25:35,229 - root - INFO -   Epoch 53/150	 Time: 2.684	 Loss: 6.25409945
2019-06-20 17:25:37,907 - root - INFO -   Epoch 54/150	 Time: 2.678	 Loss: 6.25090052
2019-06-20 17:25:40,578 - root - INFO -   Epoch 55/150	 Time: 2.671	 Loss: 6.25340900
2019-06-20 17:25:43,246 - root - INFO -   Epoch 56/150	 Time: 2.668	 Loss: 6.25297152
2019-06-20 17:25:45,921 - root - INFO -   Epoch 57/150	 Time: 2.675	 Loss: 6.25571752
2019-06-20 17:25:48,596 - root - INFO -   Epoch 58/150	 Time: 2.674	 Loss: 6.24748438
2019-06-20 17:25:51,277 - root - INFO -   Epoch 59/150	 Time: 2.681	 Loss: 6.24935644
2019-06-20 17:25:53,938 - root - INFO -   Epoch 60/150	 Time: 2.661	 Loss: 6.24719246
2019-06-20 17:25:56,611 - root - INFO -   Epoch 61/150	 Time: 2.672	 Loss: 6.25014540
2019-06-20 17:25:59,272 - root - INFO -   Epoch 62/150	 Time: 2.661	 Loss: 6.24968274
2019-06-20 17:26:01,933 - root - INFO -   Epoch 63/150	 Time: 2.661	 Loss: 6.24658368
2019-06-20 17:26:04,588 - root - INFO -   Epoch 64/150	 Time: 2.655	 Loss: 6.24563253
2019-06-20 17:26:07,221 - root - INFO -   Epoch 65/150	 Time: 2.633	 Loss: 6.24454575
2019-06-20 17:26:09,876 - root - INFO -   Epoch 66/150	 Time: 2.655	 Loss: 6.24670084
2019-06-20 17:26:12,517 - root - INFO -   Epoch 67/150	 Time: 2.640	 Loss: 6.24335873
2019-06-20 17:26:15,162 - root - INFO -   Epoch 68/150	 Time: 2.645	 Loss: 6.24679689
2019-06-20 17:26:17,810 - root - INFO -   Epoch 69/150	 Time: 2.648	 Loss: 6.24628350
2019-06-20 17:26:20,450 - root - INFO -   Epoch 70/150	 Time: 2.639	 Loss: 6.24519099
2019-06-20 17:26:23,086 - root - INFO -   Epoch 71/150	 Time: 2.636	 Loss: 6.24123851
2019-06-20 17:26:25,746 - root - INFO -   Epoch 72/150	 Time: 2.660	 Loss: 6.24276576
2019-06-20 17:26:28,394 - root - INFO -   Epoch 73/150	 Time: 2.648	 Loss: 6.23968406
2019-06-20 17:26:31,045 - root - INFO -   Epoch 74/150	 Time: 2.650	 Loss: 6.24149112
2019-06-20 17:26:33,707 - root - INFO -   Epoch 75/150	 Time: 2.662	 Loss: 6.23818318
2019-06-20 17:26:36,368 - root - INFO -   Epoch 76/150	 Time: 2.661	 Loss: 6.23869417
2019-06-20 17:26:39,040 - root - INFO -   Epoch 77/150	 Time: 2.672	 Loss: 6.24123886
2019-06-20 17:26:41,720 - root - INFO -   Epoch 78/150	 Time: 2.680	 Loss: 6.23707017
2019-06-20 17:26:44,373 - root - INFO -   Epoch 79/150	 Time: 2.652	 Loss: 6.23989738
2019-06-20 17:26:47,025 - root - INFO -   Epoch 80/150	 Time: 2.652	 Loss: 6.23740589
2019-06-20 17:26:49,680 - root - INFO -   Epoch 81/150	 Time: 2.654	 Loss: 6.23736563
2019-06-20 17:26:52,346 - root - INFO -   Epoch 82/150	 Time: 2.666	 Loss: 6.23445263
2019-06-20 17:26:55,001 - root - INFO -   Epoch 83/150	 Time: 2.655	 Loss: 6.23801863
2019-06-20 17:26:57,671 - root - INFO -   Epoch 84/150	 Time: 2.670	 Loss: 6.23396498
2019-06-20 17:27:00,336 - root - INFO -   Epoch 85/150	 Time: 2.665	 Loss: 6.23277338
2019-06-20 17:27:02,994 - root - INFO -   Epoch 86/150	 Time: 2.658	 Loss: 6.23349955
2019-06-20 17:27:05,645 - root - INFO -   Epoch 87/150	 Time: 2.650	 Loss: 6.23360542
2019-06-20 17:27:08,308 - root - INFO -   Epoch 88/150	 Time: 2.663	 Loss: 6.23273732
2019-06-20 17:27:10,985 - root - INFO -   Epoch 89/150	 Time: 2.676	 Loss: 6.23048589
2019-06-20 17:27:13,651 - root - INFO -   Epoch 90/150	 Time: 2.666	 Loss: 6.23413318
2019-06-20 17:27:16,320 - root - INFO -   Epoch 91/150	 Time: 2.669	 Loss: 6.23633983
2019-06-20 17:27:18,999 - root - INFO -   Epoch 92/150	 Time: 2.678	 Loss: 6.23004717
2019-06-20 17:27:21,666 - root - INFO -   Epoch 93/150	 Time: 2.667	 Loss: 6.22696004
2019-06-20 17:27:24,348 - root - INFO -   Epoch 94/150	 Time: 2.682	 Loss: 6.23088403
2019-06-20 17:27:27,018 - root - INFO -   Epoch 95/150	 Time: 2.670	 Loss: 6.23109467
2019-06-20 17:27:29,683 - root - INFO -   Epoch 96/150	 Time: 2.664	 Loss: 6.22754872
2019-06-20 17:27:32,370 - root - INFO -   Epoch 97/150	 Time: 2.687	 Loss: 6.22814392
2019-06-20 17:27:35,022 - root - INFO -   Epoch 98/150	 Time: 2.652	 Loss: 6.22946106
2019-06-20 17:27:37,707 - root - INFO -   Epoch 99/150	 Time: 2.684	 Loss: 6.22829848
2019-06-20 17:27:40,395 - root - INFO -   Epoch 100/150	 Time: 2.689	 Loss: 6.22453388
2019-06-20 17:27:43,086 - root - INFO -   Epoch 101/150	 Time: 2.691	 Loss: 6.22621523
2019-06-20 17:27:45,775 - root - INFO -   Epoch 102/150	 Time: 2.688	 Loss: 6.22613408
2019-06-20 17:27:48,459 - root - INFO -   Epoch 103/150	 Time: 2.684	 Loss: 6.22247566
2019-06-20 17:27:51,122 - root - INFO -   Epoch 104/150	 Time: 2.664	 Loss: 6.22381806
2019-06-20 17:27:53,789 - root - INFO -   Epoch 105/150	 Time: 2.667	 Loss: 6.22403664
2019-06-20 17:27:56,469 - root - INFO -   Epoch 106/150	 Time: 2.680	 Loss: 6.22328102
2019-06-20 17:27:59,129 - root - INFO -   Epoch 107/150	 Time: 2.660	 Loss: 6.22334327
2019-06-20 17:28:01,775 - root - INFO -   Epoch 108/150	 Time: 2.646	 Loss: 6.22365144
2019-06-20 17:28:04,442 - root - INFO -   Epoch 109/150	 Time: 2.667	 Loss: 6.21962273
2019-06-20 17:28:07,111 - root - INFO -   Epoch 110/150	 Time: 2.669	 Loss: 6.22172706
2019-06-20 17:28:09,776 - root - INFO -   Epoch 111/150	 Time: 2.665	 Loss: 6.22072601
2019-06-20 17:28:12,447 - root - INFO -   Epoch 112/150	 Time: 2.671	 Loss: 6.21691472
2019-06-20 17:28:15,114 - root - INFO -   Epoch 113/150	 Time: 2.667	 Loss: 6.21989086
2019-06-20 17:28:17,766 - root - INFO -   Epoch 114/150	 Time: 2.652	 Loss: 6.22081116
2019-06-20 17:28:20,424 - root - INFO -   Epoch 115/150	 Time: 2.658	 Loss: 6.21943299
2019-06-20 17:28:23,084 - root - INFO -   Epoch 116/150	 Time: 2.660	 Loss: 6.21633579
2019-06-20 17:28:25,744 - root - INFO -   Epoch 117/150	 Time: 2.660	 Loss: 6.21901361
2019-06-20 17:28:28,417 - root - INFO -   Epoch 118/150	 Time: 2.672	 Loss: 6.21577363
2019-06-20 17:28:31,088 - root - INFO -   Epoch 119/150	 Time: 2.671	 Loss: 6.21767719
2019-06-20 17:28:33,747 - root - INFO -   Epoch 120/150	 Time: 2.659	 Loss: 6.21827010
2019-06-20 17:28:36,411 - root - INFO -   Epoch 121/150	 Time: 2.663	 Loss: 6.21262865
2019-06-20 17:28:39,080 - root - INFO -   Epoch 122/150	 Time: 2.669	 Loss: 6.21721333
2019-06-20 17:28:41,737 - root - INFO -   Epoch 123/150	 Time: 2.658	 Loss: 6.21527074
2019-06-20 17:28:44,386 - root - INFO -   Epoch 124/150	 Time: 2.649	 Loss: 6.21526268
2019-06-20 17:28:47,047 - root - INFO -   Epoch 125/150	 Time: 2.661	 Loss: 6.21477416
2019-06-20 17:28:49,719 - root - INFO -   Epoch 126/150	 Time: 2.671	 Loss: 6.21321654
2019-06-20 17:28:52,382 - root - INFO -   Epoch 127/150	 Time: 2.664	 Loss: 6.21155486
2019-06-20 17:28:55,042 - root - INFO -   Epoch 128/150	 Time: 2.659	 Loss: 6.21139448
2019-06-20 17:28:57,709 - root - INFO -   Epoch 129/150	 Time: 2.666	 Loss: 6.21424223
2019-06-20 17:29:00,375 - root - INFO -   Epoch 130/150	 Time: 2.666	 Loss: 6.21343072
2019-06-20 17:29:03,024 - root - INFO -   Epoch 131/150	 Time: 2.648	 Loss: 6.21441805
2019-06-20 17:29:05,679 - root - INFO -   Epoch 132/150	 Time: 2.655	 Loss: 6.20868341
2019-06-20 17:29:08,346 - root - INFO -   Epoch 133/150	 Time: 2.667	 Loss: 6.21045348
2019-06-20 17:29:10,992 - root - INFO -   Epoch 134/150	 Time: 2.646	 Loss: 6.20700185
2019-06-20 17:29:13,648 - root - INFO -   Epoch 135/150	 Time: 2.656	 Loss: 6.20732049
2019-06-20 17:29:16,317 - root - INFO -   Epoch 136/150	 Time: 2.669	 Loss: 6.20880803
2019-06-20 17:29:19,005 - root - INFO -   Epoch 137/150	 Time: 2.688	 Loss: 6.20740051
2019-06-20 17:29:21,658 - root - INFO -   Epoch 138/150	 Time: 2.653	 Loss: 6.20859655
2019-06-20 17:29:24,322 - root - INFO -   Epoch 139/150	 Time: 2.663	 Loss: 6.20533798
2019-06-20 17:29:26,977 - root - INFO -   Epoch 140/150	 Time: 2.655	 Loss: 6.20727367
2019-06-20 17:29:29,666 - root - INFO -   Epoch 141/150	 Time: 2.690	 Loss: 6.20759741
2019-06-20 17:29:32,323 - root - INFO -   Epoch 142/150	 Time: 2.657	 Loss: 6.20642353
2019-06-20 17:29:34,964 - root - INFO -   Epoch 143/150	 Time: 2.640	 Loss: 6.20452491
2019-06-20 17:29:37,609 - root - INFO -   Epoch 144/150	 Time: 2.646	 Loss: 6.20737433
2019-06-20 17:29:40,269 - root - INFO -   Epoch 145/150	 Time: 2.659	 Loss: 6.20689093
2019-06-20 17:29:42,938 - root - INFO -   Epoch 146/150	 Time: 2.669	 Loss: 6.20628634
2019-06-20 17:29:45,591 - root - INFO -   Epoch 147/150	 Time: 2.652	 Loss: 6.20370042
2019-06-20 17:29:48,301 - root - INFO -   Epoch 148/150	 Time: 2.710	 Loss: 6.20365078
2019-06-20 17:29:50,997 - root - INFO -   Epoch 149/150	 Time: 2.696	 Loss: 6.20189147
2019-06-20 17:29:53,696 - root - INFO -   Epoch 150/150	 Time: 2.698	 Loss: 6.20007428
2019-06-20 17:29:53,696 - root - INFO - Pretraining time: 400.533
2019-06-20 17:29:53,696 - root - INFO - Finished pretraining.
2019-06-20 17:29:53,696 - root - INFO - Testing autoencoder...
2019-06-20 17:29:55,020 - root - INFO - Test set Loss: 6.91779534
2019-06-20 17:29:55,093 - root - INFO - Test set AUC: 61.47%
2019-06-20 17:29:55,093 - root - INFO - Autoencoder testing time: 1.397
2019-06-20 17:29:55,093 - root - INFO - Finished testing autoencoder.
2019-06-20 17:29:55,097 - root - INFO - Training optimizer: adam
2019-06-20 17:29:55,097 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:29:55,097 - root - INFO - Training epochs: 150
2019-06-20 17:29:55,097 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:29:55,097 - root - INFO - Training batch size: 200
2019-06-20 17:29:55,097 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:29:55,098 - root - INFO - Initializing center c...
2019-06-20 17:29:56,173 - root - INFO - Center c initialized.
2019-06-20 17:29:56,173 - root - INFO - Starting training...
2019-06-20 17:29:57,955 - root - INFO -   Epoch 1/150	 Time: 1.782	 Loss: 0.30549915
2019-06-20 17:29:59,727 - root - INFO -   Epoch 2/150	 Time: 1.772	 Loss: 0.07961659
2019-06-20 17:30:01,502 - root - INFO -   Epoch 3/150	 Time: 1.775	 Loss: 0.04611896
2019-06-20 17:30:03,292 - root - INFO -   Epoch 4/150	 Time: 1.790	 Loss: 0.03178556
2019-06-20 17:30:05,068 - root - INFO -   Epoch 5/150	 Time: 1.776	 Loss: 0.02498519
2019-06-20 17:30:06,806 - root - INFO -   Epoch 6/150	 Time: 1.737	 Loss: 0.02041418
2019-06-20 17:30:08,563 - root - INFO -   Epoch 7/150	 Time: 1.757	 Loss: 0.01743753
2019-06-20 17:30:10,334 - root - INFO -   Epoch 8/150	 Time: 1.770	 Loss: 0.01526006
2019-06-20 17:30:12,096 - root - INFO -   Epoch 9/150	 Time: 1.762	 Loss: 0.01389805
2019-06-20 17:30:13,800 - root - INFO -   Epoch 10/150	 Time: 1.704	 Loss: 0.01252342
2019-06-20 17:30:15,505 - root - INFO -   Epoch 11/150	 Time: 1.705	 Loss: 0.01076636
2019-06-20 17:30:17,238 - root - INFO -   Epoch 12/150	 Time: 1.733	 Loss: 0.01009415
2019-06-20 17:30:19,009 - root - INFO -   Epoch 13/150	 Time: 1.771	 Loss: 0.00978986
2019-06-20 17:30:20,730 - root - INFO -   Epoch 14/150	 Time: 1.721	 Loss: 0.00885446
2019-06-20 17:30:22,499 - root - INFO -   Epoch 15/150	 Time: 1.768	 Loss: 0.00801055
2019-06-20 17:30:24,269 - root - INFO -   Epoch 16/150	 Time: 1.770	 Loss: 0.00753892
2019-06-20 17:30:26,046 - root - INFO -   Epoch 17/150	 Time: 1.777	 Loss: 0.00755593
2019-06-20 17:30:27,823 - root - INFO -   Epoch 18/150	 Time: 1.777	 Loss: 0.00677415
2019-06-20 17:30:29,595 - root - INFO -   Epoch 19/150	 Time: 1.772	 Loss: 0.00640596
2019-06-20 17:30:31,361 - root - INFO -   Epoch 20/150	 Time: 1.766	 Loss: 0.00586725
2019-06-20 17:30:33,142 - root - INFO -   Epoch 21/150	 Time: 1.781	 Loss: 0.00580289
2019-06-20 17:30:34,922 - root - INFO -   Epoch 22/150	 Time: 1.781	 Loss: 0.00558946
2019-06-20 17:30:36,664 - root - INFO -   Epoch 23/150	 Time: 1.742	 Loss: 0.00509255
2019-06-20 17:30:38,374 - root - INFO -   Epoch 24/150	 Time: 1.710	 Loss: 0.00500704
2019-06-20 17:30:40,083 - root - INFO -   Epoch 25/150	 Time: 1.709	 Loss: 0.00462297
2019-06-20 17:30:41,800 - root - INFO -   Epoch 26/150	 Time: 1.717	 Loss: 0.00462104
2019-06-20 17:30:43,510 - root - INFO -   Epoch 27/150	 Time: 1.709	 Loss: 0.00439633
2019-06-20 17:30:45,221 - root - INFO -   Epoch 28/150	 Time: 1.711	 Loss: 0.00405758
2019-06-20 17:30:46,931 - root - INFO -   Epoch 29/150	 Time: 1.710	 Loss: 0.00397697
2019-06-20 17:30:48,681 - root - INFO -   Epoch 30/150	 Time: 1.750	 Loss: 0.00379877
2019-06-20 17:30:50,452 - root - INFO -   Epoch 31/150	 Time: 1.770	 Loss: 0.00355004
2019-06-20 17:30:52,236 - root - INFO -   Epoch 32/150	 Time: 1.784	 Loss: 0.00352081
2019-06-20 17:30:54,024 - root - INFO -   Epoch 33/150	 Time: 1.788	 Loss: 0.00340578
2019-06-20 17:30:55,815 - root - INFO -   Epoch 34/150	 Time: 1.790	 Loss: 0.00306464
2019-06-20 17:30:57,623 - root - INFO -   Epoch 35/150	 Time: 1.808	 Loss: 0.00321168
2019-06-20 17:30:59,399 - root - INFO -   Epoch 36/150	 Time: 1.776	 Loss: 0.00305746
2019-06-20 17:31:01,175 - root - INFO -   Epoch 37/150	 Time: 1.776	 Loss: 0.00290725
2019-06-20 17:31:02,962 - root - INFO -   Epoch 38/150	 Time: 1.787	 Loss: 0.00277884
2019-06-20 17:31:04,768 - root - INFO -   Epoch 39/150	 Time: 1.806	 Loss: 0.00267590
2019-06-20 17:31:06,556 - root - INFO -   Epoch 40/150	 Time: 1.788	 Loss: 0.00265328
2019-06-20 17:31:08,342 - root - INFO -   Epoch 41/150	 Time: 1.786	 Loss: 0.00260603
2019-06-20 17:31:10,134 - root - INFO -   Epoch 42/150	 Time: 1.792	 Loss: 0.00252138
2019-06-20 17:31:11,908 - root - INFO -   Epoch 43/150	 Time: 1.774	 Loss: 0.00256313
2019-06-20 17:31:13,672 - root - INFO -   Epoch 44/150	 Time: 1.763	 Loss: 0.00235844
2019-06-20 17:31:15,396 - root - INFO -   Epoch 45/150	 Time: 1.724	 Loss: 0.00224947
2019-06-20 17:31:17,104 - root - INFO -   Epoch 46/150	 Time: 1.708	 Loss: 0.00213720
2019-06-20 17:31:18,815 - root - INFO -   Epoch 47/150	 Time: 1.711	 Loss: 0.00214175
2019-06-20 17:31:20,561 - root - INFO -   Epoch 48/150	 Time: 1.746	 Loss: 0.00210359
2019-06-20 17:31:22,339 - root - INFO -   Epoch 49/150	 Time: 1.778	 Loss: 0.00195310
2019-06-20 17:31:24,101 - root - INFO -   Epoch 50/150	 Time: 1.761	 Loss: 0.00165063
2019-06-20 17:31:24,101 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:31:25,864 - root - INFO -   Epoch 51/150	 Time: 1.763	 Loss: 0.00163284
2019-06-20 17:31:27,666 - root - INFO -   Epoch 52/150	 Time: 1.802	 Loss: 0.00162081
2019-06-20 17:31:29,454 - root - INFO -   Epoch 53/150	 Time: 1.787	 Loss: 0.00159821
2019-06-20 17:31:31,228 - root - INFO -   Epoch 54/150	 Time: 1.773	 Loss: 0.00162424
2019-06-20 17:31:33,011 - root - INFO -   Epoch 55/150	 Time: 1.783	 Loss: 0.00158176
2019-06-20 17:31:34,790 - root - INFO -   Epoch 56/150	 Time: 1.779	 Loss: 0.00161527
2019-06-20 17:31:36,570 - root - INFO -   Epoch 57/150	 Time: 1.780	 Loss: 0.00160477
2019-06-20 17:31:38,341 - root - INFO -   Epoch 58/150	 Time: 1.771	 Loss: 0.00155127
2019-06-20 17:31:40,118 - root - INFO -   Epoch 59/150	 Time: 1.777	 Loss: 0.00156906
2019-06-20 17:31:41,899 - root - INFO -   Epoch 60/150	 Time: 1.781	 Loss: 0.00161760
2019-06-20 17:31:43,616 - root - INFO -   Epoch 61/150	 Time: 1.717	 Loss: 0.00158331
2019-06-20 17:31:45,323 - root - INFO -   Epoch 62/150	 Time: 1.707	 Loss: 0.00161356
2019-06-20 17:31:47,040 - root - INFO -   Epoch 63/150	 Time: 1.717	 Loss: 0.00155017
2019-06-20 17:31:48,778 - root - INFO -   Epoch 64/150	 Time: 1.738	 Loss: 0.00159163
2019-06-20 17:31:50,564 - root - INFO -   Epoch 65/150	 Time: 1.786	 Loss: 0.00156328
2019-06-20 17:31:52,339 - root - INFO -   Epoch 66/150	 Time: 1.775	 Loss: 0.00151111
2019-06-20 17:31:54,115 - root - INFO -   Epoch 67/150	 Time: 1.776	 Loss: 0.00155014
2019-06-20 17:31:55,896 - root - INFO -   Epoch 68/150	 Time: 1.781	 Loss: 0.00150546
2019-06-20 17:31:57,670 - root - INFO -   Epoch 69/150	 Time: 1.773	 Loss: 0.00146955
2019-06-20 17:31:59,446 - root - INFO -   Epoch 70/150	 Time: 1.776	 Loss: 0.00147782
2019-06-20 17:32:01,236 - root - INFO -   Epoch 71/150	 Time: 1.790	 Loss: 0.00153610
2019-06-20 17:32:03,031 - root - INFO -   Epoch 72/150	 Time: 1.796	 Loss: 0.00153439
2019-06-20 17:32:04,817 - root - INFO -   Epoch 73/150	 Time: 1.786	 Loss: 0.00152867
2019-06-20 17:32:06,592 - root - INFO -   Epoch 74/150	 Time: 1.774	 Loss: 0.00148392
2019-06-20 17:32:08,363 - root - INFO -   Epoch 75/150	 Time: 1.771	 Loss: 0.00149349
2019-06-20 17:32:10,139 - root - INFO -   Epoch 76/150	 Time: 1.776	 Loss: 0.00150436
2019-06-20 17:32:11,909 - root - INFO -   Epoch 77/150	 Time: 1.770	 Loss: 0.00151377
2019-06-20 17:32:13,651 - root - INFO -   Epoch 78/150	 Time: 1.742	 Loss: 0.00145487
2019-06-20 17:32:15,366 - root - INFO -   Epoch 79/150	 Time: 1.715	 Loss: 0.00147057
2019-06-20 17:32:17,078 - root - INFO -   Epoch 80/150	 Time: 1.712	 Loss: 0.00144507
2019-06-20 17:32:18,788 - root - INFO -   Epoch 81/150	 Time: 1.709	 Loss: 0.00144851
2019-06-20 17:32:20,505 - root - INFO -   Epoch 82/150	 Time: 1.717	 Loss: 0.00144560
2019-06-20 17:32:22,238 - root - INFO -   Epoch 83/150	 Time: 1.733	 Loss: 0.00139252
2019-06-20 17:32:24,022 - root - INFO -   Epoch 84/150	 Time: 1.783	 Loss: 0.00137220
2019-06-20 17:32:25,811 - root - INFO -   Epoch 85/150	 Time: 1.790	 Loss: 0.00140130
2019-06-20 17:32:27,612 - root - INFO -   Epoch 86/150	 Time: 1.801	 Loss: 0.00141301
2019-06-20 17:32:29,397 - root - INFO -   Epoch 87/150	 Time: 1.784	 Loss: 0.00139266
2019-06-20 17:32:31,168 - root - INFO -   Epoch 88/150	 Time: 1.771	 Loss: 0.00142614
2019-06-20 17:32:32,926 - root - INFO -   Epoch 89/150	 Time: 1.758	 Loss: 0.00138370
2019-06-20 17:32:34,695 - root - INFO -   Epoch 90/150	 Time: 1.769	 Loss: 0.00141271
2019-06-20 17:32:36,434 - root - INFO -   Epoch 91/150	 Time: 1.739	 Loss: 0.00138904
2019-06-20 17:32:38,219 - root - INFO -   Epoch 92/150	 Time: 1.785	 Loss: 0.00137946
2019-06-20 17:32:40,004 - root - INFO -   Epoch 93/150	 Time: 1.784	 Loss: 0.00137353
2019-06-20 17:32:41,833 - root - INFO -   Epoch 94/150	 Time: 1.829	 Loss: 0.00141786
2019-06-20 17:32:43,645 - root - INFO -   Epoch 95/150	 Time: 1.812	 Loss: 0.00132232
2019-06-20 17:32:45,459 - root - INFO -   Epoch 96/150	 Time: 1.814	 Loss: 0.00135083
2019-06-20 17:32:47,270 - root - INFO -   Epoch 97/150	 Time: 1.810	 Loss: 0.00135456
2019-06-20 17:32:49,078 - root - INFO -   Epoch 98/150	 Time: 1.808	 Loss: 0.00134975
2019-06-20 17:32:50,869 - root - INFO -   Epoch 99/150	 Time: 1.791	 Loss: 0.00132467
2019-06-20 17:32:52,686 - root - INFO -   Epoch 100/150	 Time: 1.817	 Loss: 0.00132863
2019-06-20 17:32:54,471 - root - INFO -   Epoch 101/150	 Time: 1.784	 Loss: 0.00134698
2019-06-20 17:32:56,286 - root - INFO -   Epoch 102/150	 Time: 1.815	 Loss: 0.00130890
2019-06-20 17:32:58,099 - root - INFO -   Epoch 103/150	 Time: 1.813	 Loss: 0.00134472
2019-06-20 17:32:59,875 - root - INFO -   Epoch 104/150	 Time: 1.776	 Loss: 0.00131823
2019-06-20 17:33:01,664 - root - INFO -   Epoch 105/150	 Time: 1.789	 Loss: 0.00132456
2019-06-20 17:33:03,448 - root - INFO -   Epoch 106/150	 Time: 1.785	 Loss: 0.00130109
2019-06-20 17:33:05,235 - root - INFO -   Epoch 107/150	 Time: 1.787	 Loss: 0.00127746
2019-06-20 17:33:07,031 - root - INFO -   Epoch 108/150	 Time: 1.796	 Loss: 0.00124052
2019-06-20 17:33:08,845 - root - INFO -   Epoch 109/150	 Time: 1.814	 Loss: 0.00129026
2019-06-20 17:33:10,654 - root - INFO -   Epoch 110/150	 Time: 1.808	 Loss: 0.00128377
2019-06-20 17:33:12,478 - root - INFO -   Epoch 111/150	 Time: 1.825	 Loss: 0.00129167
2019-06-20 17:33:14,266 - root - INFO -   Epoch 112/150	 Time: 1.787	 Loss: 0.00125346
2019-06-20 17:33:16,055 - root - INFO -   Epoch 113/150	 Time: 1.789	 Loss: 0.00128441
2019-06-20 17:33:17,841 - root - INFO -   Epoch 114/150	 Time: 1.786	 Loss: 0.00126068
2019-06-20 17:33:19,654 - root - INFO -   Epoch 115/150	 Time: 1.813	 Loss: 0.00120740
2019-06-20 17:33:21,445 - root - INFO -   Epoch 116/150	 Time: 1.791	 Loss: 0.00119652
2019-06-20 17:33:23,247 - root - INFO -   Epoch 117/150	 Time: 1.802	 Loss: 0.00122446
2019-06-20 17:33:25,058 - root - INFO -   Epoch 118/150	 Time: 1.810	 Loss: 0.00122763
2019-06-20 17:33:26,877 - root - INFO -   Epoch 119/150	 Time: 1.819	 Loss: 0.00121931
2019-06-20 17:33:28,672 - root - INFO -   Epoch 120/150	 Time: 1.795	 Loss: 0.00120727
2019-06-20 17:33:30,418 - root - INFO -   Epoch 121/150	 Time: 1.746	 Loss: 0.00119510
2019-06-20 17:33:32,190 - root - INFO -   Epoch 122/150	 Time: 1.772	 Loss: 0.00123032
2019-06-20 17:33:33,984 - root - INFO -   Epoch 123/150	 Time: 1.793	 Loss: 0.00119412
2019-06-20 17:33:35,770 - root - INFO -   Epoch 124/150	 Time: 1.787	 Loss: 0.00117027
2019-06-20 17:33:37,564 - root - INFO -   Epoch 125/150	 Time: 1.793	 Loss: 0.00117659
2019-06-20 17:33:39,335 - root - INFO -   Epoch 126/150	 Time: 1.771	 Loss: 0.00120157
2019-06-20 17:33:41,062 - root - INFO -   Epoch 127/150	 Time: 1.727	 Loss: 0.00118976
2019-06-20 17:33:42,795 - root - INFO -   Epoch 128/150	 Time: 1.733	 Loss: 0.00116820
2019-06-20 17:33:44,523 - root - INFO -   Epoch 129/150	 Time: 1.728	 Loss: 0.00119829
2019-06-20 17:33:46,266 - root - INFO -   Epoch 130/150	 Time: 1.742	 Loss: 0.00116351
2019-06-20 17:33:48,060 - root - INFO -   Epoch 131/150	 Time: 1.794	 Loss: 0.00115290
2019-06-20 17:33:49,877 - root - INFO -   Epoch 132/150	 Time: 1.817	 Loss: 0.00114932
2019-06-20 17:33:51,660 - root - INFO -   Epoch 133/150	 Time: 1.783	 Loss: 0.00115407
2019-06-20 17:33:53,456 - root - INFO -   Epoch 134/150	 Time: 1.796	 Loss: 0.00112099
2019-06-20 17:33:55,246 - root - INFO -   Epoch 135/150	 Time: 1.789	 Loss: 0.00116200
2019-06-20 17:33:57,041 - root - INFO -   Epoch 136/150	 Time: 1.795	 Loss: 0.00111368
2019-06-20 17:33:58,828 - root - INFO -   Epoch 137/150	 Time: 1.786	 Loss: 0.00111804
2019-06-20 17:34:00,619 - root - INFO -   Epoch 138/150	 Time: 1.791	 Loss: 0.00114440
2019-06-20 17:34:02,420 - root - INFO -   Epoch 139/150	 Time: 1.801	 Loss: 0.00112799
2019-06-20 17:34:04,225 - root - INFO -   Epoch 140/150	 Time: 1.805	 Loss: 0.00110884
2019-06-20 17:34:06,051 - root - INFO -   Epoch 141/150	 Time: 1.826	 Loss: 0.00115527
2019-06-20 17:34:07,812 - root - INFO -   Epoch 142/150	 Time: 1.760	 Loss: 0.00111939
2019-06-20 17:34:09,642 - root - INFO -   Epoch 143/150	 Time: 1.830	 Loss: 0.00108965
2019-06-20 17:34:11,495 - root - INFO -   Epoch 144/150	 Time: 1.854	 Loss: 0.00108713
2019-06-20 17:34:13,297 - root - INFO -   Epoch 145/150	 Time: 1.801	 Loss: 0.00107175
2019-06-20 17:34:15,106 - root - INFO -   Epoch 146/150	 Time: 1.809	 Loss: 0.00108071
2019-06-20 17:34:16,876 - root - INFO -   Epoch 147/150	 Time: 1.770	 Loss: 0.00105417
2019-06-20 17:34:18,639 - root - INFO -   Epoch 148/150	 Time: 1.763	 Loss: 0.00113181
2019-06-20 17:34:20,446 - root - INFO -   Epoch 149/150	 Time: 1.806	 Loss: 0.00105171
2019-06-20 17:34:22,221 - root - INFO -   Epoch 150/150	 Time: 1.775	 Loss: 0.00105047
2019-06-20 17:34:22,221 - root - INFO - Training time: 266.047
2019-06-20 17:34:22,221 - root - INFO - Finished training.
2019-06-20 17:34:22,221 - root - INFO - Starting testing...
2019-06-20 17:34:23,197 - root - INFO - Testing time: 0.976
2019-06-20 17:34:23,266 - root - INFO - Test set AUC: 75.31%
2019-06-20 17:34:23,266 - root - INFO - Finished testing.
2019-06-20 17:37:26,151 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:37:26,151 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:37:26,151 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:37:26,151 - root - INFO - Dataset: hits
2019-06-20 17:37:26,151 - root - INFO - Normal class: 1
2019-06-20 17:37:26,151 - root - INFO - Network: hits_LeNet
2019-06-20 17:37:26,151 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:37:26,151 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:37:26,189 - root - INFO - Computation device: cuda
2019-06-20 17:37:26,189 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:37:36,067 - root - INFO - Pretraining: True
2019-06-20 17:37:36,068 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:37:36,068 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:37:36,068 - root - INFO - Pretraining epochs: 2
2019-06-20 17:37:36,068 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:37:36,068 - root - INFO - Pretraining batch size: 200
2019-06-20 17:37:36,068 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:37:38,154 - root - INFO - Starting pretraining...
2019-06-20 17:37:41,398 - root - INFO -   Epoch 1/2	 Time: 3.244	 Loss: 14.55410245
2019-06-20 17:37:44,375 - root - INFO -   Epoch 2/2	 Time: 2.976	 Loss: 8.22712424
2019-06-20 17:37:44,375 - root - INFO - Pretraining time: 6.220
2019-06-20 17:37:44,375 - root - INFO - Finished pretraining.
2019-06-20 17:37:44,375 - root - INFO - Testing autoencoder...
2019-06-20 17:37:46,181 - root - INFO - Test set Loss: 10.73809366
2019-06-20 17:37:46,251 - root - INFO - Test set AUC: 81.80%
2019-06-20 17:37:46,251 - root - INFO - Autoencoder testing time: 1.876
2019-06-20 17:37:46,251 - root - INFO - Finished testing autoencoder.
2019-06-20 17:37:46,255 - root - INFO - Training optimizer: adam
2019-06-20 17:37:46,256 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:37:46,256 - root - INFO - Training epochs: 2
2019-06-20 17:37:46,256 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:37:46,256 - root - INFO - Training batch size: 200
2019-06-20 17:37:46,256 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:37:46,256 - root - INFO - Initializing center c...
2019-06-20 17:37:47,711 - root - INFO - Center c initialized.
2019-06-20 17:37:47,712 - root - INFO - Starting training...
2019-06-20 17:37:49,788 - root - INFO -   Epoch 1/2	 Time: 2.076	 Loss: 0.91618391
2019-06-20 17:37:51,838 - root - INFO -   Epoch 2/2	 Time: 2.049	 Loss: 0.18287016
2019-06-20 17:37:51,838 - root - INFO - Training time: 4.126
2019-06-20 17:37:51,838 - root - INFO - Finished training.
2019-06-20 17:37:51,838 - root - INFO - Starting testing...
2019-06-20 17:37:53,297 - root - INFO - Testing time: 1.459
2019-06-20 17:37:53,367 - root - INFO - Test set AUC: 91.89%
2019-06-20 17:37:53,367 - root - INFO - Finished testing.
2019-06-20 17:39:58,781 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:39:58,781 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:39:58,781 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:39:58,781 - root - INFO - Dataset: hits
2019-06-20 17:39:58,781 - root - INFO - Normal class: 1
2019-06-20 17:39:58,781 - root - INFO - Network: hits_LeNet
2019-06-20 17:39:58,782 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:39:58,782 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:39:58,818 - root - INFO - Computation device: cuda
2019-06-20 17:39:58,818 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:40:08,680 - root - INFO - Pretraining: True
2019-06-20 17:40:08,680 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:40:08,680 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:40:08,680 - root - INFO - Pretraining epochs: 2
2019-06-20 17:40:08,680 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:40:08,680 - root - INFO - Pretraining batch size: 200
2019-06-20 17:40:08,680 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:40:10,816 - root - INFO - Starting pretraining...
2019-06-20 17:40:14,048 - root - INFO -   Epoch 1/2	 Time: 3.232	 Loss: 11.98258979
2019-06-20 17:40:17,071 - root - INFO -   Epoch 2/2	 Time: 3.023	 Loss: 7.88343131
2019-06-20 17:40:17,071 - root - INFO - Pretraining time: 6.255
2019-06-20 17:40:17,071 - root - INFO - Finished pretraining.
2019-06-20 17:40:17,072 - root - INFO - Testing autoencoder...
2019-06-20 17:40:18,929 - root - INFO - Test set Loss: 9.90700213
2019-06-20 17:40:19,000 - root - INFO - Test set AUC: 76.81%
2019-06-20 17:40:19,000 - root - INFO - Autoencoder testing time: 1.928
2019-06-20 17:40:19,000 - root - INFO - Finished testing autoencoder.
2019-06-20 17:40:19,004 - root - INFO - Training optimizer: adam
2019-06-20 17:40:19,004 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:40:19,004 - root - INFO - Training epochs: 2
2019-06-20 17:40:19,004 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:40:19,004 - root - INFO - Training batch size: 200
2019-06-20 17:40:19,004 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:40:19,004 - root - INFO - Initializing center c...
2019-06-20 17:40:20,476 - root - INFO - Center c initialized.
2019-06-20 17:40:20,476 - root - INFO - Starting training...
2019-06-20 17:40:22,536 - root - INFO -   Epoch 1/2	 Time: 2.060	 Loss: 0.81412385
2019-06-20 17:40:24,614 - root - INFO -   Epoch 2/2	 Time: 2.077	 Loss: 0.14985813
2019-06-20 17:40:24,614 - root - INFO - Training time: 4.138
2019-06-20 17:40:24,614 - root - INFO - Finished training.
2019-06-20 17:40:24,614 - root - INFO - Starting testing...
2019-06-20 17:40:26,107 - root - INFO - Testing time: 1.492
2019-06-20 17:40:26,178 - root - INFO - Test set AUC: 93.69%
2019-06-20 17:40:26,178 - root - INFO - Finished testing.
2019-06-20 17:42:25,667 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:42:25,667 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:42:25,667 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:42:25,667 - root - INFO - Dataset: hits
2019-06-20 17:42:25,667 - root - INFO - Normal class: 1
2019-06-20 17:42:25,667 - root - INFO - Network: hits_LeNet
2019-06-20 17:42:25,667 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:42:25,667 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:42:25,705 - root - INFO - Computation device: cuda
2019-06-20 17:42:25,705 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:42:35,587 - root - INFO - Pretraining: True
2019-06-20 17:42:35,587 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:42:35,587 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:42:35,587 - root - INFO - Pretraining epochs: 2
2019-06-20 17:42:35,587 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:42:35,588 - root - INFO - Pretraining batch size: 200
2019-06-20 17:42:35,588 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:42:37,678 - root - INFO - Starting pretraining...
2019-06-20 17:42:40,922 - root - INFO -   Epoch 1/2	 Time: 3.244	 Loss: 9.96876604
2019-06-20 17:42:43,934 - root - INFO -   Epoch 2/2	 Time: 3.012	 Loss: 7.44697237
2019-06-20 17:42:43,934 - root - INFO - Pretraining time: 6.256
2019-06-20 17:42:43,934 - root - INFO - Finished pretraining.
2019-06-20 17:42:43,935 - root - INFO - Testing autoencoder...
2019-06-20 17:42:45,773 - root - INFO - Test set Loss: 9.17358697
2019-06-20 17:42:45,844 - root - INFO - Test set AUC: 74.12%
2019-06-20 17:42:45,844 - root - INFO - Autoencoder testing time: 1.910
2019-06-20 17:42:45,844 - root - INFO - Finished testing autoencoder.
2019-06-20 17:42:45,848 - root - INFO - Training optimizer: adam
2019-06-20 17:42:45,848 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:42:45,848 - root - INFO - Training epochs: 2
2019-06-20 17:42:45,848 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:42:45,848 - root - INFO - Training batch size: 200
2019-06-20 17:42:45,848 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:42:45,849 - root - INFO - Initializing center c...
2019-06-20 17:42:47,290 - root - INFO - Center c initialized.
2019-06-20 17:42:47,290 - root - INFO - Starting training...
2019-06-20 17:42:49,352 - root - INFO -   Epoch 1/2	 Time: 2.061	 Loss: 0.56879167
2019-06-20 17:42:51,408 - root - INFO -   Epoch 2/2	 Time: 2.056	 Loss: 0.12290905
2019-06-20 17:42:51,408 - root - INFO - Training time: 4.118
2019-06-20 17:42:51,408 - root - INFO - Finished training.
2019-06-20 17:42:51,409 - root - INFO - Starting testing...
2019-06-20 17:42:52,896 - root - INFO - Testing time: 1.487
2019-06-20 17:42:52,966 - root - INFO - Test set AUC: 92.38%
2019-06-20 17:42:52,966 - root - INFO - Finished testing.
2019-06-20 17:43:51,483 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:43:51,484 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:43:51,484 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:43:51,484 - root - INFO - Dataset: hits
2019-06-20 17:43:51,484 - root - INFO - Normal class: 1
2019-06-20 17:43:51,484 - root - INFO - Network: hits_LeNet
2019-06-20 17:43:51,484 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:43:51,484 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:43:51,519 - root - INFO - Computation device: cuda
2019-06-20 17:43:51,519 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:44:01,451 - root - INFO - Pretraining: True
2019-06-20 17:44:01,451 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:44:01,451 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:44:01,451 - root - INFO - Pretraining epochs: 2
2019-06-20 17:44:01,451 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:44:01,451 - root - INFO - Pretraining batch size: 200
2019-06-20 17:44:01,451 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:44:03,551 - root - INFO - Starting pretraining...
2019-06-20 17:44:06,799 - root - INFO -   Epoch 1/2	 Time: 3.248	 Loss: 10.77849464
2019-06-20 17:44:09,825 - root - INFO -   Epoch 2/2	 Time: 3.026	 Loss: 7.63928155
2019-06-20 17:44:09,825 - root - INFO - Pretraining time: 6.275
2019-06-20 17:44:09,825 - root - INFO - Finished pretraining.
2019-06-20 17:44:09,826 - root - INFO - Testing autoencoder...
2019-06-20 17:44:11,634 - root - INFO - Test set Loss: 9.31854469
2019-06-20 17:44:11,705 - root - INFO - Test set AUC: 75.12%
2019-06-20 17:44:11,705 - root - INFO - Autoencoder testing time: 1.879
2019-06-20 17:44:11,705 - root - INFO - Finished testing autoencoder.
2019-06-20 17:44:11,709 - root - INFO - Training optimizer: adam
2019-06-20 17:44:11,709 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:44:11,709 - root - INFO - Training epochs: 2
2019-06-20 17:44:11,709 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:44:11,709 - root - INFO - Training batch size: 200
2019-06-20 17:44:11,709 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:44:11,710 - root - INFO - Initializing center c...
2019-06-20 17:44:13,133 - root - INFO - Center c initialized.
2019-06-20 17:44:13,133 - root - INFO - Starting training...
2019-06-20 17:44:15,279 - root - INFO -   Epoch 1/2	 Time: 2.146	 Loss: 0.62023142
2019-06-20 17:44:17,340 - root - INFO -   Epoch 2/2	 Time: 2.061	 Loss: 0.14132732
2019-06-20 17:44:17,340 - root - INFO - Training time: 4.207
2019-06-20 17:44:17,340 - root - INFO - Finished training.
2019-06-20 17:44:17,341 - root - INFO - Starting testing...
2019-06-20 17:44:18,807 - root - INFO - Testing time: 1.466
2019-06-20 17:44:18,877 - root - INFO - Test set AUC: 91.98%
2019-06-20 17:44:18,877 - root - INFO - Finished testing.
2019-06-20 17:44:54,669 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:44:54,669 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:44:54,669 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:44:54,669 - root - INFO - Dataset: hits
2019-06-20 17:44:54,669 - root - INFO - Normal class: 1
2019-06-20 17:44:54,669 - root - INFO - Network: hits_LeNet
2019-06-20 17:44:54,669 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:44:54,669 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:44:54,704 - root - INFO - Computation device: cuda
2019-06-20 17:44:54,705 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:45:04,557 - root - INFO - Pretraining: True
2019-06-20 17:45:04,557 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:45:04,557 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:45:04,557 - root - INFO - Pretraining epochs: 2
2019-06-20 17:45:04,557 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:45:04,557 - root - INFO - Pretraining batch size: 200
2019-06-20 17:45:04,558 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:45:06,635 - root - INFO - Starting pretraining...
2019-06-20 17:45:09,880 - root - INFO -   Epoch 1/2	 Time: 3.245	 Loss: 9.78301325
2019-06-20 17:45:12,897 - root - INFO -   Epoch 2/2	 Time: 3.017	 Loss: 7.38386713
2019-06-20 17:45:12,897 - root - INFO - Pretraining time: 6.262
2019-06-20 17:45:12,897 - root - INFO - Finished pretraining.
2019-06-20 17:45:12,898 - root - INFO - Testing autoencoder...
2019-06-20 17:45:14,741 - root - INFO - Test set Loss: 9.15403120
2019-06-20 17:45:14,812 - root - INFO - Test set AUC: 73.55%
2019-06-20 17:45:14,812 - root - INFO - Autoencoder testing time: 1.914
2019-06-20 17:45:14,812 - root - INFO - Finished testing autoencoder.
2019-06-20 17:45:14,816 - root - INFO - Training optimizer: adam
2019-06-20 17:45:14,816 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:45:14,816 - root - INFO - Training epochs: 2
2019-06-20 17:45:14,816 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:45:14,816 - root - INFO - Training batch size: 200
2019-06-20 17:45:14,816 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:45:14,817 - root - INFO - Initializing center c...
2019-06-20 17:45:16,273 - root - INFO - Center c initialized.
2019-06-20 17:45:16,273 - root - INFO - Starting training...
2019-06-20 17:45:18,333 - root - INFO -   Epoch 1/2	 Time: 2.060	 Loss: 0.55296865
2019-06-20 17:45:20,398 - root - INFO -   Epoch 2/2	 Time: 2.065	 Loss: 0.12050932
2019-06-20 17:45:20,398 - root - INFO - Training time: 4.126
2019-06-20 17:45:20,398 - root - INFO - Finished training.
2019-06-20 17:45:20,399 - root - INFO - Starting testing...
2019-06-20 17:45:21,888 - root - INFO - Testing time: 1.489
2019-06-20 17:45:21,959 - root - INFO - Test set AUC: 89.55%
2019-06-20 17:45:21,959 - root - INFO - Finished testing.
2019-06-20 17:47:44,336 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-20 17:47:44,336 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-20 17:47:44,336 - root - INFO - Export path is ../log/hits_test.
2019-06-20 17:47:44,336 - root - INFO - Dataset: hits
2019-06-20 17:47:44,336 - root - INFO - Normal class: 1
2019-06-20 17:47:44,336 - root - INFO - Network: hits_LeNet
2019-06-20 17:47:44,336 - root - INFO - Deep SVDD objective: one-class
2019-06-20 17:47:44,336 - root - INFO - Nu-paramerter: 0.10
2019-06-20 17:47:44,371 - root - INFO - Computation device: cuda
2019-06-20 17:47:44,372 - root - INFO - Number of dataloader workers: 16
2019-06-20 17:47:54,296 - root - INFO - Pretraining: True
2019-06-20 17:47:54,296 - root - INFO - Pretraining optimizer: adam
2019-06-20 17:47:54,296 - root - INFO - Pretraining learning rate: 0.0001
2019-06-20 17:47:54,296 - root - INFO - Pretraining epochs: 150
2019-06-20 17:47:54,296 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-20 17:47:54,296 - root - INFO - Pretraining batch size: 200
2019-06-20 17:47:54,296 - root - INFO - Pretraining weight decay: 0.0005
2019-06-20 17:47:56,384 - root - INFO - Starting pretraining...
2019-06-20 17:47:59,602 - root - INFO -   Epoch 1/150	 Time: 3.218	 Loss: 10.96036076
2019-06-20 17:48:02,596 - root - INFO -   Epoch 2/150	 Time: 2.994	 Loss: 7.57195216
2019-06-20 17:48:05,604 - root - INFO -   Epoch 3/150	 Time: 3.007	 Loss: 7.22401037
2019-06-20 17:48:08,590 - root - INFO -   Epoch 4/150	 Time: 2.986	 Loss: 7.05673695
2019-06-20 17:48:11,596 - root - INFO -   Epoch 5/150	 Time: 3.006	 Loss: 6.95665355
2019-06-20 17:48:14,573 - root - INFO -   Epoch 6/150	 Time: 2.976	 Loss: 6.88093352
2019-06-20 17:48:17,583 - root - INFO -   Epoch 7/150	 Time: 3.010	 Loss: 6.82540081
2019-06-20 17:48:20,541 - root - INFO -   Epoch 8/150	 Time: 2.958	 Loss: 6.77073026
2019-06-20 17:48:23,548 - root - INFO -   Epoch 9/150	 Time: 3.006	 Loss: 6.72421800
2019-06-20 17:48:26,515 - root - INFO -   Epoch 10/150	 Time: 2.967	 Loss: 6.68699269
2019-06-20 17:48:29,503 - root - INFO -   Epoch 11/150	 Time: 2.988	 Loss: 6.64374182
2019-06-20 17:48:32,474 - root - INFO -   Epoch 12/150	 Time: 2.971	 Loss: 6.61168104
2019-06-20 17:48:35,466 - root - INFO -   Epoch 13/150	 Time: 2.991	 Loss: 6.58263281
2019-06-20 17:48:38,449 - root - INFO -   Epoch 14/150	 Time: 2.983	 Loss: 6.56075949
2019-06-20 17:48:41,440 - root - INFO -   Epoch 15/150	 Time: 2.991	 Loss: 6.53560044
2019-06-20 17:48:44,518 - root - INFO -   Epoch 16/150	 Time: 3.077	 Loss: 6.52014546
2019-06-20 17:48:47,517 - root - INFO -   Epoch 17/150	 Time: 2.999	 Loss: 6.50182996
2019-06-20 17:48:50,525 - root - INFO -   Epoch 18/150	 Time: 3.008	 Loss: 6.48389193
2019-06-20 17:48:53,529 - root - INFO -   Epoch 19/150	 Time: 3.004	 Loss: 6.47167795
2019-06-20 17:48:56,493 - root - INFO -   Epoch 20/150	 Time: 2.964	 Loss: 6.46368330
2019-06-20 17:48:59,458 - root - INFO -   Epoch 21/150	 Time: 2.965	 Loss: 6.44533823
2019-06-20 17:49:02,435 - root - INFO -   Epoch 22/150	 Time: 2.977	 Loss: 6.43411785
2019-06-20 17:49:05,474 - root - INFO -   Epoch 23/150	 Time: 3.038	 Loss: 6.42180299
2019-06-20 17:49:08,483 - root - INFO -   Epoch 24/150	 Time: 3.009	 Loss: 6.41001554
2019-06-20 17:49:11,464 - root - INFO -   Epoch 25/150	 Time: 2.981	 Loss: 6.40343632
2019-06-20 17:49:14,425 - root - INFO -   Epoch 26/150	 Time: 2.961	 Loss: 6.39495918
2019-06-20 17:49:17,410 - root - INFO -   Epoch 27/150	 Time: 2.985	 Loss: 6.38143938
2019-06-20 17:49:20,429 - root - INFO -   Epoch 28/150	 Time: 3.019	 Loss: 6.37343210
2019-06-20 17:49:23,405 - root - INFO -   Epoch 29/150	 Time: 2.975	 Loss: 6.36879019
2019-06-20 17:49:26,397 - root - INFO -   Epoch 30/150	 Time: 2.992	 Loss: 6.36047093
2019-06-20 17:49:29,388 - root - INFO -   Epoch 31/150	 Time: 2.991	 Loss: 6.35366426
2019-06-20 17:49:32,405 - root - INFO -   Epoch 32/150	 Time: 3.016	 Loss: 6.34668343
2019-06-20 17:49:35,401 - root - INFO -   Epoch 33/150	 Time: 2.996	 Loss: 6.34223263
2019-06-20 17:49:38,377 - root - INFO -   Epoch 34/150	 Time: 2.976	 Loss: 6.33498974
2019-06-20 17:49:41,378 - root - INFO -   Epoch 35/150	 Time: 3.001	 Loss: 6.33044595
2019-06-20 17:49:44,354 - root - INFO -   Epoch 36/150	 Time: 2.975	 Loss: 6.32661851
2019-06-20 17:49:47,376 - root - INFO -   Epoch 37/150	 Time: 3.022	 Loss: 6.32264344
2019-06-20 17:49:50,366 - root - INFO -   Epoch 38/150	 Time: 2.990	 Loss: 6.31665776
2019-06-20 17:49:53,385 - root - INFO -   Epoch 39/150	 Time: 3.018	 Loss: 6.31464158
2019-06-20 17:49:56,390 - root - INFO -   Epoch 40/150	 Time: 3.005	 Loss: 6.30649902
2019-06-20 17:49:59,404 - root - INFO -   Epoch 41/150	 Time: 3.014	 Loss: 6.30345398
2019-06-20 17:50:02,404 - root - INFO -   Epoch 42/150	 Time: 3.000	 Loss: 6.29688850
2019-06-20 17:50:05,480 - root - INFO -   Epoch 43/150	 Time: 3.075	 Loss: 6.29288064
2019-06-20 17:50:08,507 - root - INFO -   Epoch 44/150	 Time: 3.027	 Loss: 6.28843697
2019-06-20 17:50:11,522 - root - INFO -   Epoch 45/150	 Time: 3.015	 Loss: 6.28605066
2019-06-20 17:50:14,638 - root - INFO -   Epoch 46/150	 Time: 3.116	 Loss: 6.28524171
2019-06-20 17:50:17,751 - root - INFO -   Epoch 47/150	 Time: 3.112	 Loss: 6.28036864
2019-06-20 17:50:20,776 - root - INFO -   Epoch 48/150	 Time: 3.026	 Loss: 6.27663287
2019-06-20 17:50:23,859 - root - INFO -   Epoch 49/150	 Time: 3.082	 Loss: 6.27210133
2019-06-20 17:50:26,887 - root - INFO -   Epoch 50/150	 Time: 3.028	 Loss: 6.26715455
2019-06-20 17:50:26,888 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:50:29,924 - root - INFO -   Epoch 51/150	 Time: 3.036	 Loss: 6.26479727
2019-06-20 17:50:32,979 - root - INFO -   Epoch 52/150	 Time: 3.055	 Loss: 6.26518513
2019-06-20 17:50:36,028 - root - INFO -   Epoch 53/150	 Time: 3.049	 Loss: 6.26423376
2019-06-20 17:50:39,063 - root - INFO -   Epoch 54/150	 Time: 3.035	 Loss: 6.26485502
2019-06-20 17:50:42,113 - root - INFO -   Epoch 55/150	 Time: 3.050	 Loss: 6.26507266
2019-06-20 17:50:45,199 - root - INFO -   Epoch 56/150	 Time: 3.086	 Loss: 6.26599734
2019-06-20 17:50:48,247 - root - INFO -   Epoch 57/150	 Time: 3.047	 Loss: 6.26495138
2019-06-20 17:50:51,335 - root - INFO -   Epoch 58/150	 Time: 3.088	 Loss: 6.26301161
2019-06-20 17:50:54,382 - root - INFO -   Epoch 59/150	 Time: 3.047	 Loss: 6.26309533
2019-06-20 17:50:57,397 - root - INFO -   Epoch 60/150	 Time: 3.014	 Loss: 6.26460581
2019-06-20 17:51:00,445 - root - INFO -   Epoch 61/150	 Time: 3.048	 Loss: 6.26098878
2019-06-20 17:51:03,496 - root - INFO -   Epoch 62/150	 Time: 3.051	 Loss: 6.26435303
2019-06-20 17:51:06,562 - root - INFO -   Epoch 63/150	 Time: 3.066	 Loss: 6.26441282
2019-06-20 17:51:09,623 - root - INFO -   Epoch 64/150	 Time: 3.061	 Loss: 6.26118788
2019-06-20 17:51:12,730 - root - INFO -   Epoch 65/150	 Time: 3.106	 Loss: 6.26170778
2019-06-20 17:51:15,774 - root - INFO -   Epoch 66/150	 Time: 3.044	 Loss: 6.26056741
2019-06-20 17:51:18,812 - root - INFO -   Epoch 67/150	 Time: 3.038	 Loss: 6.26186917
2019-06-20 17:51:21,857 - root - INFO -   Epoch 68/150	 Time: 3.045	 Loss: 6.25944569
2019-06-20 17:51:24,888 - root - INFO -   Epoch 69/150	 Time: 3.030	 Loss: 6.26156627
2019-06-20 17:51:27,902 - root - INFO -   Epoch 70/150	 Time: 3.014	 Loss: 6.26004454
2019-06-20 17:51:30,930 - root - INFO -   Epoch 71/150	 Time: 3.028	 Loss: 6.26035032
2019-06-20 17:51:33,948 - root - INFO -   Epoch 72/150	 Time: 3.017	 Loss: 6.25774589
2019-06-20 17:51:37,002 - root - INFO -   Epoch 73/150	 Time: 3.053	 Loss: 6.25631467
2019-06-20 17:51:40,045 - root - INFO -   Epoch 74/150	 Time: 3.043	 Loss: 6.25695519
2019-06-20 17:51:43,126 - root - INFO -   Epoch 75/150	 Time: 3.082	 Loss: 6.25972166
2019-06-20 17:51:46,137 - root - INFO -   Epoch 76/150	 Time: 3.010	 Loss: 6.25630420
2019-06-20 17:51:49,219 - root - INFO -   Epoch 77/150	 Time: 3.082	 Loss: 6.25675753
2019-06-20 17:51:52,276 - root - INFO -   Epoch 78/150	 Time: 3.057	 Loss: 6.25400395
2019-06-20 17:51:55,300 - root - INFO -   Epoch 79/150	 Time: 3.024	 Loss: 6.25427469
2019-06-20 17:51:58,300 - root - INFO -   Epoch 80/150	 Time: 3.000	 Loss: 6.25506653
2019-06-20 17:52:01,304 - root - INFO -   Epoch 81/150	 Time: 3.004	 Loss: 6.25337676
2019-06-20 17:52:04,287 - root - INFO -   Epoch 82/150	 Time: 2.983	 Loss: 6.25449513
2019-06-20 17:52:07,279 - root - INFO -   Epoch 83/150	 Time: 2.991	 Loss: 6.25346565
2019-06-20 17:52:10,316 - root - INFO -   Epoch 84/150	 Time: 3.037	 Loss: 6.25270229
2019-06-20 17:52:13,317 - root - INFO -   Epoch 85/150	 Time: 3.001	 Loss: 6.25109933
2019-06-20 17:52:16,311 - root - INFO -   Epoch 86/150	 Time: 2.993	 Loss: 6.25173321
2019-06-20 17:52:19,313 - root - INFO -   Epoch 87/150	 Time: 3.002	 Loss: 6.25183058
2019-06-20 17:52:22,313 - root - INFO -   Epoch 88/150	 Time: 2.999	 Loss: 6.25232123
2019-06-20 17:52:25,322 - root - INFO -   Epoch 89/150	 Time: 3.009	 Loss: 6.25259536
2019-06-20 17:52:28,322 - root - INFO -   Epoch 90/150	 Time: 3.000	 Loss: 6.25206949
2019-06-20 17:52:31,346 - root - INFO -   Epoch 91/150	 Time: 3.023	 Loss: 6.25073677
2019-06-20 17:52:34,366 - root - INFO -   Epoch 92/150	 Time: 3.020	 Loss: 6.25026184
2019-06-20 17:52:37,350 - root - INFO -   Epoch 93/150	 Time: 2.984	 Loss: 6.24940509
2019-06-20 17:52:40,370 - root - INFO -   Epoch 94/150	 Time: 3.019	 Loss: 6.24769692
2019-06-20 17:52:43,362 - root - INFO -   Epoch 95/150	 Time: 2.992	 Loss: 6.24830864
2019-06-20 17:52:46,365 - root - INFO -   Epoch 96/150	 Time: 3.002	 Loss: 6.24650805
2019-06-20 17:52:49,350 - root - INFO -   Epoch 97/150	 Time: 2.985	 Loss: 6.24940529
2019-06-20 17:52:52,354 - root - INFO -   Epoch 98/150	 Time: 3.004	 Loss: 6.24727135
2019-06-20 17:52:55,345 - root - INFO -   Epoch 99/150	 Time: 2.991	 Loss: 6.24573993
2019-06-20 17:52:58,353 - root - INFO -   Epoch 100/150	 Time: 3.008	 Loss: 6.24642082
2019-06-20 17:53:01,361 - root - INFO -   Epoch 101/150	 Time: 3.008	 Loss: 6.24528965
2019-06-20 17:53:04,359 - root - INFO -   Epoch 102/150	 Time: 2.997	 Loss: 6.24666766
2019-06-20 17:53:07,395 - root - INFO -   Epoch 103/150	 Time: 3.036	 Loss: 6.24836951
2019-06-20 17:53:10,368 - root - INFO -   Epoch 104/150	 Time: 2.973	 Loss: 6.24368960
2019-06-20 17:53:13,343 - root - INFO -   Epoch 105/150	 Time: 2.975	 Loss: 6.24467032
2019-06-20 17:53:16,356 - root - INFO -   Epoch 106/150	 Time: 3.013	 Loss: 6.24218954
2019-06-20 17:53:19,333 - root - INFO -   Epoch 107/150	 Time: 2.976	 Loss: 6.24643382
2019-06-20 17:53:22,385 - root - INFO -   Epoch 108/150	 Time: 3.052	 Loss: 6.24276111
2019-06-20 17:53:25,381 - root - INFO -   Epoch 109/150	 Time: 2.996	 Loss: 6.24106553
2019-06-20 17:53:28,362 - root - INFO -   Epoch 110/150	 Time: 2.981	 Loss: 6.24345646
2019-06-20 17:53:31,384 - root - INFO -   Epoch 111/150	 Time: 3.021	 Loss: 6.24080523
2019-06-20 17:53:34,411 - root - INFO -   Epoch 112/150	 Time: 3.026	 Loss: 6.24380897
2019-06-20 17:53:37,398 - root - INFO -   Epoch 113/150	 Time: 2.987	 Loss: 6.24494787
2019-06-20 17:53:40,421 - root - INFO -   Epoch 114/150	 Time: 3.023	 Loss: 6.23981172
2019-06-20 17:53:43,429 - root - INFO -   Epoch 115/150	 Time: 3.007	 Loss: 6.23881325
2019-06-20 17:53:46,430 - root - INFO -   Epoch 116/150	 Time: 3.001	 Loss: 6.24096669
2019-06-20 17:53:49,427 - root - INFO -   Epoch 117/150	 Time: 2.997	 Loss: 6.23773433
2019-06-20 17:53:52,438 - root - INFO -   Epoch 118/150	 Time: 3.011	 Loss: 6.23925651
2019-06-20 17:53:55,475 - root - INFO -   Epoch 119/150	 Time: 3.037	 Loss: 6.23928804
2019-06-20 17:53:58,480 - root - INFO -   Epoch 120/150	 Time: 3.005	 Loss: 6.23884540
2019-06-20 17:54:01,504 - root - INFO -   Epoch 121/150	 Time: 3.024	 Loss: 6.24141474
2019-06-20 17:54:04,511 - root - INFO -   Epoch 122/150	 Time: 3.007	 Loss: 6.23820496
2019-06-20 17:54:07,503 - root - INFO -   Epoch 123/150	 Time: 2.992	 Loss: 6.23752825
2019-06-20 17:54:10,512 - root - INFO -   Epoch 124/150	 Time: 3.009	 Loss: 6.23655763
2019-06-20 17:54:13,522 - root - INFO -   Epoch 125/150	 Time: 3.009	 Loss: 6.23821381
2019-06-20 17:54:16,533 - root - INFO -   Epoch 126/150	 Time: 3.011	 Loss: 6.23691339
2019-06-20 17:54:19,531 - root - INFO -   Epoch 127/150	 Time: 2.998	 Loss: 6.23643666
2019-06-20 17:54:22,549 - root - INFO -   Epoch 128/150	 Time: 3.018	 Loss: 6.23478127
2019-06-20 17:54:25,565 - root - INFO -   Epoch 129/150	 Time: 3.015	 Loss: 6.23557813
2019-06-20 17:54:28,574 - root - INFO -   Epoch 130/150	 Time: 3.009	 Loss: 6.23592750
2019-06-20 17:54:31,608 - root - INFO -   Epoch 131/150	 Time: 3.033	 Loss: 6.23584092
2019-06-20 17:54:34,630 - root - INFO -   Epoch 132/150	 Time: 3.022	 Loss: 6.23549195
2019-06-20 17:54:37,654 - root - INFO -   Epoch 133/150	 Time: 3.024	 Loss: 6.23441371
2019-06-20 17:54:40,666 - root - INFO -   Epoch 134/150	 Time: 3.011	 Loss: 6.23377683
2019-06-20 17:54:43,678 - root - INFO -   Epoch 135/150	 Time: 3.012	 Loss: 6.23282170
2019-06-20 17:54:46,679 - root - INFO -   Epoch 136/150	 Time: 3.000	 Loss: 6.23497851
2019-06-20 17:54:49,693 - root - INFO -   Epoch 137/150	 Time: 3.014	 Loss: 6.23292577
2019-06-20 17:54:52,704 - root - INFO -   Epoch 138/150	 Time: 3.011	 Loss: 6.23134460
2019-06-20 17:54:55,716 - root - INFO -   Epoch 139/150	 Time: 3.011	 Loss: 6.23372023
2019-06-20 17:54:58,716 - root - INFO -   Epoch 140/150	 Time: 3.000	 Loss: 6.23313330
2019-06-20 17:55:01,717 - root - INFO -   Epoch 141/150	 Time: 3.001	 Loss: 6.23129545
2019-06-20 17:55:04,728 - root - INFO -   Epoch 142/150	 Time: 3.011	 Loss: 6.23137745
2019-06-20 17:55:07,747 - root - INFO -   Epoch 143/150	 Time: 3.018	 Loss: 6.23036829
2019-06-20 17:55:10,729 - root - INFO -   Epoch 144/150	 Time: 2.982	 Loss: 6.23280677
2019-06-20 17:55:13,727 - root - INFO -   Epoch 145/150	 Time: 2.998	 Loss: 6.22910980
2019-06-20 17:55:16,721 - root - INFO -   Epoch 146/150	 Time: 2.994	 Loss: 6.23014503
2019-06-20 17:55:19,736 - root - INFO -   Epoch 147/150	 Time: 3.015	 Loss: 6.23281071
2019-06-20 17:55:22,764 - root - INFO -   Epoch 148/150	 Time: 3.027	 Loss: 6.22919517
2019-06-20 17:55:25,765 - root - INFO -   Epoch 149/150	 Time: 3.001	 Loss: 6.22950084
2019-06-20 17:55:28,771 - root - INFO -   Epoch 150/150	 Time: 3.006	 Loss: 6.22966143
2019-06-20 17:55:28,771 - root - INFO - Pretraining time: 452.387
2019-06-20 17:55:28,771 - root - INFO - Finished pretraining.
2019-06-20 17:55:28,772 - root - INFO - Testing autoencoder...
2019-06-20 17:55:30,583 - root - INFO - Test set Loss: 6.82389880
2019-06-20 17:55:30,658 - root - INFO - Test set AUC: 59.45%
2019-06-20 17:55:30,658 - root - INFO - Autoencoder testing time: 1.886
2019-06-20 17:55:30,658 - root - INFO - Finished testing autoencoder.
2019-06-20 17:55:30,662 - root - INFO - Training optimizer: adam
2019-06-20 17:55:30,662 - root - INFO - Training learning rate: 0.0001
2019-06-20 17:55:30,662 - root - INFO - Training epochs: 150
2019-06-20 17:55:30,662 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-20 17:55:30,662 - root - INFO - Training batch size: 200
2019-06-20 17:55:30,662 - root - INFO - Training weight decay: 5e-07
2019-06-20 17:55:30,663 - root - INFO - Initializing center c...
2019-06-20 17:55:32,114 - root - INFO - Center c initialized.
2019-06-20 17:55:32,114 - root - INFO - Starting training...
2019-06-20 17:55:34,260 - root - INFO -   Epoch 1/150	 Time: 2.146	 Loss: 0.56860383
2019-06-20 17:55:36,340 - root - INFO -   Epoch 2/150	 Time: 2.080	 Loss: 0.10188770
2019-06-20 17:55:38,404 - root - INFO -   Epoch 3/150	 Time: 2.064	 Loss: 0.05618494
2019-06-20 17:55:40,456 - root - INFO -   Epoch 4/150	 Time: 2.052	 Loss: 0.03859255
2019-06-20 17:55:42,498 - root - INFO -   Epoch 5/150	 Time: 2.042	 Loss: 0.02800876
2019-06-20 17:55:44,576 - root - INFO -   Epoch 6/150	 Time: 2.077	 Loss: 0.02090943
2019-06-20 17:55:46,674 - root - INFO -   Epoch 7/150	 Time: 2.098	 Loss: 0.01614070
2019-06-20 17:55:48,753 - root - INFO -   Epoch 8/150	 Time: 2.079	 Loss: 0.01253932
2019-06-20 17:55:50,829 - root - INFO -   Epoch 9/150	 Time: 2.076	 Loss: 0.00983775
2019-06-20 17:55:52,906 - root - INFO -   Epoch 10/150	 Time: 2.077	 Loss: 0.00774067
2019-06-20 17:55:54,952 - root - INFO -   Epoch 11/150	 Time: 2.045	 Loss: 0.00613702
2019-06-20 17:55:57,042 - root - INFO -   Epoch 12/150	 Time: 2.090	 Loss: 0.00492503
2019-06-20 17:55:59,071 - root - INFO -   Epoch 13/150	 Time: 2.029	 Loss: 0.00400851
2019-06-20 17:56:01,157 - root - INFO -   Epoch 14/150	 Time: 2.085	 Loss: 0.00327998
2019-06-20 17:56:03,267 - root - INFO -   Epoch 15/150	 Time: 2.110	 Loss: 0.00271381
2019-06-20 17:56:05,437 - root - INFO -   Epoch 16/150	 Time: 2.170	 Loss: 0.00226000
2019-06-20 17:56:07,522 - root - INFO -   Epoch 17/150	 Time: 2.084	 Loss: 0.00193265
2019-06-20 17:56:09,615 - root - INFO -   Epoch 18/150	 Time: 2.093	 Loss: 0.00163068
2019-06-20 17:56:11,706 - root - INFO -   Epoch 19/150	 Time: 2.090	 Loss: 0.00142879
2019-06-20 17:56:13,777 - root - INFO -   Epoch 20/150	 Time: 2.071	 Loss: 0.00123429
2019-06-20 17:56:15,855 - root - INFO -   Epoch 21/150	 Time: 2.078	 Loss: 0.00107016
2019-06-20 17:56:17,929 - root - INFO -   Epoch 22/150	 Time: 2.074	 Loss: 0.00096139
2019-06-20 17:56:19,995 - root - INFO -   Epoch 23/150	 Time: 2.065	 Loss: 0.00084264
2019-06-20 17:56:22,055 - root - INFO -   Epoch 24/150	 Time: 2.060	 Loss: 0.00076620
2019-06-20 17:56:24,132 - root - INFO -   Epoch 25/150	 Time: 2.077	 Loss: 0.00068628
2019-06-20 17:56:26,214 - root - INFO -   Epoch 26/150	 Time: 2.082	 Loss: 0.00060536
2019-06-20 17:56:28,264 - root - INFO -   Epoch 27/150	 Time: 2.050	 Loss: 0.00056684
2019-06-20 17:56:30,361 - root - INFO -   Epoch 28/150	 Time: 2.097	 Loss: 0.00050700
2019-06-20 17:56:32,528 - root - INFO -   Epoch 29/150	 Time: 2.167	 Loss: 0.00046897
2019-06-20 17:56:34,606 - root - INFO -   Epoch 30/150	 Time: 2.077	 Loss: 0.00043419
2019-06-20 17:56:36,714 - root - INFO -   Epoch 31/150	 Time: 2.108	 Loss: 0.00039975
2019-06-20 17:56:38,790 - root - INFO -   Epoch 32/150	 Time: 2.075	 Loss: 0.00036157
2019-06-20 17:56:40,874 - root - INFO -   Epoch 33/150	 Time: 2.083	 Loss: 0.00033226
2019-06-20 17:56:42,943 - root - INFO -   Epoch 34/150	 Time: 2.070	 Loss: 0.00031686
2019-06-20 17:56:44,991 - root - INFO -   Epoch 35/150	 Time: 2.047	 Loss: 0.00028546
2019-06-20 17:56:47,054 - root - INFO -   Epoch 36/150	 Time: 2.062	 Loss: 0.00026457
2019-06-20 17:56:49,120 - root - INFO -   Epoch 37/150	 Time: 2.067	 Loss: 0.00025994
2019-06-20 17:56:51,180 - root - INFO -   Epoch 38/150	 Time: 2.060	 Loss: 0.00025441
2019-06-20 17:56:53,199 - root - INFO -   Epoch 39/150	 Time: 2.018	 Loss: 0.00022174
2019-06-20 17:56:55,278 - root - INFO -   Epoch 40/150	 Time: 2.078	 Loss: 0.00021341
2019-06-20 17:56:57,349 - root - INFO -   Epoch 41/150	 Time: 2.071	 Loss: 0.00019923
2019-06-20 17:56:59,413 - root - INFO -   Epoch 42/150	 Time: 2.065	 Loss: 0.00018992
2019-06-20 17:57:01,467 - root - INFO -   Epoch 43/150	 Time: 2.053	 Loss: 0.00017840
2019-06-20 17:57:03,569 - root - INFO -   Epoch 44/150	 Time: 2.101	 Loss: 0.00016729
2019-06-20 17:57:05,647 - root - INFO -   Epoch 45/150	 Time: 2.078	 Loss: 0.00017528
2019-06-20 17:57:07,691 - root - INFO -   Epoch 46/150	 Time: 2.043	 Loss: 0.00015080
2019-06-20 17:57:09,765 - root - INFO -   Epoch 47/150	 Time: 2.074	 Loss: 0.00014530
2019-06-20 17:57:11,841 - root - INFO -   Epoch 48/150	 Time: 2.076	 Loss: 0.00014877
2019-06-20 17:57:13,907 - root - INFO -   Epoch 49/150	 Time: 2.066	 Loss: 0.00014233
2019-06-20 17:57:15,972 - root - INFO -   Epoch 50/150	 Time: 2.064	 Loss: 0.00010170
2019-06-20 17:57:15,972 - root - INFO -   LR scheduler: new learning rate is 1e-05
2019-06-20 17:57:18,047 - root - INFO -   Epoch 51/150	 Time: 2.075	 Loss: 0.00009788
2019-06-20 17:57:20,118 - root - INFO -   Epoch 52/150	 Time: 2.070	 Loss: 0.00009712
2019-06-20 17:57:22,181 - root - INFO -   Epoch 53/150	 Time: 2.063	 Loss: 0.00009595
2019-06-20 17:57:24,238 - root - INFO -   Epoch 54/150	 Time: 2.057	 Loss: 0.00009529
2019-06-20 17:57:26,313 - root - INFO -   Epoch 55/150	 Time: 2.075	 Loss: 0.00009686
2019-06-20 17:57:28,394 - root - INFO -   Epoch 56/150	 Time: 2.081	 Loss: 0.00009501
2019-06-20 17:57:30,492 - root - INFO -   Epoch 57/150	 Time: 2.097	 Loss: 0.00009459
2019-06-20 17:57:32,570 - root - INFO -   Epoch 58/150	 Time: 2.079	 Loss: 0.00009442
2019-06-20 17:57:34,621 - root - INFO -   Epoch 59/150	 Time: 2.051	 Loss: 0.00009234
2019-06-20 17:57:36,700 - root - INFO -   Epoch 60/150	 Time: 2.078	 Loss: 0.00009273
2019-06-20 17:57:38,789 - root - INFO -   Epoch 61/150	 Time: 2.088	 Loss: 0.00009175
2019-06-20 17:57:40,840 - root - INFO -   Epoch 62/150	 Time: 2.051	 Loss: 0.00009175
2019-06-20 17:57:42,934 - root - INFO -   Epoch 63/150	 Time: 2.094	 Loss: 0.00008905
2019-06-20 17:57:45,008 - root - INFO -   Epoch 64/150	 Time: 2.073	 Loss: 0.00008856
2019-06-20 17:57:47,092 - root - INFO -   Epoch 65/150	 Time: 2.084	 Loss: 0.00009068
2019-06-20 17:57:49,175 - root - INFO -   Epoch 66/150	 Time: 2.083	 Loss: 0.00008870
2019-06-20 17:57:51,193 - root - INFO -   Epoch 67/150	 Time: 2.017	 Loss: 0.00008748
2019-06-20 17:57:53,243 - root - INFO -   Epoch 68/150	 Time: 2.050	 Loss: 0.00008805
2019-06-20 17:57:55,305 - root - INFO -   Epoch 69/150	 Time: 2.062	 Loss: 0.00008672
2019-06-20 17:57:57,336 - root - INFO -   Epoch 70/150	 Time: 2.031	 Loss: 0.00008328
2019-06-20 17:57:59,401 - root - INFO -   Epoch 71/150	 Time: 2.064	 Loss: 0.00008469
2019-06-20 17:58:01,490 - root - INFO -   Epoch 72/150	 Time: 2.089	 Loss: 0.00008590
2019-06-20 17:58:03,564 - root - INFO -   Epoch 73/150	 Time: 2.074	 Loss: 0.00008345
2019-06-20 17:58:05,621 - root - INFO -   Epoch 74/150	 Time: 2.057	 Loss: 0.00008402
2019-06-20 17:58:07,697 - root - INFO -   Epoch 75/150	 Time: 2.075	 Loss: 0.00008329
2019-06-20 17:58:09,810 - root - INFO -   Epoch 76/150	 Time: 2.113	 Loss: 0.00008334
2019-06-20 17:58:11,892 - root - INFO -   Epoch 77/150	 Time: 2.082	 Loss: 0.00008184
2019-06-20 17:58:13,967 - root - INFO -   Epoch 78/150	 Time: 2.075	 Loss: 0.00008421
2019-06-20 17:58:16,016 - root - INFO -   Epoch 79/150	 Time: 2.049	 Loss: 0.00007936
2019-06-20 17:58:18,074 - root - INFO -   Epoch 80/150	 Time: 2.057	 Loss: 0.00008014
2019-06-20 17:58:20,136 - root - INFO -   Epoch 81/150	 Time: 2.061	 Loss: 0.00007945
2019-06-20 17:58:22,187 - root - INFO -   Epoch 82/150	 Time: 2.051	 Loss: 0.00007759
2019-06-20 17:58:24,280 - root - INFO -   Epoch 83/150	 Time: 2.093	 Loss: 0.00007869
2019-06-20 17:58:26,371 - root - INFO -   Epoch 84/150	 Time: 2.091	 Loss: 0.00007740
2019-06-20 17:58:28,413 - root - INFO -   Epoch 85/150	 Time: 2.041	 Loss: 0.00007732
2019-06-20 17:58:30,481 - root - INFO -   Epoch 86/150	 Time: 2.068	 Loss: 0.00007690
2019-06-20 17:58:32,535 - root - INFO -   Epoch 87/150	 Time: 2.053	 Loss: 0.00007882
2019-06-20 17:58:34,613 - root - INFO -   Epoch 88/150	 Time: 2.078	 Loss: 0.00007395
2019-06-20 17:58:36,712 - root - INFO -   Epoch 89/150	 Time: 2.100	 Loss: 0.00007533
2019-06-20 17:58:38,799 - root - INFO -   Epoch 90/150	 Time: 2.086	 Loss: 0.00007471
2019-06-20 17:58:40,861 - root - INFO -   Epoch 91/150	 Time: 2.062	 Loss: 0.00007464
2019-06-20 17:58:42,943 - root - INFO -   Epoch 92/150	 Time: 2.082	 Loss: 0.00007358
2019-06-20 17:58:45,014 - root - INFO -   Epoch 93/150	 Time: 2.070	 Loss: 0.00007330
2019-06-20 17:58:47,091 - root - INFO -   Epoch 94/150	 Time: 2.077	 Loss: 0.00007311
2019-06-20 17:58:49,171 - root - INFO -   Epoch 95/150	 Time: 2.079	 Loss: 0.00007271
2019-06-20 17:58:51,227 - root - INFO -   Epoch 96/150	 Time: 2.056	 Loss: 0.00007139
2019-06-20 17:58:53,324 - root - INFO -   Epoch 97/150	 Time: 2.096	 Loss: 0.00007200
2019-06-20 17:58:55,406 - root - INFO -   Epoch 98/150	 Time: 2.082	 Loss: 0.00007118
2019-06-20 17:58:57,463 - root - INFO -   Epoch 99/150	 Time: 2.056	 Loss: 0.00007203
2019-06-20 17:58:59,509 - root - INFO -   Epoch 100/150	 Time: 2.046	 Loss: 0.00007113
2019-06-20 17:59:01,553 - root - INFO -   Epoch 101/150	 Time: 2.044	 Loss: 0.00006889
2019-06-20 17:59:03,619 - root - INFO -   Epoch 102/150	 Time: 2.065	 Loss: 0.00006915
2019-06-20 17:59:05,666 - root - INFO -   Epoch 103/150	 Time: 2.048	 Loss: 0.00006893
2019-06-20 17:59:07,717 - root - INFO -   Epoch 104/150	 Time: 2.050	 Loss: 0.00006832
2019-06-20 17:59:09,765 - root - INFO -   Epoch 105/150	 Time: 2.048	 Loss: 0.00006720
2019-06-20 17:59:11,829 - root - INFO -   Epoch 106/150	 Time: 2.063	 Loss: 0.00006939
2019-06-20 17:59:13,893 - root - INFO -   Epoch 107/150	 Time: 2.064	 Loss: 0.00006685
2019-06-20 17:59:15,959 - root - INFO -   Epoch 108/150	 Time: 2.066	 Loss: 0.00006804
2019-06-20 17:59:18,048 - root - INFO -   Epoch 109/150	 Time: 2.088	 Loss: 0.00006666
2019-06-20 17:59:20,123 - root - INFO -   Epoch 110/150	 Time: 2.075	 Loss: 0.00006688
2019-06-20 17:59:22,186 - root - INFO -   Epoch 111/150	 Time: 2.063	 Loss: 0.00006664
2019-06-20 17:59:24,267 - root - INFO -   Epoch 112/150	 Time: 2.080	 Loss: 0.00006634
2019-06-20 17:59:26,338 - root - INFO -   Epoch 113/150	 Time: 2.071	 Loss: 0.00006387
2019-06-20 17:59:28,381 - root - INFO -   Epoch 114/150	 Time: 2.043	 Loss: 0.00006530
2019-06-20 17:59:30,459 - root - INFO -   Epoch 115/150	 Time: 2.077	 Loss: 0.00006450
2019-06-20 17:59:32,536 - root - INFO -   Epoch 116/150	 Time: 2.077	 Loss: 0.00006572
2019-06-20 17:59:34,609 - root - INFO -   Epoch 117/150	 Time: 2.073	 Loss: 0.00006507
2019-06-20 17:59:36,630 - root - INFO -   Epoch 118/150	 Time: 2.021	 Loss: 0.00006227
2019-06-20 17:59:38,686 - root - INFO -   Epoch 119/150	 Time: 2.055	 Loss: 0.00006229
2019-06-20 17:59:40,733 - root - INFO -   Epoch 120/150	 Time: 2.047	 Loss: 0.00006380
2019-06-20 17:59:42,821 - root - INFO -   Epoch 121/150	 Time: 2.088	 Loss: 0.00006168
2019-06-20 17:59:44,878 - root - INFO -   Epoch 122/150	 Time: 2.056	 Loss: 0.00006188
2019-06-20 17:59:46,964 - root - INFO -   Epoch 123/150	 Time: 2.086	 Loss: 0.00006098
2019-06-20 17:59:49,065 - root - INFO -   Epoch 124/150	 Time: 2.101	 Loss: 0.00006072
2019-06-20 17:59:51,130 - root - INFO -   Epoch 125/150	 Time: 2.065	 Loss: 0.00006263
2019-06-20 17:59:53,214 - root - INFO -   Epoch 126/150	 Time: 2.083	 Loss: 0.00006164
2019-06-20 17:59:55,309 - root - INFO -   Epoch 127/150	 Time: 2.096	 Loss: 0.00006035
2019-06-20 17:59:57,349 - root - INFO -   Epoch 128/150	 Time: 2.040	 Loss: 0.00005949
2019-06-20 17:59:59,436 - root - INFO -   Epoch 129/150	 Time: 2.087	 Loss: 0.00006035
2019-06-20 18:00:01,519 - root - INFO -   Epoch 130/150	 Time: 2.082	 Loss: 0.00005930
2019-06-20 18:00:03,565 - root - INFO -   Epoch 131/150	 Time: 2.046	 Loss: 0.00005956
2019-06-20 18:00:05,651 - root - INFO -   Epoch 132/150	 Time: 2.086	 Loss: 0.00006024
2019-06-20 18:00:07,712 - root - INFO -   Epoch 133/150	 Time: 2.060	 Loss: 0.00005794
2019-06-20 18:00:09,773 - root - INFO -   Epoch 134/150	 Time: 2.061	 Loss: 0.00005838
2019-06-20 18:00:11,867 - root - INFO -   Epoch 135/150	 Time: 2.094	 Loss: 0.00005602
2019-06-20 18:00:13,933 - root - INFO -   Epoch 136/150	 Time: 2.065	 Loss: 0.00005896
2019-06-20 18:00:15,996 - root - INFO -   Epoch 137/150	 Time: 2.063	 Loss: 0.00005717
2019-06-20 18:00:18,061 - root - INFO -   Epoch 138/150	 Time: 2.065	 Loss: 0.00005861
2019-06-20 18:00:20,138 - root - INFO -   Epoch 139/150	 Time: 2.077	 Loss: 0.00005741
2019-06-20 18:00:22,208 - root - INFO -   Epoch 140/150	 Time: 2.069	 Loss: 0.00005685
2019-06-20 18:00:24,268 - root - INFO -   Epoch 141/150	 Time: 2.060	 Loss: 0.00005573
2019-06-20 18:00:26,331 - root - INFO -   Epoch 142/150	 Time: 2.062	 Loss: 0.00005904
2019-06-20 18:00:28,396 - root - INFO -   Epoch 143/150	 Time: 2.065	 Loss: 0.00005665
2019-06-20 18:00:30,439 - root - INFO -   Epoch 144/150	 Time: 2.043	 Loss: 0.00005636
2019-06-20 18:00:32,471 - root - INFO -   Epoch 145/150	 Time: 2.032	 Loss: 0.00005632
2019-06-20 18:00:34,552 - root - INFO -   Epoch 146/150	 Time: 2.081	 Loss: 0.00005397
2019-06-20 18:00:36,601 - root - INFO -   Epoch 147/150	 Time: 2.049	 Loss: 0.00005492
2019-06-20 18:00:38,667 - root - INFO -   Epoch 148/150	 Time: 2.066	 Loss: 0.00005456
2019-06-20 18:00:40,716 - root - INFO -   Epoch 149/150	 Time: 2.048	 Loss: 0.00005363
2019-06-20 18:00:42,779 - root - INFO -   Epoch 150/150	 Time: 2.063	 Loss: 0.00005307
2019-06-20 18:00:42,780 - root - INFO - Training time: 310.666
2019-06-20 18:00:42,780 - root - INFO - Finished training.
2019-06-20 18:00:42,780 - root - INFO - Starting testing...
2019-06-20 18:00:44,167 - root - INFO - Testing time: 1.387
2019-06-20 18:00:44,243 - root - INFO - Test set AUC: 69.61%
2019-06-20 18:00:44,243 - root - INFO - Finished testing.
2019-06-21 11:47:17,947 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 11:47:17,947 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 11:47:17,947 - root - INFO - Export path is ../log/hits_test.
2019-06-21 11:47:17,947 - root - INFO - Dataset: hits
2019-06-21 11:47:17,947 - root - INFO - Normal class: 1
2019-06-21 11:47:17,947 - root - INFO - Network: hits_LeNet
2019-06-21 11:47:17,947 - root - INFO - Deep SVDD objective: one-class
2019-06-21 11:47:17,947 - root - INFO - Nu-paramerter: 0.10
2019-06-21 11:47:17,979 - root - INFO - Computation device: cuda
2019-06-21 11:47:17,979 - root - INFO - Number of dataloader workers: 16
2019-06-21 11:47:27,868 - root - INFO - Pretraining: True
2019-06-21 11:47:27,868 - root - INFO - Pretraining optimizer: adam
2019-06-21 11:47:27,868 - root - INFO - Pretraining learning rate: 0.0001
2019-06-21 11:47:27,868 - root - INFO - Pretraining epochs: 2
2019-06-21 11:47:27,868 - root - INFO - Pretraining learning rate scheduler milestones: [50]
2019-06-21 11:47:27,868 - root - INFO - Pretraining batch size: 200
2019-06-21 11:47:27,868 - root - INFO - Pretraining weight decay: 0.0005
2019-06-21 11:47:29,971 - root - INFO - Starting pretraining...
2019-06-21 11:47:33,343 - root - INFO -   Epoch 1/2	 Time: 3.372	 Loss: 12.15694988
2019-06-21 11:47:36,449 - root - INFO -   Epoch 2/2	 Time: 3.106	 Loss: 7.83186128
2019-06-21 11:47:36,450 - root - INFO - Pretraining time: 6.478
2019-06-21 11:47:36,450 - root - INFO - Finished pretraining.
2019-06-21 11:47:36,450 - root - INFO - Testing autoencoder...
2019-06-21 11:47:38,435 - root - INFO - Test set Loss: 9.29181943
2019-06-21 11:47:38,505 - root - INFO - Test set AUC: 74.46%
2019-06-21 11:47:38,506 - root - INFO - Autoencoder testing time: 2.056
2019-06-21 11:47:38,506 - root - INFO - Finished testing autoencoder.
2019-06-21 11:47:38,509 - root - INFO - Training optimizer: adam
2019-06-21 11:47:38,510 - root - INFO - Training learning rate: 0.0001
2019-06-21 11:47:38,510 - root - INFO - Training epochs: 2
2019-06-21 11:47:38,510 - root - INFO - Training learning rate scheduler milestones: [50]
2019-06-21 11:47:38,510 - root - INFO - Training batch size: 200
2019-06-21 11:47:38,510 - root - INFO - Training weight decay: 5e-07
2019-06-21 11:47:38,510 - root - INFO - Initializing center c...
2019-06-21 11:47:40,065 - root - INFO - Center c initialized.
2019-06-21 11:47:40,065 - root - INFO - Starting training...
2019-06-21 11:47:42,253 - root - INFO -   Epoch 1/2	 Time: 2.188	 Loss: 0.72287164
2019-06-21 11:47:44,430 - root - INFO -   Epoch 2/2	 Time: 2.177	 Loss: 0.15676613
2019-06-21 11:47:44,430 - root - INFO - Training time: 4.365
2019-06-21 11:47:44,430 - root - INFO - Finished training.
2019-06-21 11:47:44,431 - root - INFO - Starting testing...
2019-06-21 11:47:45,961 - root - INFO - Testing time: 1.530
2019-06-21 11:47:46,030 - root - INFO - Test set AUC: 94.45%
2019-06-21 11:47:46,031 - root - INFO - Finished testing.
2019-06-21 13:33:15,467 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 13:33:15,467 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 13:33:15,467 - root - INFO - Export path is ../log/hits_test.
2019-06-21 13:33:15,467 - root - INFO - Dataset: hits
2019-06-21 13:33:15,468 - root - INFO - Normal class: 1
2019-06-21 13:33:15,468 - root - INFO - Network: hits_LeNet
2019-06-21 13:33:15,468 - root - INFO - Deep SVDD objective: one-class
2019-06-21 13:33:15,468 - root - INFO - Nu-paramerter: 0.10
2019-06-21 13:33:15,501 - root - INFO - Computation device: cuda
2019-06-21 13:33:15,501 - root - INFO - Number of dataloader workers: 16
2019-06-21 13:33:29,711 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 13:33:29,711 - root - INFO - Starting testing...
2019-06-21 13:33:31,908 - root - INFO - Testing time: 2.196
2019-06-21 13:33:31,980 - root - INFO - Test set AUC: 94.45%
2019-06-21 13:33:31,980 - root - INFO - Finished testing.
2019-06-21 13:37:45,455 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 13:37:45,455 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 13:37:45,455 - root - INFO - Export path is ../log/hits_test.
2019-06-21 13:37:45,455 - root - INFO - Dataset: hits
2019-06-21 13:37:45,455 - root - INFO - Normal class: 1
2019-06-21 13:37:45,455 - root - INFO - Network: hits_LeNet
2019-06-21 13:37:45,455 - root - INFO - Deep SVDD objective: one-class
2019-06-21 13:37:45,455 - root - INFO - Nu-paramerter: 0.10
2019-06-21 13:37:45,489 - root - INFO - Computation device: cuda
2019-06-21 13:37:45,489 - root - INFO - Number of dataloader workers: 16
2019-06-21 13:37:57,418 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 13:37:57,418 - root - INFO - Starting testing...
2019-06-21 13:37:59,502 - root - INFO - Testing time: 2.083
2019-06-21 13:37:59,584 - root - INFO - Test set AUC: 94.45%
2019-06-21 13:37:59,584 - root - INFO - Finished testing.
2019-06-21 14:00:39,739 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 14:00:39,740 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 14:00:39,740 - root - INFO - Export path is ../log/hits_test.
2019-06-21 14:00:39,740 - root - INFO - Dataset: hits
2019-06-21 14:00:39,740 - root - INFO - Normal class: 1
2019-06-21 14:00:39,740 - root - INFO - Network: hits_LeNet
2019-06-21 14:00:39,740 - root - INFO - Deep SVDD objective: one-class
2019-06-21 14:00:39,740 - root - INFO - Nu-paramerter: 0.10
2019-06-21 14:00:39,753 - root - INFO - Computation device: cuda
2019-06-21 14:00:39,753 - root - INFO - Number of dataloader workers: 16
2019-06-21 14:00:51,742 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 14:00:51,743 - root - INFO - Starting testing...
2019-06-21 14:00:53,683 - root - INFO - Testing time: 1.940
2019-06-21 14:00:53,768 - root - INFO - Test set AUC: 94.45%
2019-06-21 14:00:53,768 - root - INFO - Finished testing.
2019-06-21 14:04:04,940 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 14:04:04,940 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 14:04:04,940 - root - INFO - Export path is ../log/hits_test.
2019-06-21 14:04:04,940 - root - INFO - Dataset: hits
2019-06-21 14:04:04,940 - root - INFO - Normal class: 1
2019-06-21 14:04:04,940 - root - INFO - Network: hits_LeNet
2019-06-21 14:04:04,940 - root - INFO - Deep SVDD objective: one-class
2019-06-21 14:04:04,940 - root - INFO - Nu-paramerter: 0.10
2019-06-21 14:04:04,947 - root - INFO - Computation device: cuda
2019-06-21 14:04:04,947 - root - INFO - Number of dataloader workers: 16
2019-06-21 15:56:31,169 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 15:56:31,169 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 15:56:31,169 - root - INFO - Export path is ../log/hits_test.
2019-06-21 15:56:31,169 - root - INFO - Dataset: hits
2019-06-21 15:56:31,169 - root - INFO - Normal class: 1
2019-06-21 15:56:31,170 - root - INFO - Network: hits_LeNet
2019-06-21 15:56:31,170 - root - INFO - Deep SVDD objective: one-class
2019-06-21 15:56:31,170 - root - INFO - Nu-paramerter: 0.10
2019-06-21 15:56:31,188 - root - INFO - Computation device: cuda
2019-06-21 15:56:31,188 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:21:36,481 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 16:21:36,482 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 16:21:36,482 - root - INFO - Export path is ../log/hits_test.
2019-06-21 16:21:36,482 - root - INFO - Dataset: hits
2019-06-21 16:21:36,482 - root - INFO - Normal class: 1
2019-06-21 16:21:36,482 - root - INFO - Network: hits_LeNet
2019-06-21 16:21:36,482 - root - INFO - Deep SVDD objective: one-class
2019-06-21 16:21:36,482 - root - INFO - Nu-paramerter: 0.10
2019-06-21 16:21:36,500 - root - INFO - Computation device: cuda
2019-06-21 16:21:36,500 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:21:48,182 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 16:21:48,183 - root - INFO - Starting testing...
2019-06-21 16:21:49,885 - root - INFO - Testing time: 1.702
2019-06-21 16:21:49,967 - root - INFO - Test set AUC: 94.45%
2019-06-21 16:21:49,967 - root - INFO - Finished testing.
2019-06-21 16:28:05,550 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 16:28:05,550 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 16:28:05,550 - root - INFO - Export path is ../log/hits_test.
2019-06-21 16:28:05,550 - root - INFO - Dataset: hits
2019-06-21 16:28:05,550 - root - INFO - Normal class: 1
2019-06-21 16:28:05,550 - root - INFO - Network: hits_LeNet
2019-06-21 16:28:05,550 - root - INFO - Deep SVDD objective: one-class
2019-06-21 16:28:05,550 - root - INFO - Nu-paramerter: 0.10
2019-06-21 16:28:05,566 - root - INFO - Computation device: cuda
2019-06-21 16:28:05,566 - root - INFO - Number of dataloader workers: 16
2019-06-21 16:28:17,364 - root - INFO - Loading model from ../log/hits_test/model.tar.
2019-06-21 16:28:17,365 - root - INFO - Starting testing...
2019-06-21 16:28:19,057 - root - INFO - Testing time: 1.692
2019-06-21 16:28:19,141 - root - INFO - Test set AUC: 94.45%
2019-06-21 16:28:19,141 - root - INFO - Finished testing.
2019-06-21 16:31:16,277 - root - INFO - Log file is ../log/hits_test/log.txt.
2019-06-21 16:31:16,277 - root - INFO - Data path is ../../datasets/HiTS2013_300k_samples.pkl.
2019-06-21 16:31:16,277 - root - INFO - Export path is ../log/hits_test.
2019-06-21 16:31:16,277 - root - INFO - Dataset: hits
2019-06-21 16:31:16,277 - root - INFO - Normal class: 1
2019-06-21 16:31:16,277 - root - INFO - Network: hits_LeNet
2019-06-21 16:31:16,277 - root - INFO - Deep SVDD objective: one-class
2019-06-21 16:31:16,277 - root - INFO - Nu-paramerter: 0.10
2019-06-21 16:31:16,295 - root - INFO - Computation device: cuda
2019-06-21 16:31:16,295 - root - INFO - Number of dataloader workers: 16
